<!DOCTYPE html>
<html lang="en">
    <head>
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9438949773830708"
     crossorigin="anonymous"></script>
        <script data-ad-client="ca-pub-9438949773830708" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <meta name="google-site-verification" content="HvFNVSLsWn54ozIScWeIk-WXC8CR7sPOig2Hi9mCHRQ" />
        <meta name="baidu-site-verification" content="code-4CkV5PFvDB" />

        <meta name="referrer" content="no-referrer" />
        
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title>coursera课程-Review of distributions - 胡子叔叔的小站</title><meta name="description" content="coursera上贝叶斯统计专项课程"><meta property="og:title" content="coursera课程-Review of distributions" />
<meta property="og:description" content="coursera上贝叶斯统计专项课程" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://unclehuzi.github.io/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/" /><meta property="og:image" content="https://unclehuzi.github.io/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-09-03T17:16:55+08:00" />
<meta property="article:modified_time" content="2023-09-16T21:08:49+08:00" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://unclehuzi.github.io/"/>

<meta name="twitter:title" content="coursera课程-Review of distributions"/>
<meta name="twitter:description" content="coursera上贝叶斯统计专项课程"/>
<meta name="application-name" content="胡子叔叔的小站">
<meta name="apple-mobile-web-app-title" content="胡子叔叔的小站"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://unclehuzi.github.io/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/" /><link rel="prev" href="https://unclehuzi.github.io/2023/08/da-bayesian_statistics-coursera-from_concept_to_data_analysis/" /><link rel="next" href="https://unclehuzi.github.io/2023/09/python-macos_install_anaconda_by_homebrew/" /><link rel="stylesheet" href="/css/page.min.css"><link rel="stylesheet" href="/css/home.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "coursera课程-Review of distributions",
        "inLanguage": "en",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/unclehuzi.github.io\/2023\/09\/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions\/"
        },"image": ["https:\/\/unclehuzi.github.io\/images\/Apple-Devices-Preview.webp"],"genre": "posts","keywords": "课程笔记, 贝叶斯, 统计学","wordcount":  2727 ,
        "url": "https:\/\/unclehuzi.github.io\/2023\/09\/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions\/","datePublished": "2023-09-03T17:16:55+08:00","dateModified": "2023-09-16T21:08:49+08:00","publisher": {
            "@type": "Organization",
            "name": "胡子叔叔"},"author": {
                "@type": "Person",
                "name": "胡子叔叔"
            },"description": "coursera上贝叶斯统计专项课程"
    }
    </script></head><body data-header-desktop="fixed" data-header-mobile="auto"><script>(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="胡子叔叔的小站"><img
        class="lazyload logo"
        src="/svg/loading.min.svg"
        data-src="https://s2.loli.net/2022/05/28/gVFfRHDzYneST3J.png"
        data-srcset="https://s2.loli.net/2022/05/28/gVFfRHDzYneST3J.png, https://s2.loli.net/2022/05/28/gVFfRHDzYneST3J.png 1.5x, https://s2.loli.net/2022/05/28/gVFfRHDzYneST3J.png 2x"
        data-sizes="auto"
        alt="https://s2.loli.net/2022/05/28/gVFfRHDzYneST3J.png"
        title="https://s2.loli.net/2022/05/28/gVFfRHDzYneST3J.png" />胡子叔叔的小站</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> 文章 </a><a class="menu-item" href="/tags/"> 标签 </a><a class="menu-item" href="/categories/"> 分类 </a><a class="menu-item" href="/about/"> About </a><a class="menu-item" href="https://github.com/unclehuzi/unclehuzi.github.io" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw'></i>  </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-desktop">
                        <a href="#" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="#" class="search-button search-clear" id="search-clear-desktop" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </span><a class="menu-item" href="/index.xml" title="RSS"><i class="fas fa-rss fa-fw" title="RSS"></i> </a><a href="#" onclick="return false;" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="胡子叔叔的小站"><img
        class="lazyload logo"
        src="/svg/loading.min.svg"
        data-src="https://s2.loli.net/2022/05/28/gVFfRHDzYneST3J.png"
        data-srcset="https://s2.loli.net/2022/05/28/gVFfRHDzYneST3J.png, https://s2.loli.net/2022/05/28/gVFfRHDzYneST3J.png 1.5x, https://s2.loli.net/2022/05/28/gVFfRHDzYneST3J.png 2x"
        data-sizes="auto"
        alt="https://s2.loli.net/2022/05/28/gVFfRHDzYneST3J.png"
        title="https://s2.loli.net/2022/05/28/gVFfRHDzYneST3J.png" />胡子叔叔的小站</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-mobile">
                        <a href="#" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="#" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </div>
                    <a href="#" class="search-cancel" id="search-cancel-mobile">
                        Cancel
                    </a>
                </div><a class="menu-item" href="/posts/" title="">文章</a><a class="menu-item" href="/tags/" title="">标签</a><a class="menu-item" href="/categories/" title="">分类</a><a class="menu-item" href="/about/" title="">About</a><a class="menu-item" href="https://github.com/unclehuzi/unclehuzi.github.io" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw'></i></a><div class="menu-item"><a href="/index.xml" title="RSS"><i class="fas fa-rss fa-fw" title="RSS"></i> </a>
                <span>&nbsp;|&nbsp;</span><a href="#" onclick="return false;" class="theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div></div>
    </div>
</header><div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div><main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single" data-toc="enable"><div class="single-card" ><h2 class="single-title animated flipInX">coursera课程-Review of distributions</h2><h2 class="single-subtitle">Bayesian Statistics: From Concept to Data Analysis</h2><div class="post-meta">
                <div class="post-meta-line"><span class="post-author"><a href="https://www.linkedin.com/in/unclehuzi/" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw"></i>胡子叔叔</a></span>&nbsp;<span class="post-category">published in <a href="/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"><i class="far fa-folder fa-fw"></i>数据分析</a>&nbsp;<a href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"><i class="far fa-folder fa-fw"></i>读书笔记</a></span></div>
                <div class="post-meta-line"><span><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2023-09-03">2023-09-03</time></span>&nbsp;<span><i class="fas fa-pencil-alt fa-fw"></i>&nbsp;2727 words</span>&nbsp;
                    <span><i class="far fa-clock fa-fw"></i>&nbsp;13 minutes</span>&nbsp;</div>
            </div>
            
            <hr><div class="details toc" id="toc-static"  data-kept="">
                    <div class="details-summary toc-title">
                        <span>Contents</span>
                        <span><i class="details-icon fas fa-angle-right"></i></span>
                    </div>
                    <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#bernoulli-and-binomial-distributions"><strong>Bernoulli and binomial distributions</strong></a></li>
    <li><a href="#uniform-distribution">Uniform distribution</a></li>
    <li><a href="#exponential-and-normal-distributions"><strong>Exponential and normal distributions</strong></a>
      <ul>
        <li><a href="#exponential-distribution">Exponential distribution</a></li>
        <li><a href="#normal-distribution">Normal distribution</a></li>
      </ul>
    </li>
    <li><a href="#supplementary-material-for-lesson-3"><strong>Supplementary material for Lesson 3</strong></a></li>
    <li><a href="#additional-discrete-distributions">Additional Discrete Distributions</a>
      <ul>
        <li><a href="#geometric-distribution">Geometric distribution</a></li>
        <li><a href="#multinomial-distribution">Multinomial distribution</a></li>
        <li><a href="#poisson-distribution">Poisson distribution</a></li>
      </ul>
    </li>
    <li><a href="#continuous-distributions">Continuous Distributions</a>
      <ul>
        <li><a href="#gamma">Gamma</a></li>
        <li><a href="#beta">Beta</a></li>
        <li><a href="#t">t</a></li>
      </ul>
    </li>
    <li><a href="#central-limit-theorem">Central Limit Theorem</a></li>
  </ul>
</nav></div>
                </div><div class="content" id="content"><h2 id="bernoulli-and-binomial-distributions"><strong>Bernoulli and binomial distributions</strong></h2>
<p><strong>Bernoulli distribution</strong> is used when we have <strong>two possible outcomes</strong>, such as flipping a coin, where it could be heads and tails, or the cases where we have a success or a failure.</p>
<p>$X \sim B(p)$ : A random variable $X$ follows a Bernoulli distribution with probability $p$, where $p$ is probability of success, or probability of heads.</p>
<p>这里用 <strong>Indicator Function</strong> 表示$x$ 取值为0,1 的情况</p>
<p>$$
\begin{align*}
f(X=x \mid p) &amp;= f(x \mid p) \newline
&amp;= p^x(1-p)^{1-x} I_{{x \in {0,1} }}(x) \newline
\end{align*}
$$</p>
<blockquote>
<p>「ChatGPT-3.5」
The indicator function, also referred to as the characteristic function, is a mathematical construct used to <strong>represent whether a certain condition is satisfied or not.</strong> It is commonly denoted by symbols such as <code>I</code> or <code>1</code>. The indicator function takes an element from a set and outputs either 1 or 0, depending on whether the element meets a specified condition.</p>
<p>In formal terms, for a set <code>A</code> and an element <code>x</code>, the indicator function <code>I_A(x)</code> is defined as:</p>
<p>$$
\begin{align*}
I_A(x) =
\begin{cases}
1 &amp; \text{if $x \in A$ (x belongs to $A$) } \newline
0 &amp; \text{if $x \notin A$ (x does not belong to $A$) }
\end{cases}
\end{align*}
$$</p>
<p>In simpler words, the indicator function serves as a way to &ldquo;indicate&rdquo; whether an element is part of a set (condition is true) or not (condition is false).</p>
<p>Indicator functions find applications in various mathematical fields, including probability theory, statistics, and analysis. They are used to express events, define indicator variables, calculate expected values, and simplify mathematical expressions involving conditions or events.</p>
</blockquote>
<blockquote>
<p>In some textbooks, they make a strong distinction between <strong>discrete variables</strong> where these were <em><strong>probably mass functions</strong></em>, and <strong>continues variables</strong> where these are <em><strong>probability density functions</strong></em>.</p>
</blockquote>
<p><strong>Bernoulli distribution</strong>的期望和方差</p>
<p>$$
\begin{align*}
E(X) &amp;= \sum_{x} x \cdot P(X=x) \newline
&amp;=  1 \cdot p + 0 \cdot (1-p)  \newline
&amp;= p
\end{align*}
$$</p>
<p>$$
\begin{align*}
Var(X) &amp;= \sum_{x} (x- E(x))^2 \cdot P(X=x) \newline
&amp;=  (1-p)^2 \cdot p + (0-p)^2 \cdot (1-p)  \newline
&amp;= p(1-p)
\end{align*}
$$</p>
<p>The generalization of the Bernoulli when we have <em><strong>N repeated trials</strong></em> is a <strong>Binomial</strong>. $X \sim Bin(n,p)$</p>
<p>$$
P(X = x \mid p) = \binom{n}{x} p^x (1 - p)^{n - x} \newline
\binom{n}{x} = \frac{n!}{x!(n-x)!}   ; \text{for $x \in { 0,1,&hellip;,n } $}
$$</p>
<p>期望和方差：$E(X)=np, ; Var(X)=np(1-p)$</p>
<h2 id="uniform-distribution">Uniform distribution</h2>
<p>We can define a continuous random variable based on its <strong>probability density function</strong>(<strong>PDF</strong>).</p>
<p>以Uniform distribution为例， $X \sim U(0,1)$</p>
<p>$$
\begin{align*}
f(x) &amp;=
\begin{cases}
1 &amp; x \in [0,1] \newline
0 &amp; \text{otherwise}
\end{cases} \newline
&amp;= I_{{0 \leq x \leq 1}}(x)
\end{align*}
$$</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled.png"
        data-srcset="/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled.png, Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled.png 1.5x, /2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled.png 2x"
        data-sizes="auto"
        alt="/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled.png"
        title="Untitled" /></p>
<ul>
<li>
<p>Python 生成 $U(0,1)$ PDF</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># FROM ChatGPT-3.5</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>  <span class="c1"># 创建一个横坐标范围从0到1的数据点</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># 每个数据点的纵坐标值都是1，因为在U(0,1)均匀分布中概率密度是常数</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;$f(x)$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;$X \sim U(0,1)$&#39;</span><span class="p">)</span>

<span class="c1"># 设置纵轴上限为1.1</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.25</span><span class="p">)</span>

<span class="c1"># 去除上边框和右边框</span>
<span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># 绘制垂直线段</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></td></tr></table>
</div>
</div></li>
</ul>
<p>$$
P(0&lt;x&lt; \frac{1}{2})=\int_{0}^{\frac{1}{2}} f(x) , dx=\frac{1}{2}=P(0 \leq x \leq \frac{1}{2}) \newline
P(x=\frac{1}{2})=0
$$</p>
<p>Some key rules for probability density functions: $\int_{-\infty}^{\infty} f(x) , dx=1$；$f(x) \geq 0$</p>
<p>通用型Uniform distribution，$X \sim U(\theta_1,\theta_2)$  ⇒ $f(x|\theta_1,\theta_2)=\frac{1}{\theta_2-\theta_1}I_{{\theta_1 \leq x \leq \theta_2 }}(x)$</p>
<p>关于连续型随机变量的期望 the expected value for a continuous random variable</p>
<p>$$
\begin{align*}
&amp; E(X)=\int_{-\infty}^{\infty} x f(x) , dx \newline
&amp; E(g(X))=\int g(x)f(x) , dx \newline
&amp; E(CX)=cE(x) \text{,$c$为常数} \newline
&amp; E(X+Y) = E(X) + E(Y) \newline
&amp; \text{if $X \perp Y$, } E(XY)=E(X)E(Y)
\end{align*}
$$</p>
<h2 id="exponential-and-normal-distributions"><strong>Exponential and normal distributions</strong></h2>
<h3 id="exponential-distribution">Exponential distribution</h3>
<blockquote>
<p>「ChatGPT-3.5」</p>
<p>The <strong>Exponential distribution</strong> is a mathematical model often used to <strong>describe the time</strong> <em>between events in situations</em> where <em>events occur randomly and independently at a constant average rate.</em> It&rsquo;s commonly used in fields like queuing theory, reliability analysis, and telecommunications.</p>
<p>Key points about the Exponential distribution:</p>
<ul>
<li><strong>Probability Density Function (PDF)</strong>: The distribution is defined by the equation ( $f(x | \lambda) = \lambda e^{-\lambda x} ，\text{for $x \geq 0$}$ ), where ($x$) is the time between events, and ($\lambda$) is the rate parameter.</li>
<li><strong>Memorylessness</strong>: It has the property that the <strong>probability</strong> of <em>an event occurring in a given interval</em> is <strong>not influenced by the past</strong>. This means that the distribution of time until the next event remains the same, <em><strong>regardless of</strong> how much time has already passed.</em></li>
<li><strong>Cumulative Distribution Function (CDF)</strong>: The CDF is ( $F(x | \lambda) = 1 - e^{-\lambda x}$ ), which provides the probability that an event will occur <em>before a certain time</em> ($x$).</li>
<li><strong>Mean and Variance</strong>: The mean (average) time between events is ($1/\lambda$), and the variance is ($1/\lambda^2$).</li>
</ul>
<p>The Exponential distribution is widely used due to its simplicity and relevance in modeling various real-world scenarios involving random occurrences over time.</p>
</blockquote>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%201.png"
        data-srcset="/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%201.png, Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%201.png 1.5x, /2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%201.png 2x"
        data-sizes="auto"
        alt="/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%201.png"
        title="Untitled" /></p>
<ul>
<li>
<p>code</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">stats</span>

<span class="c1"># Parameters for the exponential distributions (rate)</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;λ=0.5&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;λ=1&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;λ=2&#39;</span><span class="p">)</span>
<span class="p">]</span>

<span class="c1"># Create a figure and axis</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># Plotting</span>
<span class="k">for</span> <span class="n">lambd</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">lambd</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">lambd</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>
        <span class="c1">#y = stats.expon(scale=1/lambd).pdf(x)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Probability Density&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Exponential Distribution&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># 去除上边框和右边框</span>
<span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Display the plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></td></tr></table>
</div>
</div></li>
</ul>
<h3 id="normal-distribution">Normal distribution</h3>
<blockquote>
<p>「ChatGPT-3.5」</p>
<p>The <strong>Normal distribution</strong>, also known as the Gaussian distribution, is a bell-shaped curve that describes the distribution of many types of data. It is symmetrical and its mean, median, and mode are all equal.</p>
<p>Key points:</p>
<ul>
<li><strong>Bell-shaped</strong>: Its graph is a symmetrical bell-shaped curve.</li>
<li><strong>Parameters</strong>: It is defined by two parameters: the mean ($\mu$) and the standard deviation ($\sigma$).</li>
<li><strong>68-95-99.7 Rule</strong>: About 68% of the data falls within one standard deviation of the mean, 95% within two standard deviations, and 99.7% within three.</li>
<li><strong>Applications</strong>: It&rsquo;s widely used in statistics, science, and engineering due to many natural phenomena and processes being approximately normally distributed.</li>
</ul>
<p>The formula for its probability density function (PDF) is:</p>
<p>$$
f(x | \mu, \sigma) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}
$$</p>
<p>However, for many practical applications, understanding its bell shape and the 68-95-99.7 rule is often more crucial than knowing its exact formula.</p>
</blockquote>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%202.png"
        data-srcset="/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%202.png, Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%202.png 1.5x, /2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%202.png 2x"
        data-sizes="auto"
        alt="/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%202.png"
        title="Untitled" /></p>
<ul>
<li>
<p>code</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">stats</span>

<span class="c1"># Parameters for the normal distributions</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;$\mu=0, \sigma=1$&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;$\mu=2, \sigma=0.5$&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="s1">&#39;$\mu=-2, \sigma=2.5$&#39;</span><span class="p">)</span>
<span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="k">for</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">mu</span> <span class="o">-</span> <span class="mi">3</span><span class="o">*</span><span class="n">sigma</span><span class="p">,</span> <span class="n">mu</span> <span class="o">+</span> <span class="mi">3</span><span class="o">*</span><span class="n">sigma</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>

<span class="c1"># 去除上边框和右边框</span>
<span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Probability Density&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Normal Distribution&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></td></tr></table>
</div>
</div></li>
</ul>
<h2 id="supplementary-material-for-lesson-3"><strong>Supplementary material for Lesson 3</strong></h2>
<p><a href="https://d3c33hcgiwev3.cloudfront.net/_29f7eaaba3ac0d35ee74f8bd61aafc39_L3_supp.pdf?Expires=1692144000&amp;Signature=KA2KF0vx3gwhBdV~Qp1XAF3vmfziOf~pLoeyXkGI1sDGXz5P33eynAVVDQoyGfg3mFzxs0Jil10bamlf2z6rm8fb3cqMK7mVH5D~BjvT-W0MxKqjKUKvJsiiq6g1u23yDIWzSOxb39qZp1ISLzVL27Pqkdb6YgaqxrjsxaFAaOE_&amp;Key-Pair-Id=APKAJLTNE6QMUY6HBC5A" target="_blank" rel="noopener noreffer">https://d3c33hcgiwev3.cloudfront.net/<em>29f7eaaba3ac0d35ee74f8bd61aafc39_L3_supp.pdf?Expires=1692144000&amp;Signature=KA2KF0vx3gwhBdV~Qp1XAF3vmfziOf~pLoeyXkGI1sDGXz5P33eynAVVDQoyGfg3mFzxs0Jil10bamlf2z6rm8fb3cqMK7mVH5D~BjvT-W0MxKqjKUKvJsiiq6g1u23yDIWzSOxb39qZp1ISLzVL27Pqkdb6YgaqxrjsxaFAaOE</em>&amp;Key-Pair-Id=APKAJLTNE6QMUY6HBC5A</a></p>
<h2 id="additional-discrete-distributions">Additional Discrete Distributions</h2>
<h3 id="geometric-distribution">Geometric distribution</h3>
<p>The geometric distribution is <em><strong>the number of trials</strong></em> needed to get the first success, i.e., the number of Bernoulli events until a success is observed, such as the first head when flipping a coin. It takes values on the positive integers starting with one (since at least one trial is needed to observe a success).</p>
<p>$$
X \sim Geo(p) \newline
P(X=x|p)=p(1-p)^{x-1} \text{for $x=1,2,&hellip;$} \newline
E(X)=\frac{1}{p}
$$</p>
<p>If the probability of getting a success is $p$, then the expected number of trials until the first
success is $\frac{1}{p}$.</p>
<p>🌰 <strong>Example</strong>: What is the probability that we flip a fair coin four times and don’t see any heads?
This is the same as asking what is $P(X &gt; 4)$  where $X \sim Geo(1/2)$ .</p>
<p>$$
\begin{align*}
P(X&gt;4) &amp;= 1-P(X=1)-P(X=2)-P(X=3)-p(X=4) \newline
&amp;=1-\frac{1}{2}-\frac{1}{2} (\frac{1}{2})-\frac{1}{2} (\frac{1}{2})^2-\frac{1}{2} (\frac{1}{2})^3 \newline
&amp;= \frac{1}{16}
\end{align*}
$$</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%203.png"
        data-srcset="/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%203.png, Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%203.png 1.5x, /2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%203.png 2x"
        data-sizes="auto"
        alt="/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%203.png"
        title="Untitled" /></p>
<ul>
<li>
<p>code</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">geom</span>

<span class="c1"># Parameters for the geometric distribution</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="s1">&#39;$p=0.3$&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;$p=0.5$&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">0.7</span><span class="p">,</span> <span class="s1">&#39;$p=0.7$&#39;</span><span class="p">)</span>
<span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">geom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>   <span class="c1"># Probability mass function</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>

<span class="c1"># Remove top and right borders</span>
<span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Trials&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Probability&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Geometric Distribution&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></td></tr></table>
</div>
</div></li>
</ul>
<h3 id="multinomial-distribution">Multinomial distribution</h3>
<p>Another generalization of the Bernoulli and the binomial is the <em><strong>multinomial distribution</strong></em>, which is <em><strong>like a binomial</strong></em> when there are <em><strong>more than two possible outcomes</strong></em>.</p>
<p>Suppose we have $n$ trials and there are $k$ different possible outcomes which occur with probabilities $p_1,p_2,&hellip;,p_k$ .</p>
<p>For example, we are rolling a six-sided die that might be loaded so that the sides are not equally likely, then $n$ is the total number of rolls, $k=6$, $p_1$ is the probability of rolling a one, and we denote by $x_1,&hellip;,x_6$ a possible outcome for <strong>the number of times</strong> we observe rolls of each of one through six, where $\sum\limits_{i=1}^{6}x_i=n \text{ and } \sum\limits_{i=1}^{6}p_i=1$.</p>
<p>$$
f(x_1,\dots ,x_k|p_1,\dots ,p_k)=\frac{n!}{x_1!\dots x_k !}p_1^{x_1}\dots p_k^{x_k}
$$</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%204.png"
        data-srcset="/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%204.png, Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%204.png 1.5x, /2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%204.png 2x"
        data-sizes="auto"
        alt="/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%204.png"
        title="Untitled" /></p>
<ul>
<li>
<p>模拟code</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">multinomial</span>
<span class="c1"># set seed for reproductibility</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">999</span><span class="p">)</span> 

<span class="c1"># Parameters for the multinomial distribution</span>
<span class="n">k</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">12</span> <span class="c1"># number of trials (games in one tourment)</span>
<span class="n">pvals</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">]</span>

<span class="n">sizes</span> <span class="o">=</span><span class="p">[]</span> <span class="c1"># number of tournments played</span>
<span class="n">p</span> <span class="o">=</span> <span class="p">[]</span>    <span class="c1"># a list to hold ratios (converge to prob) that player 1 wins 7 times, player 2 wins 2 times and 3 ties</span>

<span class="c1"># 公式计算</span>
<span class="n">f_x</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">multinomial</span><span class="o">.</span><span class="n">pmf</span><span class="p">([</span><span class="mi">7</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span><span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span><span class="n">p</span><span class="o">=</span><span class="n">pvals</span><span class="p">),</span><span class="mi">4</span><span class="p">)</span>

<span class="c1"># 模拟</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="k">for</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">):</span>
    <span class="c1"># the line below is where we actually generate discrete random variables according the multinomial distribution</span>
    <span class="n">outcomes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">pvals</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">size</span><span class="p">))</span>

    <span class="c1"># let&#39;s count the ratio of the expected outcome over all the outcomes - this will lastly converge to the probability</span>
    <span class="n">prob</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">((</span><span class="n">outcomes</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">==</span><span class="mi">7</span><span class="p">)</span><span class="o">&amp;</span><span class="p">(</span><span class="n">outcomes</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">==</span><span class="mi">2</span><span class="p">)</span><span class="o">&amp;</span><span class="p">(</span><span class="n">outcomes</span><span class="p">[:,</span><span class="mi">2</span><span class="p">]</span><span class="o">==</span><span class="mi">3</span><span class="p">))</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">outcomes</span><span class="p">)</span>

    <span class="n">p</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prob</span><span class="p">)</span>
    <span class="n">sizes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">size</span><span class="p">))</span>

<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sizes</span><span class="p">,</span><span class="n">p</span><span class="p">,</span><span class="s1">&#39;o-&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sizes</span><span class="p">,[</span><span class="n">f_x</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">),</span><span class="s1">&#39;--r&#39;</span><span class="p">)</span>

<span class="n">line1</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&#34;$p_1,p_2,p_3=(0.4, 0.35, 0.25)$&#34;</span>  <span class="c1"># 文本内容</span>
<span class="n">line2</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&#34;$x_1,x_2,x_3=(7,2,3)$&#34;</span>  <span class="c1"># 文本内容</span>

<span class="n">x_pos</span> <span class="o">=</span> <span class="mf">0.95</span>  <span class="c1"># x 坐标位置（相对于轴范围的比例）</span>
<span class="n">y_pos</span> <span class="o">=</span> <span class="mf">0.95</span>  <span class="c1"># y 坐标位置（相对于轴范围的比例）</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x_pos</span><span class="p">,</span> <span class="n">y_pos</span><span class="p">,</span> <span class="n">line2</span><span class="o">+</span><span class="s2">&#34;</span><span class="se">\n</span><span class="s2">&#34;</span><span class="o">+</span><span class="n">line1</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">ax</span><span class="o">.</span><span class="n">transAxes</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
        <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;top&#39;</span><span class="p">)</span>
<span class="c1"># Remove top and right borders</span>
<span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">xmin</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Drawings&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;$p(x_1,x_2,x_3|p_1,p_2,p_3)$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Theoretical $f(x_1,x_2,x_3|p_1,p_2,p_3)=</span><span class="si">{}</span><span class="s1">$&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">f_x</span><span class="p">))</span>

<span class="c1">#plt.grid(True)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></td></tr></table>
</div>
</div></li>
</ul>
<h3 id="poisson-distribution">Poisson distribution</h3>
<p>The Poisson distribution is used for counts, and arises in a variety of situations. The parameter $\lambda &gt; 0$ is the <em><strong>rate</strong></em> at which we expect to observe the thing we are counting.</p>
<p>$$
X \sim Pois(\lambda) \newline
P(X=x|\lambda)=\frac{\lambda^xexp(- \lambda)}{x!} \text{ for $x=0,1,2,\dots$} \newline
E(X)=\lambda \newline
Var(X) =\lambda
$$</p>
<p>🌰 <strong>Example</strong>: Significant earthquakes occur in the Western United States approximately following a Poisson process with rate of two earthquakes per week. What is the probability there will be at least 3 earthquakes in the next two weeks?</p>
<p>未来两周发生地震的次数记为$X$，由题意得，$X \sim Pois(4)$.</p>
<p>$$
\begin{align*}
P(X\geq 3) &amp;= 1-P(X\leq2) \newline
&amp;=1- P(X=0)- P(X=1)- P(X=2) \newline
&amp;=1 - \frac{4^0 exp(- 4)}{0!} -\frac{4^1 exp(- 4)}{1!} - \frac{4^2 exp(- 4)}{2!} \newline
&amp;= 1-13e^{-4} \newline
&amp;=0.762
\end{align*}
$$</p>
<h2 id="continuous-distributions">Continuous Distributions</h2>
<h3 id="gamma">Gamma</h3>
<p>If $X_1,X_2,\dots,X_n$ are independent (and identically distributed $Exp(\lambda)$) <em><strong>waiting times</strong></em> between successive events, then the total waiting time for all n events to occur $Y=\sum_{i=1}^{n}X_i$ will follow a gamma distribution with shape parameter $\alpha=n$ and rate parameter $\beta=\lambda$.</p>
<p>$$
Y \sim Gamma(\alpha,\beta) \newline
f(y|\alpha,\beta)=\frac{\beta^\alpha}{\Gamma(\alpha)}y^{\alpha-1}e^{-\beta y}I_{ {y \geq0}}(y) \newline
E(Y) = \frac{\alpha}{\beta} \newline
Var(Y) =  \frac{\alpha}{\beta^2}
$$</p>
<p>where $\Gamma(·)$ is the gamma function, a generalization of the factorial function which can accept non-integer arguments. If $n$ is a positive integer, then $\Gamma(n) = (n − 1)!$ . Note also that $\alpha&gt; 0$ and $\beta &gt; 0$ .</p>
<p>The exponential distribution is a special case of the gamma distribution with $\alpha = 1$. The gamma distribution commonly appears in statistical problems, as we will see in this course. It is used to model positive-valued, continuous quantities whose distribution is right-skewed. As $\alpha$ increases, the gamma distribution more closely resembles the normal distribution.</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%205.png"
        data-srcset="/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%205.png, Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%205.png 1.5x, /2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%205.png 2x"
        data-sizes="auto"
        alt="/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%205.png"
        title="Untitled" /></p>
<ul>
<li>
<p>code</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">gamma</span>

<span class="c1"># Parameters for the gamma distribution</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;$</span><span class="se">\\</span><span class="s1">alpha=1, </span><span class="se">\\</span><span class="s1">beta=0.5$&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;$</span><span class="se">\\</span><span class="s1">alpha=5, </span><span class="se">\\</span><span class="s1">beta=1$&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;$</span><span class="se">\\</span><span class="s1">alpha=8, </span><span class="se">\\</span><span class="s1">beta=2$&#39;</span><span class="p">)</span>
<span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="k">for</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">gamma</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">beta</span><span class="p">),</span> <span class="n">gamma</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">beta</span><span class="p">),</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">gamma</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">beta</span><span class="p">)</span>   <span class="c1"># Probability density function</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>

<span class="c1"># Remove top and right borders</span>
<span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Probability Density&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Gamma Distribution&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></td></tr></table>
</div>
</div></li>
</ul>
<h3 id="beta">Beta</h3>
<p>The beta distribution is used for random variables which <strong>take on values between 0 and 1</strong>. For this reason (and other reasons we will see later in the course), the beta distribution is commonly used to model probabilities</p>
<p>$$
X \sim Beta(\alpha,\beta) \newline
f(x|\alpha,\beta)=\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha-1}(1-x)^{\beta -1}I_{ {0&lt;x&lt;1}}(x) \newline
E(X) = \frac{\alpha}{\alpha + \beta} \newline
Var(X) =  \frac{\alpha \beta}{(\alpha+\beta)^2(\alpha+\beta+1)}
$$</p>
<p>where $\Gamma(·)$ is the gamma function introduced with the gamma distribution. Note also that $\alpha&gt; 0$ and $\beta &gt; 0$ . The standard Uniform(0, 1) distribution is a special case of the betadistribution with $\alpha=\beta=1$ .</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%206.png"
        data-srcset="/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%206.png, Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%206.png 1.5x, /2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%206.png 2x"
        data-sizes="auto"
        alt="/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%206.png"
        title="Untitled" /></p>
<ul>
<li>
<p>code</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">beta</span>

<span class="c1"># Parameters for the Beta distribution</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;$</span><span class="se">\\</span><span class="s1">alpha=2, </span><span class="se">\\</span><span class="s1">beta=5$&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;$</span><span class="se">\\</span><span class="s1">alpha=5, </span><span class="se">\\</span><span class="s1">beta=1$&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;$</span><span class="se">\\</span><span class="s1">alpha=2, </span><span class="se">\\</span><span class="s1">beta=2$&#39;</span><span class="p">)</span>
<span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>   <span class="c1"># Probability density function</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>

<span class="c1"># Remove top and right borders</span>
<span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Probability Density&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Beta Distribution&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></td></tr></table>
</div>
</div></li>
</ul>
<h3 id="t">t</h3>
<p>If we have normal data, we can use $\bar{X} \sim N(\mu,\frac{\sigma^2}{n})$ to help us estimate the mean $\mu$. 标准正态分布： $\frac{\bar{X} - \mu}{\sigma/ \sqrt{n}} \sim N(0,1)$. However, we may not know the value of $\sigma$. If we estimate it from data, we can replace it with $S=\sqrt{\sum_i(X_i - \bar{X})^2/(n-1)}$ , the sample standard deviation. This causes the $\frac{\bar{X} - \mu}{\sigma/ \sqrt{n}}$ to no longer be distributed as standard normal, but as a standard t distribution with $\nu=n-1$ degrees of freedom.</p>
<p>$$
Y \sim t_{\nu} \newline
f(y) = \frac{\Gamma(\frac{\nu +1}{2})}{\Gamma(\frac{\nu}{2}) \sqrt{\nu \pi}}(1+\frac{y^2}{\nu})^{-(\frac{\nu + 1}{2})} \newline
E(Y) = 0 \text{, if $\nu &gt; 1$ } \newline
Var(Y) = \frac{\nu}{\nu - 2} \text{, if $\nu &gt; 2$}
$$</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%207.png"
        data-srcset="/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%207.png, Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%207.png 1.5x, /2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%207.png 2x"
        data-sizes="auto"
        alt="/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%207.png"
        title="Untitled" /></p>
<ul>
<li>
<p>code</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">t</span>

<span class="c1"># Parameters for the t distribution</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;$df=2$&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;$df=5$&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="s1">&#39;$df=10$&#39;</span><span class="p">)</span>
<span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># Plot probability density function</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;t Distribution - Probability Density Function&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">df</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span>   <span class="c1"># Probability density function</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>

<span class="c1"># Plot cumulative distribution function</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;t Distribution - Cumulative Distribution Function&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">df</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span>   <span class="c1"># Cumulative distribution function</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>

<span class="c1"># Remove top and right borders</span>
<span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">:</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Probability Density&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Cumulative Probability&#39;</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></td></tr></table>
</div>
</div></li>
</ul>
<blockquote>
<p>作者：吴端</p>
<p>链接：https://www.zhihu.com/question/34866983/answer/1540230125</p>
<p>来源：知乎</p>
<p>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
<p>分布分为离散分布和连续分布。连续分布几乎都能找到对应的离散分布。因为连续分布本质上就是把离散分布中投硬币的次数，变成连续的时间长度。把每次投硬币的正反面概率，变成单位时间内出现正面的概率密度。</p>
<p>下面我从贝努利实验出发，把所有分布的关系梳理出来：</p>
<p>贝努利实验：投硬币，正面反面概率分别为p，1-p</p>
<p>二项分布：如果把贝努利实验连续做n次，出现正面的次数服从的分布。</p>
<p>二项分布的极限：泊松分布。给定时间内时间发生次数的分布。</p>
<p>负二项分布：在贝努利实验中，如果想让正面出现n次，需要做的实验次数的分布。</p>
<p>负二项分布的极限：gamma分布。问如果指定事件出现N次，需要等待的时间。</p>
<p>二项分布与负二项分布的关系：二项分布是在固定实验次数情况下，问结果分布。负二项分布是在固定结果情况下问实验次数分布。一个是在固定投入问产出，一个是在固定产出下问投入。</p>
<p>几何分布：n重贝努利实验，正面第一次出现时的实验次数。</p>
<p>几何分布的极限：指数分布。事件第一次发生等待的时间。</p>
<p>几何分布与负二项分布的关系：负二项分布是N个几何分布的和。相当于做N次几何分布，事件正好发生N次。各几何分布的实验次数之和就是负二项分布的总次数。</p>
<p>指数分布与gamma分布的关系：N次指数分布时间之和就是gamma分布中事件发生N次等待总时间。</p>
<p>如果课本能这样组织这些知识，估计也没有人困惑为啥整这么多奇怪的分布，到底有什么用。推倒过程反而没那么重要</p>
</blockquote>
<h2 id="central-limit-theorem">Central Limit Theorem</h2>
<p>The Central Limit Theorem is one of the most important results in statistics, basically saying
that with sufficiently large sample sizes, <em><strong>the sample average</strong></em> approximately follows a normal
distribution.</p>
<p>In formal mathematical notation, the Central Limit Theorem says: Let $X_1,\dots ,X_n$ be independent and identically distributed with $E(X_i)=\mu \text{ and } Var(X_i)= \sigma^2,0 &lt; \sigma^2 &lt; \infty$, then,</p>
<p>$$
\frac{\sqrt{n}(\bar{X}-\mu)}{\sigma} \sim N(0,1)
$$</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%208.png"
        data-srcset="/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%208.png, Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%208.png 1.5x, /2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%208.png 2x"
        data-sizes="auto"
        alt="/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%208.png"
        title="Untitled" /></p>
<p>
<script src="https://gist.github.com/unclehuzi/31feb53fe47d33b937fc70f7a71d1cf4.js"></script>
</p></div><div class="post-footer" id="post-footer">
    <div class="post-info"><div class="post-info-tag"><span><a href="/tags/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/">课程笔记</a>
                </span><span><a href="/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF/">贝叶斯</a>
                </span><span><a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6/">统计学</a>
                </span></div><div class="post-info-line"><div class="post-info-mod">
                <span>Updated on 2023-09-16&nbsp;<a class="git-hash" href="https://github.com/unclehuzi/unclehuzi.github.io/commit/19447759ea69bbccf251a23e5dda0045544acffa" target="_blank" title="committed&nbsp;by&nbsp;unclehuzi(weihu0730@gmail.com)&nbsp;1944775:&nbsp;homebrew_install_anaconda">
                            <i class="fas fa-hashtag fa-fw"></i>1944775</a></span>
            </div><div class="post-info-mod"><span>
                            <a class="link-to-markdown" href="/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/index.md" target="_blank">Read Markdown</a>
                        </span></div>
        </div><div class="post-info-share">
            <span><a href="#" onclick="return false;" title="Share on Twitter" data-sharer="twitter" data-url="https://unclehuzi.github.io/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/" data-title="coursera课程-Review of distributions" data-hashtags="课程笔记,贝叶斯,统计学"><i class="fab fa-twitter fa-fw"></i></a><a href="#" onclick="return false;" title="Share on Facebook" data-sharer="facebook" data-url="https://unclehuzi.github.io/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/" data-hashtag="课程笔记"><i class="fab fa-facebook-square fa-fw"></i></a><a href="#" onclick="return false;" title="Share on Linkedin" data-sharer="linkedin" data-url="https://unclehuzi.github.io/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/"><i class="fab fa-linkedin fa-fw"></i></a><a href="#" onclick="return false;" title="Share on Reddit" data-sharer="reddit" data-url="https://unclehuzi.github.io/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/"><i class="fab fa-reddit fa-fw"></i></a><a href="#" onclick="return false;" title="Share on 微博" data-sharer="weibo" data-url="https://unclehuzi.github.io/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/" data-title="coursera课程-Review of distributions"><i class="fab fa-weibo fa-fw"></i></a><a href="#" onclick="return false;" title="Share on Trello" data-sharer="trello" data-url="https://unclehuzi.github.io/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/" data-title="coursera课程-Review of distributions" data-description="coursera上贝叶斯统计专项课程"><i class="fab fa-trello fa-fw"></i></a></span>
        </div></div><div class="post-nav"><a href="/2023/08/da-bayesian_statistics-coursera-from_concept_to_data_analysis/" class="prev" rel="prev" title="coursera课程-Probability and Bayes’ Theorem"><i class="fas fa-angle-left fa-fw"></i>Previous Post</a>
            <a href="/2023/09/python-macos_install_anaconda_by_homebrew/" class="next" rel="next" title="macOS通过homebrew安装anaconda">Next Post<i class="fas fa-angle-right fa-fw"></i></a></div></div>
</div><div id="comments" class="single-card"><div id="utterances"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://utteranc.es/">Utterances</a>.
            </noscript></div></article></div>
            </main>
            <footer class="footer"><div class="footer-container"><div class="footer-line"><span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span> • <span id="busuanzi_container_site_uv">访客数<span id="busuanzi_value_site_uv"></span>人</span></div><div class="footer-line">Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.84.4">Hugo</a> | Theme - <a href="https://github.com/khusika/FeelIt" target="_blank" rel="noopener noreffer" title="FeelIt 1.0.1"><i class="fas fa-hand-holding-heart fa-fw"></i> FeelIt</a>
        </div><div class="footer-line" itemscope itemtype="http://schema.org/CreativeWork"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2020 - 2023</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="https://www.linkedin.com/in/unclehuzi/">胡子叔叔</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div>
</div>
<script>
if ('serviceWorker' in navigator) {
    navigator.serviceWorker
        .register('/sw.min.js?version=1.0.1', { scope: '/' })
        .then(() => {
            console.info('胡子叔叔的小站\u00A0Service Worker Registered');
        }, err => console.error('胡子叔叔的小站\u00A0Service Worker registration failed: ', err));

    navigator.serviceWorker
        .ready
        .then(() => {
            console.info('胡子叔叔的小站\u00A0Service Worker Ready');
        });
}
</script>
</footer>
        </div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-chevron-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment-alt fa-fw"></i>
            </a></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.7.2/animate.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.1-beta.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/copy-tex.min.css"><script src="https://cdn.jsdelivr.net/npm/autocomplete.js@0.38.0/dist/autocomplete.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lunr@2.3.9/lunr.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js"></script><script src="https://cdn.jsdelivr.net/npm/twemoji@13.1.0/dist/twemoji.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.1-beta.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js"></script><script src="https://cdn.jsdelivr.net/npm/sharer.js@0.4.1/sharer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.js"></script><script src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/auto-render.min.js"></script><script src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/copy-tex.min.js"></script><script src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/mhchem.min.js"></script><script>window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":66},"comment":{"utterances":{"darkTheme":"github-dark","issueTerm":"pathname","label":"","lightTheme":"github-light","repo":"unclehuzi/unclehuzi.github.io"}},"lightGallery":{"actualSize":false,"exThumbImage":"data-thumbnail","hideBarsDelay":2000,"selector":".lightgallery","speed":400,"thumbContHeight":80,"thumbWidth":80,"thumbnail":true},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","maxResultLength":10,"noResultsFound":"No results found","snippetLength":30,"type":"lunr"},"twemoji":true};</script><script src="/js/theme.min.js"></script></body><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

</html>
