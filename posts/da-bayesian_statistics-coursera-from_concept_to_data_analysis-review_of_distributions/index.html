<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>courseraè¯¾ç¨‹-Review of distributions | H.W.</title><meta name=keywords content="è¯¾ç¨‹ç¬”è®°,è´å¶æ–¯,ç»Ÿè®¡å­¦"><meta name=description content="courseraä¸Šè´å¶æ–¯ç»Ÿè®¡ä¸“é¡¹è¯¾ç¨‹"><meta name=author content="èƒ¡å­å”å”"><link rel=canonical href=https://unclehuzi.github.io/posts/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/><link crossorigin=anonymous href=/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=https://unclehuzi.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://unclehuzi.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://unclehuzi.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://unclehuzi.github.io/apple-touch-icon.png><link rel=mask-icon href=https://unclehuzi.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload=renderMathInElement(document.body)></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-JZ3C49ZSKM"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-JZ3C49ZSKM",{anonymize_ip:!1})}</script><meta property="og:title" content="courseraè¯¾ç¨‹-Review of distributions"><meta property="og:description" content="courseraä¸Šè´å¶æ–¯ç»Ÿè®¡ä¸“é¡¹è¯¾ç¨‹"><meta property="og:type" content="article"><meta property="og:url" content="https://unclehuzi.github.io/posts/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/"><meta property="og:image" content="https://unclehuzi.github.io/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-09-03T17:16:55+08:00"><meta property="article:modified_time" content="2023-09-03T17:16:55+08:00"><meta property="og:site_name" content="èƒ¡å­å”å”çš„å°ç«™"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://unclehuzi.github.io/"><meta name=twitter:title content="courseraè¯¾ç¨‹-Review of distributions"><meta name=twitter:description content="courseraä¸Šè´å¶æ–¯ç»Ÿè®¡ä¸“é¡¹è¯¾ç¨‹"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://unclehuzi.github.io/posts/"},{"@type":"ListItem","position":2,"name":"courseraè¯¾ç¨‹-Review of distributions","item":"https://unclehuzi.github.io/posts/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"courseraè¯¾ç¨‹-Review of distributions","name":"courseraè¯¾ç¨‹-Review of distributions","description":"courseraä¸Šè´å¶æ–¯ç»Ÿè®¡ä¸“é¡¹è¯¾ç¨‹","keywords":["è¯¾ç¨‹ç¬”è®°","è´å¶æ–¯","ç»Ÿè®¡å­¦"],"articleBody":"Bernoulli and binomial distributions Bernoulli distribution is used when we have two possible outcomes, such as flipping a coin, whereÂ it could be heads and tails, or the cases where we have a success or a failure.\n$X \\sim B(p)$ : A random variable $X$ follows a Bernoulli distribution with probability $p$, where $p$ is probability of success, or probability of heads.\nè¿™é‡Œç”¨ Indicator Function è¡¨ç¤º$x$ å–å€¼ä¸º0,1 çš„æƒ…å†µ\n$$ \\begin{align*} f(X=x \\mid p) \u0026= f(x \\mid p) \\newline \u0026= p^x(1-p)^{1-x} I_{{x \\in {0,1} }}(x) \\newline \\end{align*} $$\nã€ŒChatGPT-3.5ã€ The indicator function, also referred to as the characteristic function, is a mathematical construct used to represent whether a certain condition is satisfied or not. It is commonly denoted by symbols such as I or 1. The indicator function takes an element from a set and outputs either 1 or 0, depending on whether the element meets a specified condition.\nIn formal terms, for a set A and an element x, the indicator function I_A(x) is defined as:\n$$ \\begin{align*} I_A(x) = \\begin{cases} 1 \u0026 \\text{if $x \\in A$ (x belongs to $A$) } \\newline 0 \u0026 \\text{if $x \\notin A$ (x does not belong to $A$) } \\end{cases} \\end{align*} $$\nIn simpler words, the indicator function serves as a way to â€œindicateâ€ whether an element is part of a set (condition is true) or not (condition is false).\nIndicator functions find applications in various mathematical fields, including probability theory, statistics, and analysis. They are used to express events, define indicator variables, calculate expected values, and simplify mathematical expressions involving conditions or events.\nIn some textbooks, they make a strong distinction between discrete variables where these were probably mass functions, and continues variables where these are probability density functions.\nBernoulli distributionçš„æœŸæœ›å’Œæ–¹å·®\n$$ \\begin{align*} E(X) \u0026= \\sum_{x} x \\cdot P(X=x) \\newline \u0026= 1 \\cdot p + 0 \\cdot (1-p) \\newline \u0026= p \\end{align*} $$\n$$ \\begin{align*} Var(X) \u0026= \\sum_{x} (x- E(x))^2 \\cdot P(X=x) \\newline \u0026= (1-p)^2 \\cdot p + (0-p)^2 \\cdot (1-p) \\newline \u0026= p(1-p) \\end{align*} $$\nThe generalization of the Bernoulli when we have N repeated trials is a Binomial. $X \\sim Bin(n,p)$\n$$ P(X = x \\mid p) = \\binom{n}{x} p^x (1 - p)^{n - x} \\newline \\binom{n}{x} = \\frac{n!}{x!(n-x)!} ; \\text{for $x \\in { 0,1,â€¦,n } $} $$\næœŸæœ›å’Œæ–¹å·®ï¼š$E(X)=np, ; Var(X)=np(1-p)$\nUniform distribution We can define a continuous random variable based on its probability density function(PDF).\nä»¥Uniform distributionä¸ºä¾‹ï¼Œ $X \\sim U(0,1)$\n$$ \\begin{align*} f(x) \u0026= \\begin{cases} 1 \u0026 x \\in [0,1] \\newline 0 \u0026 \\text{otherwise} \\end{cases} \\newline \u0026= I_{{0 \\leq x \\leq 1}}(x) \\end{align*} $$\nPython ç”Ÿæˆ $U(0,1)$ PDF\n# FROM ChatGPT-3.5 import numpy as np import matplotlib.pyplot as plt x = np.linspace(0, 1, 1000) # åˆ›å»ºä¸€ä¸ªæ¨ªåæ ‡èŒƒå›´ä»0åˆ°1çš„æ•°æ®ç‚¹ y = np.ones_like(x) # æ¯ä¸ªæ•°æ®ç‚¹çš„çºµåæ ‡å€¼éƒ½æ˜¯1ï¼Œå› ä¸ºåœ¨U(0,1)å‡åŒ€åˆ†å¸ƒä¸­æ¦‚ç‡å¯†åº¦æ˜¯å¸¸æ•° fig, ax = plt.subplots() ax.plot(x, y, color='blue') ax.set_xlabel('x') ax.set_ylabel('$f(x)$') ax.set_title('$X \\sim U(0,1)$') # è®¾ç½®çºµè½´ä¸Šé™ä¸º1.1 ax.set_ylim(0, 1.25) # å»é™¤ä¸Šè¾¹æ¡†å’Œå³è¾¹æ¡† ax.spines['top'].set_visible(False) ax.spines['right'].set_visible(False) # ç»˜åˆ¶å‚ç›´çº¿æ®µ plt.plot([0, 0], [0, 1], color='gray', linestyle='dashed', linewidth=1) plt.plot([1, 1], [0, 1], color='gray', linestyle='dashed', linewidth=1) plt.show() $$ P(0","wordCount":"2474","inLanguage":"en","datePublished":"2023-09-03T17:16:55+08:00","dateModified":"2023-09-03T17:16:55+08:00","author":{"@type":"Person","name":"èƒ¡å­å”å”"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://unclehuzi.github.io/posts/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/"},"publisher":{"@type":"Organization","name":"H.W.","logo":{"@type":"ImageObject","url":"https://unclehuzi.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://unclehuzi.github.io/ accesskey=h title="H.W. (Alt + H)">H.W.</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://unclehuzi.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://unclehuzi.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://unclehuzi.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://unclehuzi.github.io/tags/ title=tags><span>tags</span></a></li><li><a href=https://unclehuzi.github.io/about/ title=about><span>about</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://unclehuzi.github.io/>Home</a>&nbsp;Â»&nbsp;<a href=https://unclehuzi.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">courseraè¯¾ç¨‹-Review of distributions</h1><div class=post-description>courseraä¸Šè´å¶æ–¯ç»Ÿè®¡ä¸“é¡¹è¯¾ç¨‹</div><div class=post-meta><span title='2023-09-03 17:16:55 +0800 +0800'>2023-09-03</span>&nbsp;Â·&nbsp;èƒ¡å­å”å”</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#bernoulli-and-binomial-distributions><strong>Bernoulli and binomial distributions</strong></a></li><li><a href=#uniform-distribution>Uniform distribution</a></li><li><a href=#exponential-and-normal-distributions><strong>Exponential and normal distributions</strong></a><ul><li><a href=#exponential-distribution>Exponential distribution</a></li><li><a href=#normal-distribution>Normal distribution</a></li></ul></li><li><a href=#supplementary-material-for-lesson-3><strong>Supplementary material for Lesson 3</strong></a></li><li><a href=#additional-discrete-distributions>Additional Discrete Distributions</a><ul><li><a href=#geometric-distribution>Geometric distribution</a></li><li><a href=#multinomial-distribution>Multinomial distribution</a></li><li><a href=#poisson-distribution>Poisson distribution</a></li></ul></li><li><a href=#continuous-distributions>Continuous Distributions</a><ul><li><a href=#gamma>Gamma</a></li><li><a href=#beta>Beta</a></li><li><a href=#t>t</a></li></ul></li><li><a href=#central-limit-theorem>Central Limit Theorem</a></li></ul></nav></div></details></div><div class=post-content><h2 id=bernoulli-and-binomial-distributions><strong>Bernoulli and binomial distributions</strong><a hidden class=anchor aria-hidden=true href=#bernoulli-and-binomial-distributions>#</a></h2><p><strong>Bernoulli distribution</strong> is used when we have <strong>two possible outcomes</strong>, such as flipping a coin, whereÂ it could be heads and tails, or the cases where we have a success or a failure.</p><p>$X \sim B(p)$ : A random variable $X$ follows a Bernoulli distribution with probability $p$, where $p$ is probability of success, or probability of heads.</p><p>è¿™é‡Œç”¨ <strong>Indicator Function</strong> è¡¨ç¤º$x$ å–å€¼ä¸º0,1 çš„æƒ…å†µ</p><p>$$
\begin{align*}
f(X=x \mid p) &= f(x \mid p) \newline
&= p^x(1-p)^{1-x} I_{{x \in {0,1} }}(x) \newline
\end{align*}
$$</p><blockquote><p>ã€ŒChatGPT-3.5ã€
The indicator function, also referred to as the characteristic function, is a mathematical construct used to <strong>represent whether a certain condition is satisfied or not.</strong> It is commonly denoted by symbols such as <code>I</code> or <code>1</code>. The indicator function takes an element from a set and outputs either 1 or 0, depending on whether the element meets a specified condition.</p><p>In formal terms, for a set <code>A</code> and an element <code>x</code>, the indicator function <code>I_A(x)</code> is defined as:</p><p>$$
\begin{align*}
I_A(x) =
\begin{cases}
1 & \text{if $x \in A$ (x belongs to $A$) } \newline
0 & \text{if $x \notin A$ (x does not belong to $A$) }
\end{cases}
\end{align*}
$$</p><p>In simpler words, the indicator function serves as a way to &ldquo;indicate&rdquo; whether an element is part of a set (condition is true) or not (condition is false).</p><p>Indicator functions find applications in various mathematical fields, including probability theory, statistics, and analysis. They are used to express events, define indicator variables, calculate expected values, and simplify mathematical expressions involving conditions or events.</p></blockquote><blockquote><p>In some textbooks, they make a strong distinction between <strong>discrete variables</strong> where these were <em><strong>probably mass functions</strong></em>, and <strong>continues variables</strong> where these are <em><strong>probability density functions</strong></em>.</p></blockquote><p><strong>Bernoulli distribution</strong>çš„æœŸæœ›å’Œæ–¹å·®</p><p>$$
\begin{align*}
E(X) &= \sum_{x} x \cdot P(X=x) \newline
&= 1 \cdot p + 0 \cdot (1-p) \newline
&= p
\end{align*}
$$</p><p>$$
\begin{align*}
Var(X) &= \sum_{x} (x- E(x))^2 \cdot P(X=x) \newline
&= (1-p)^2 \cdot p + (0-p)^2 \cdot (1-p) \newline
&= p(1-p)
\end{align*}
$$</p><p>The generalization of the Bernoulli when we have <em><strong>N repeated trials</strong></em> is a <strong>Binomial</strong>. $X \sim Bin(n,p)$</p><p>$$
P(X = x \mid p) = \binom{n}{x} p^x (1 - p)^{n - x} \newline
\binom{n}{x} = \frac{n!}{x!(n-x)!} ; \text{for $x \in { 0,1,&mldr;,n } $}
$$</p><p>æœŸæœ›å’Œæ–¹å·®ï¼š$E(X)=np, ; Var(X)=np(1-p)$</p><h2 id=uniform-distribution>Uniform distribution<a hidden class=anchor aria-hidden=true href=#uniform-distribution>#</a></h2><p>We can define a continuous random variable based on its <strong>probability density function</strong>(<strong>PDF</strong>).</p><p>ä»¥Uniform distributionä¸ºä¾‹ï¼Œ $X \sim U(0,1)$</p><p>$$
\begin{align*}
f(x) &=
\begin{cases}
1 & x \in [0,1] \newline
0 & \text{otherwise}
\end{cases} \newline
&= I_{{0 \leq x \leq 1}}(x)
\end{align*}
$$</p><p><img loading=lazy src=Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled.png alt=Untitled></p><ul><li><p>Python ç”Ÿæˆ $U(0,1)$ PDF</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># FROM ChatGPT-3.5</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1000</span><span class=p>)</span>  <span class=c1># åˆ›å»ºä¸€ä¸ªæ¨ªåæ ‡èŒƒå›´ä»0åˆ°1çš„æ•°æ®ç‚¹</span>
</span></span><span class=line><span class=cl><span class=n>y</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>ones_like</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>  <span class=c1># æ¯ä¸ªæ•°æ®ç‚¹çš„çºµåæ ‡å€¼éƒ½æ˜¯1ï¼Œå› ä¸ºåœ¨U(0,1)å‡åŒ€åˆ†å¸ƒä¸­æ¦‚ç‡å¯†åº¦æ˜¯å¸¸æ•°</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=p>,</span> <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;blue&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;x&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;$f(x)$&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;$X \sim U(0,1)$&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># è®¾ç½®çºµè½´ä¸Šé™ä¸º1.1</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>set_ylim</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mf>1.25</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># å»é™¤ä¸Šè¾¹æ¡†å’Œå³è¾¹æ¡†</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;top&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># ç»˜åˆ¶å‚ç›´çº¿æ®µ</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>([</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;gray&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;dashed&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;gray&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;dashed&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div></li></ul><p>$$
P(0&lt;x&lt; \frac{1}{2})=\int_{0}^{\frac{1}{2}} f(x) , dx=\frac{1}{2}=P(0 \leq x \leq \frac{1}{2}) \newline
P(x=\frac{1}{2})=0
$$</p><p>Some key rules for probability density functions: $\int_{-\infty}^{\infty} f(x) , dx=1$ï¼›$f(x) \geq 0$</p><p>é€šç”¨å‹Uniform distributionï¼Œ$X \sim U(\theta_1,\theta_2)$ â‡’ $f(x|\theta_1,\theta_2)=\frac{1}{\theta_2-\theta_1}I_{{\theta_1 \leq x \leq \theta_2 }}(x)$</p><p>å…³äºè¿ç»­å‹éšæœºå˜é‡çš„æœŸæœ› the expected value for a continuous random variable</p><p>$$
\begin{align*}
& E(X)=\int_{-\infty}^{\infty} x f(x) , dx \newline
& E(g(X))=\int g(x)f(x) , dx \newline
& E(CX)=cE(x) \text{,$c$ä¸ºå¸¸æ•°} \newline
& E(X+Y) = E(X) + E(Y) \newline
& \text{if $X \perp Y$, } E(XY)=E(X)E(Y)
\end{align*}
$$</p><h2 id=exponential-and-normal-distributions><strong>Exponential and normal distributions</strong><a hidden class=anchor aria-hidden=true href=#exponential-and-normal-distributions>#</a></h2><h3 id=exponential-distribution>Exponential distribution<a hidden class=anchor aria-hidden=true href=#exponential-distribution>#</a></h3><blockquote><p>ã€ŒChatGPT-3.5ã€</p><p>The <strong>Exponential distribution</strong> is a mathematical model often used to <strong>describe the time</strong> <em>between events in situations</em> where <em>events occur randomly and independently at a constant average rate.</em> It&rsquo;s commonly used in fields like queuing theory, reliability analysis, and telecommunications.</p><p>Key points about the Exponential distribution:</p><ul><li><strong>Probability Density Function (PDF)</strong>: The distribution is defined by the equation ( $f(x | \lambda) = \lambda e^{-\lambda x} ï¼Œ\text{for $x \geq 0$}$ ), where ($x$) is the time between events, and ($\lambda$) is the rate parameter.</li><li><strong>Memorylessness</strong>: It has the property that the <strong>probability</strong> of <em>an event occurring in a given interval</em> is <strong>not influenced by the past</strong>. This means that the distribution of time until the next event remains the same, <em><strong>regardless of</strong> how much time has already passed.</em></li><li><strong>Cumulative Distribution Function (CDF)</strong>: The CDF is ( $F(x | \lambda) = 1 - e^{-\lambda x}$Â ), which provides the probability that an event will occur <em>before a certain time</em> ($x$).</li><li><strong>Mean and Variance</strong>: The mean (average) time between events is ($1/\lambda$), and the variance is ($1/\lambda^2$).</li></ul><p>The Exponential distribution is widely used due to its simplicity and relevance in modeling various real-world scenarios involving random occurrences over time.</p></blockquote><p><img loading=lazy src=Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%201.png alt=Untitled></p><ul><li><p>code</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>scipy.stats</span> <span class=k>as</span> <span class=nn>stats</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Parameters for the exponential distributions (rate)</span>
</span></span><span class=line><span class=cl><span class=n>params</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mf>0.5</span><span class=p>,</span> <span class=s1>&#39;Î»=0.5&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=s1>&#39;Î»=1&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=s1>&#39;Î»=2&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Create a figure and axis</span>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=p>,</span> <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Plotting</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>lambd</span><span class=p>,</span> <span class=n>label</span> <span class=ow>in</span> <span class=n>params</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>lambd</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=o>-</span><span class=n>lambd</span> <span class=o>*</span> <span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=c1>#y = stats.expon(scale=1/lambd).pdf(x)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=n>label</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;x&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;Probability Density&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;Exponential Distribution&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># å»é™¤ä¸Šè¾¹æ¡†å’Œå³è¾¹æ¡†</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;top&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Display the plot</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div></li></ul><h3 id=normal-distribution>Normal distribution<a hidden class=anchor aria-hidden=true href=#normal-distribution>#</a></h3><blockquote><p>ã€ŒChatGPT-3.5ã€</p><p>The <strong>Normal distribution</strong>, also known as the Gaussian distribution, is a bell-shaped curve that describes the distribution of many types of data. It is symmetrical and its mean, median, and mode are all equal.</p><p>Key points:</p><ul><li><strong>Bell-shaped</strong>: Its graph is a symmetrical bell-shaped curve.</li><li><strong>Parameters</strong>: It is defined by two parameters: the mean ($\mu$) and the standard deviation ($\sigma$).</li><li><strong>68-95-99.7 Rule</strong>: About 68% of the data falls within one standard deviation of the mean, 95% within two standard deviations, and 99.7% within three.</li><li><strong>Applications</strong>: It&rsquo;s widely used in statistics, science, and engineering due to many natural phenomena and processes being approximately normally distributed.</li></ul><p>The formula for its probability density function (PDF) is:</p><p>$$
f(x | \mu, \sigma) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}
$$</p><p>However, for many practical applications, understanding its bell shape and the 68-95-99.7 rule is often more crucial than knowing its exact formula.</p></blockquote><p><img loading=lazy src=Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%202.png alt=Untitled></p><ul><li><p>code</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>scipy.stats</span> <span class=k>as</span> <span class=nn>stats</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Parameters for the normal distributions</span>
</span></span><span class=line><span class=cl><span class=n>params</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=s1>&#39;$\mu=0, \sigma=1$&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>,</span> <span class=s1>&#39;$\mu=2, \sigma=0.5$&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=o>-</span><span class=mi>2</span><span class=p>,</span> <span class=mf>2.5</span><span class=p>,</span> <span class=s1>&#39;$\mu=-2, \sigma=2.5$&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=p>,</span> <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>mu</span><span class=p>,</span> <span class=n>sigma</span><span class=p>,</span> <span class=n>label</span> <span class=ow>in</span> <span class=n>params</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=n>mu</span> <span class=o>-</span> <span class=mi>3</span><span class=o>*</span><span class=n>sigma</span><span class=p>,</span> <span class=n>mu</span> <span class=o>+</span> <span class=mi>3</span><span class=o>*</span><span class=n>sigma</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>norm</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>mu</span><span class=p>,</span> <span class=n>sigma</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=n>label</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># å»é™¤ä¸Šè¾¹æ¡†å’Œå³è¾¹æ¡†</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;top&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;x&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Probability Density&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Normal Distribution&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div></li></ul><h2 id=supplementary-material-for-lesson-3><strong>Supplementary material for Lesson 3</strong><a hidden class=anchor aria-hidden=true href=#supplementary-material-for-lesson-3>#</a></h2><p><a href="https://d3c33hcgiwev3.cloudfront.net/_29f7eaaba3ac0d35ee74f8bd61aafc39_L3_supp.pdf?Expires=1692144000&amp;Signature=KA2KF0vx3gwhBdV~Qp1XAF3vmfziOf~pLoeyXkGI1sDGXz5P33eynAVVDQoyGfg3mFzxs0Jil10bamlf2z6rm8fb3cqMK7mVH5D~BjvT-W0MxKqjKUKvJsiiq6g1u23yDIWzSOxb39qZp1ISLzVL27Pqkdb6YgaqxrjsxaFAaOE_&amp;Key-Pair-Id=APKAJLTNE6QMUY6HBC5A">https://d3c33hcgiwev3.cloudfront.net/<em>29f7eaaba3ac0d35ee74f8bd61aafc39_L3_supp.pdf?Expires=1692144000&amp;Signature=KA2KF0vx3gwhBdV~Qp1XAF3vmfziOf~pLoeyXkGI1sDGXz5P33eynAVVDQoyGfg3mFzxs0Jil10bamlf2z6rm8fb3cqMK7mVH5D~BjvT-W0MxKqjKUKvJsiiq6g1u23yDIWzSOxb39qZp1ISLzVL27Pqkdb6YgaqxrjsxaFAaOE</em>&amp;Key-Pair-Id=APKAJLTNE6QMUY6HBC5A</a></p><h2 id=additional-discrete-distributions>Additional Discrete Distributions<a hidden class=anchor aria-hidden=true href=#additional-discrete-distributions>#</a></h2><h3 id=geometric-distribution>Geometric distribution<a hidden class=anchor aria-hidden=true href=#geometric-distribution>#</a></h3><p>The geometric distribution is <em><strong>the number of trials</strong></em> needed to get the first success, i.e., the number of Bernoulli events until a success is observed, such as the first head when flipping a coin. It takes values on the positive integers starting with one (since at least one trial is needed to observe a success).</p><p>$$
X \sim Geo(p) \newline
P(X=x|p)=p(1-p)^{x-1} \text{for $x=1,2,&mldr;$} \newline
E(X)=\frac{1}{p}
$$</p><p>If the probability of getting a success is $p$, then the expected number of trials until the first
success is $\frac{1}{p}$.</p><p>ğŸŒ° <strong>Example</strong>: What is the probability that we flip a fair coin four times and donâ€™t see any heads?
This is the same as asking what is $P(X > 4)$ where $X \sim Geo(1/2)$ .</p><p>$$
\begin{align*}
P(X>4) &= 1-P(X=1)-P(X=2)-P(X=3)-p(X=4) \newline
&=1-\frac{1}{2}-\frac{1}{2} (\frac{1}{2})-\frac{1}{2} (\frac{1}{2})^2-\frac{1}{2} (\frac{1}{2})^3 \newline
&= \frac{1}{16}
\end{align*}
$$</p><p><img loading=lazy src=Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%203.png alt=Untitled></p><ul><li><p>code</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>scipy.stats</span> <span class=kn>import</span> <span class=n>geom</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Parameters for the geometric distribution</span>
</span></span><span class=line><span class=cl><span class=n>params</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mf>0.3</span><span class=p>,</span> <span class=s1>&#39;$p=0.3$&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mf>0.5</span><span class=p>,</span> <span class=s1>&#39;$p=0.5$&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mf>0.7</span><span class=p>,</span> <span class=s1>&#39;$p=0.7$&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=p>,</span> <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>p</span><span class=p>,</span> <span class=n>label</span> <span class=ow>in</span> <span class=n>params</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>16</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>geom</span><span class=o>.</span><span class=n>pmf</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>p</span><span class=p>)</span>   <span class=c1># Probability mass function</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>marker</span><span class=o>=</span><span class=s1>&#39;o&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;-&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=n>label</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Remove top and right borders</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;top&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Number of Trials&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Probability&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Geometric Distribution&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div></li></ul><h3 id=multinomial-distribution>Multinomial distribution<a hidden class=anchor aria-hidden=true href=#multinomial-distribution>#</a></h3><p>Another generalization of the Bernoulli and the binomial is the <em><strong>multinomial distribution</strong></em>, which is <em><strong>like a binomial</strong></em> when there are <em><strong>more than two possible outcomes</strong></em>.</p><p>Suppose we have $n$ trials and there are $k$ different possible outcomes which occur with probabilities $p_1,p_2,&mldr;,p_k$ .</p><p>For example, we are rolling a six-sided die that might be loaded so that the sides are not equally likely, then $n$ is the total number of rolls, $k=6$, $p_1$ is the probability of rolling a one, and we denote by $x_1,&mldr;,x_6$ a possible outcome for <strong>the number of times</strong> we observe rolls of each of one through six, where $\sum\limits_{i=1}^{6}x_i=n \text{ and } \sum\limits_{i=1}^{6}p_i=1$.</p><p>$$
f(x_1,\dots ,x_k|p_1,\dots ,p_k)=\frac{n!}{x_1!\dots x_k !}p_1^{x_1}\dots p_k^{x_k}
$$</p><p><img loading=lazy src=Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%204.png alt=Untitled></p><ul><li><p>æ¨¡æ‹Ÿcode</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>scipy.stats</span> <span class=kn>import</span> <span class=n>multinomial</span>
</span></span><span class=line><span class=cl><span class=c1># set seed for reproductibility</span>
</span></span><span class=line><span class=cl><span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>999</span><span class=p>)</span> 
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Parameters for the multinomial distribution</span>
</span></span><span class=line><span class=cl><span class=n>k</span> <span class=o>=</span> <span class=mi>3</span>
</span></span><span class=line><span class=cl><span class=n>n</span> <span class=o>=</span> <span class=mi>12</span> <span class=c1># number of trials (games in one tourment)</span>
</span></span><span class=line><span class=cl><span class=n>pvals</span> <span class=o>=</span> <span class=p>[</span><span class=mf>0.4</span><span class=p>,</span> <span class=mf>0.35</span><span class=p>,</span> <span class=mf>0.25</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>sizes</span> <span class=o>=</span><span class=p>[]</span> <span class=c1># number of tournments played</span>
</span></span><span class=line><span class=cl><span class=n>p</span> <span class=o>=</span> <span class=p>[]</span>    <span class=c1># a list to hold ratios (converge to prob) that player 1 wins 7 times, player 2 wins 2 times and 3 ties</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># å…¬å¼è®¡ç®—</span>
</span></span><span class=line><span class=cl><span class=n>f_x</span> <span class=o>=</span> <span class=nb>round</span><span class=p>(</span><span class=n>multinomial</span><span class=o>.</span><span class=n>pmf</span><span class=p>([</span><span class=mi>7</span><span class=p>,</span><span class=mi>2</span><span class=p>,</span><span class=mi>3</span><span class=p>],</span><span class=n>n</span><span class=o>=</span><span class=n>n</span><span class=p>,</span><span class=n>p</span><span class=o>=</span><span class=n>pvals</span><span class=p>),</span><span class=mi>4</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># æ¨¡æ‹Ÿ</span>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=p>,</span> <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>4</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>size</span> <span class=ow>in</span> <span class=n>np</span><span class=o>.</span><span class=n>logspace</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span><span class=mi>4</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># the line below is where we actually generate discrete random variables according the multinomial distribution</span>
</span></span><span class=line><span class=cl>    <span class=n>outcomes</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>multinomial</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=n>pvals</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=nb>int</span><span class=p>(</span><span class=n>size</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># let&#39;s count the ratio of the expected outcome over all the outcomes - this will lastly converge to the probability</span>
</span></span><span class=line><span class=cl>    <span class=n>prob</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>((</span><span class=n>outcomes</span><span class=p>[:,</span><span class=mi>0</span><span class=p>]</span><span class=o>==</span><span class=mi>7</span><span class=p>)</span><span class=o>&amp;</span><span class=p>(</span><span class=n>outcomes</span><span class=p>[:,</span><span class=mi>1</span><span class=p>]</span><span class=o>==</span><span class=mi>2</span><span class=p>)</span><span class=o>&amp;</span><span class=p>(</span><span class=n>outcomes</span><span class=p>[:,</span><span class=mi>2</span><span class=p>]</span><span class=o>==</span><span class=mi>3</span><span class=p>))</span><span class=o>/</span><span class=nb>len</span><span class=p>(</span><span class=n>outcomes</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>p</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>prob</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>sizes</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=nb>int</span><span class=p>(</span><span class=n>size</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>sizes</span><span class=p>,</span><span class=n>p</span><span class=p>,</span><span class=s1>&#39;o-&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>sizes</span><span class=p>,[</span><span class=n>f_x</span><span class=p>]</span><span class=o>*</span><span class=nb>len</span><span class=p>(</span><span class=n>sizes</span><span class=p>),</span><span class=s1>&#39;--r&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>line1</span> <span class=o>=</span> <span class=sa>r</span><span class=s2>&#34;$p_1,p_2,p_3=(0.4, 0.35, 0.25)$&#34;</span>  <span class=c1># æ–‡æœ¬å†…å®¹</span>
</span></span><span class=line><span class=cl><span class=n>line2</span> <span class=o>=</span> <span class=sa>r</span><span class=s2>&#34;$x_1,x_2,x_3=(7,2,3)$&#34;</span>  <span class=c1># æ–‡æœ¬å†…å®¹</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>x_pos</span> <span class=o>=</span> <span class=mf>0.95</span>  <span class=c1># x åæ ‡ä½ç½®ï¼ˆç›¸å¯¹äºè½´èŒƒå›´çš„æ¯”ä¾‹ï¼‰</span>
</span></span><span class=line><span class=cl><span class=n>y_pos</span> <span class=o>=</span> <span class=mf>0.95</span>  <span class=c1># y åæ ‡ä½ç½®ï¼ˆç›¸å¯¹äºè½´èŒƒå›´çš„æ¯”ä¾‹ï¼‰</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>text</span><span class=p>(</span><span class=n>x_pos</span><span class=p>,</span> <span class=n>y_pos</span><span class=p>,</span> <span class=n>line2</span><span class=o>+</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>&#34;</span><span class=o>+</span><span class=n>line1</span><span class=p>,</span> <span class=n>transform</span><span class=o>=</span><span class=n>ax</span><span class=o>.</span><span class=n>transAxes</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>12</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>ha</span><span class=o>=</span><span class=s1>&#39;right&#39;</span><span class=p>,</span> <span class=n>va</span><span class=o>=</span><span class=s1>&#39;top&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># Remove top and right borders</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;top&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlim</span><span class=p>(</span><span class=n>xmin</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Number of Drawings&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;$p(x_1,x_2,x_3|p_1,p_2,p_3)$&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Theoretical $f(x_1,x_2,x_3|p_1,p_2,p_3)=</span><span class=si>{}</span><span class=s1>$&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>f_x</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#plt.grid(True)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div></li></ul><h3 id=poisson-distribution>Poisson distribution<a hidden class=anchor aria-hidden=true href=#poisson-distribution>#</a></h3><p>The Poisson distribution is used for counts, and arises in a variety of situations. The parameter $\lambda > 0$ is the <em><strong>rate</strong></em> at which we expect to observe the thing we are counting.</p><p>$$
X \sim Pois(\lambda) \newline
P(X=x|\lambda)=\frac{\lambda^xexp(- \lambda)}{x!} \text{ for $x=0,1,2,\dots$} \newline
E(X)=\lambda \newline
Var(X) =\lambda
$$</p><p>ğŸŒ° <strong>Example</strong>: Significant earthquakes occur in the Western United States approximately following a Poisson process with rate of two earthquakes per week. What is the probability there will be at least 3 earthquakes in the next two weeks?</p><p>æœªæ¥ä¸¤å‘¨å‘ç”Ÿåœ°éœ‡çš„æ¬¡æ•°è®°ä¸º$X$ï¼Œç”±é¢˜æ„å¾—ï¼Œ$X \sim Pois(4)$.</p><p>$$
\begin{align*}
P(X\geq 3) &= 1-P(X\leq2) \newline
&=1- P(X=0)- P(X=1)- P(X=2) \newline
&=1 - \frac{4^0 exp(- 4)}{0!} -\frac{4^1 exp(- 4)}{1!} - \frac{4^2 exp(- 4)}{2!} \newline
&= 1-13e^{-4} \newline
&=0.762
\end{align*}
$$</p><h2 id=continuous-distributions>Continuous Distributions<a hidden class=anchor aria-hidden=true href=#continuous-distributions>#</a></h2><h3 id=gamma>Gamma<a hidden class=anchor aria-hidden=true href=#gamma>#</a></h3><p>If $X_1,X_2,\dots,X_n$ are independent (and identically distributed $Exp(\lambda)$) <em><strong>waiting times</strong></em> between successive events, then the total waiting time for all n events to occur $Y=\sum_{i=1}^{n}X_i$ will follow a gamma distribution with shape parameter $\alpha=n$ and rate parameter $\beta=\lambda$.</p><p>$$
Y \sim Gamma(\alpha,\beta) \newline
f(y|\alpha,\beta)=\frac{\beta^\alpha}{\Gamma(\alpha)}y^{\alpha-1}e^{-\beta y}I_{ {y \geq0}}(y) \newline
E(Y) = \frac{\alpha}{\beta} \newline
Var(Y) = \frac{\alpha}{\beta^2}
$$</p><p>where $\Gamma(Â·)$ is the gamma function, a generalization of the factorial function which can accept non-integer arguments. If $n$ is a positive integer, then $\Gamma(n) = (n âˆ’ 1)!$ . Note also that $\alpha> 0$ and $\beta > 0$ .</p><p>The exponential distribution is a special case of the gamma distribution with $\alpha = 1$. The gamma distribution commonly appears in statistical problems, as we will see in this course. It is used to model positive-valued, continuous quantities whose distribution is right-skewed. As $\alpha$ increases, the gamma distribution more closely resembles the normal distribution.</p><p><img loading=lazy src=Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%205.png alt=Untitled></p><ul><li><p>code</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>scipy.stats</span> <span class=kn>import</span> <span class=n>gamma</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Parameters for the gamma distribution</span>
</span></span><span class=line><span class=cl><span class=n>params</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>,</span> <span class=s1>&#39;$</span><span class=se>\\</span><span class=s1>alpha=1, </span><span class=se>\\</span><span class=s1>beta=0.5$&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=s1>&#39;$</span><span class=se>\\</span><span class=s1>alpha=5, </span><span class=se>\\</span><span class=s1>beta=1$&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mi>8</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=s1>&#39;$</span><span class=se>\\</span><span class=s1>alpha=8, </span><span class=se>\\</span><span class=s1>beta=2$&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=p>,</span> <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>alpha</span><span class=p>,</span> <span class=n>beta</span><span class=p>,</span> <span class=n>label</span> <span class=ow>in</span> <span class=n>params</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=n>gamma</span><span class=o>.</span><span class=n>ppf</span><span class=p>(</span><span class=mf>0.001</span><span class=p>,</span> <span class=n>alpha</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mi>1</span><span class=o>/</span><span class=n>beta</span><span class=p>),</span> <span class=n>gamma</span><span class=o>.</span><span class=n>ppf</span><span class=p>(</span><span class=mf>0.999</span><span class=p>,</span> <span class=n>alpha</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mi>1</span><span class=o>/</span><span class=n>beta</span><span class=p>),</span> <span class=mi>100</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>gamma</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>alpha</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mi>1</span><span class=o>/</span><span class=n>beta</span><span class=p>)</span>   <span class=c1># Probability density function</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;-&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=n>label</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Remove top and right borders</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;top&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;X&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Probability Density&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Gamma Distribution&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div></li></ul><h3 id=beta>Beta<a hidden class=anchor aria-hidden=true href=#beta>#</a></h3><p>The beta distribution is used for random variables which <strong>take on values between 0 and 1</strong>. For this reason (and other reasons we will see later in the course), the beta distribution is commonly used to model probabilities</p><p>$$
X \sim Beta(\alpha,\beta) \newline
f(x|\alpha,\beta)=\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha-1}(1-x)^{\beta -1}I_{ {0&lt;x&lt;1}}(x) \newline
E(X) = \frac{\alpha}{\alpha + \beta} \newline
Var(X) = \frac{\alpha \beta}{(\alpha+\beta)^2(\alpha+\beta+1)}
$$</p><p>where $\Gamma(Â·)$ is the gamma function introduced with the gamma distribution. Note also that $\alpha> 0$ and $\beta > 0$ . The standard Uniform(0, 1) distribution is a special case of the betadistribution with $\alpha=\beta=1$ .</p><p><img loading=lazy src=Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%206.png alt=Untitled></p><ul><li><p>code</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>scipy.stats</span> <span class=kn>import</span> <span class=n>beta</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Parameters for the Beta distribution</span>
</span></span><span class=line><span class=cl><span class=n>params</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=s1>&#39;$</span><span class=se>\\</span><span class=s1>alpha=2, </span><span class=se>\\</span><span class=s1>beta=5$&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=s1>&#39;$</span><span class=se>\\</span><span class=s1>alpha=5, </span><span class=se>\\</span><span class=s1>beta=1$&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=s1>&#39;$</span><span class=se>\\</span><span class=s1>alpha=2, </span><span class=se>\\</span><span class=s1>beta=2$&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=p>,</span> <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>,</span> <span class=n>label</span> <span class=ow>in</span> <span class=n>params</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>beta</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>)</span>   <span class=c1># Probability density function</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=n>label</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Remove top and right borders</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;top&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Value&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Probability Density&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Beta Distribution&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div></li></ul><h3 id=t>t<a hidden class=anchor aria-hidden=true href=#t>#</a></h3><p>If we have normal data, we can use $\bar{X} \sim N(\mu,\frac{\sigma^2}{n})$ to help us estimate the mean $\mu$. æ ‡å‡†æ­£æ€åˆ†å¸ƒï¼š $\frac{\bar{X} - \mu}{\sigma/ \sqrt{n}} \sim N(0,1)$. However, we may not know the value of $\sigma$. If we estimate it from data, we can replace it with $S=\sqrt{\sum_i(X_i - \bar{X})^2/(n-1)}$ , the sample standard deviation. This causes the $\frac{\bar{X} - \mu}{\sigma/ \sqrt{n}}$ to no longer be distributed as standard normal, but as a standard t distribution with $\nu=n-1$ degrees of freedom.</p><p>$$
Y \sim t_{\nu} \newline
f(y) = \frac{\Gamma(\frac{\nu +1}{2})}{\Gamma(\frac{\nu}{2}) \sqrt{\nu \pi}}(1+\frac{y^2}{\nu})^{-(\frac{\nu + 1}{2})} \newline
E(Y) = 0 \text{, if $\nu > 1$ } \newline
Var(Y) = \frac{\nu}{\nu - 2} \text{, if $\nu > 2$}
$$</p><p><img loading=lazy src=Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%207.png alt=Untitled></p><ul><li><p>code</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>scipy.stats</span> <span class=kn>import</span> <span class=n>t</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Parameters for the t distribution</span>
</span></span><span class=line><span class=cl><span class=n>params</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=s1>&#39;$df=2$&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=s1>&#39;$df=5$&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=s1>&#39;$df=10$&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=p>,</span> <span class=n>axes</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Plot probability density function</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;t Distribution - Probability Density Function&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>df</span><span class=p>,</span> <span class=n>label</span> <span class=ow>in</span> <span class=n>params</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=o>-</span><span class=mi>4</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>t</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>df</span><span class=p>)</span>   <span class=c1># Probability density function</span>
</span></span><span class=line><span class=cl>    <span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=n>label</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Plot cumulative distribution function</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;t Distribution - Cumulative Distribution Function&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>df</span><span class=p>,</span> <span class=n>label</span> <span class=ow>in</span> <span class=n>params</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=o>-</span><span class=mi>4</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>t</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>df</span><span class=p>)</span>   <span class=c1># Cumulative distribution function</span>
</span></span><span class=line><span class=cl>    <span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=n>label</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Remove top and right borders</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>ax</span> <span class=ow>in</span> <span class=n>axes</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;top&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;Value&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;Probability Density&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;Value&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;Cumulative Probability&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div></li></ul><blockquote><p>ä½œè€…ï¼šå´ç«¯</p><p>é“¾æ¥ï¼šhttps://www.zhihu.com/question/34866983/answer/1540230125</p><p>æ¥æºï¼šçŸ¥ä¹</p><p>è‘—ä½œæƒå½’ä½œè€…æ‰€æœ‰ã€‚å•†ä¸šè½¬è½½è¯·è”ç³»ä½œè€…è·å¾—æˆæƒï¼Œéå•†ä¸šè½¬è½½è¯·æ³¨æ˜å‡ºå¤„ã€‚</p><p>åˆ†å¸ƒåˆ†ä¸ºç¦»æ•£åˆ†å¸ƒå’Œè¿ç»­åˆ†å¸ƒã€‚è¿ç»­åˆ†å¸ƒå‡ ä¹éƒ½èƒ½æ‰¾åˆ°å¯¹åº”çš„ç¦»æ•£åˆ†å¸ƒã€‚å› ä¸ºè¿ç»­åˆ†å¸ƒæœ¬è´¨ä¸Šå°±æ˜¯æŠŠç¦»æ•£åˆ†å¸ƒä¸­æŠ•ç¡¬å¸çš„æ¬¡æ•°ï¼Œå˜æˆè¿ç»­çš„æ—¶é—´é•¿åº¦ã€‚æŠŠæ¯æ¬¡æŠ•ç¡¬å¸çš„æ­£åé¢æ¦‚ç‡ï¼Œå˜æˆå•ä½æ—¶é—´å†…å‡ºç°æ­£é¢çš„æ¦‚ç‡å¯†åº¦ã€‚</p><p>ä¸‹é¢æˆ‘ä»è´åŠªåˆ©å®éªŒå‡ºå‘ï¼ŒæŠŠæ‰€æœ‰åˆ†å¸ƒçš„å…³ç³»æ¢³ç†å‡ºæ¥ï¼š</p><p>è´åŠªåˆ©å®éªŒï¼šæŠ•ç¡¬å¸ï¼Œæ­£é¢åé¢æ¦‚ç‡åˆ†åˆ«ä¸ºpï¼Œ1-p</p><p>äºŒé¡¹åˆ†å¸ƒï¼šå¦‚æœæŠŠè´åŠªåˆ©å®éªŒè¿ç»­åšnæ¬¡ï¼Œå‡ºç°æ­£é¢çš„æ¬¡æ•°æœä»çš„åˆ†å¸ƒã€‚</p><p>äºŒé¡¹åˆ†å¸ƒçš„æé™ï¼šæ³Šæ¾åˆ†å¸ƒã€‚ç»™å®šæ—¶é—´å†…æ—¶é—´å‘ç”Ÿæ¬¡æ•°çš„åˆ†å¸ƒã€‚</p><p>è´ŸäºŒé¡¹åˆ†å¸ƒï¼šåœ¨è´åŠªåˆ©å®éªŒä¸­ï¼Œå¦‚æœæƒ³è®©æ­£é¢å‡ºç°næ¬¡ï¼Œéœ€è¦åšçš„å®éªŒæ¬¡æ•°çš„åˆ†å¸ƒã€‚</p><p>è´ŸäºŒé¡¹åˆ†å¸ƒçš„æé™ï¼šgammaåˆ†å¸ƒã€‚é—®å¦‚æœæŒ‡å®šäº‹ä»¶å‡ºç°Næ¬¡ï¼Œéœ€è¦ç­‰å¾…çš„æ—¶é—´ã€‚</p><p>äºŒé¡¹åˆ†å¸ƒä¸è´ŸäºŒé¡¹åˆ†å¸ƒçš„å…³ç³»ï¼šäºŒé¡¹åˆ†å¸ƒæ˜¯åœ¨å›ºå®šå®éªŒæ¬¡æ•°æƒ…å†µä¸‹ï¼Œé—®ç»“æœåˆ†å¸ƒã€‚è´ŸäºŒé¡¹åˆ†å¸ƒæ˜¯åœ¨å›ºå®šç»“æœæƒ…å†µä¸‹é—®å®éªŒæ¬¡æ•°åˆ†å¸ƒã€‚ä¸€ä¸ªæ˜¯åœ¨å›ºå®šæŠ•å…¥é—®äº§å‡ºï¼Œä¸€ä¸ªæ˜¯åœ¨å›ºå®šäº§å‡ºä¸‹é—®æŠ•å…¥ã€‚</p><p>å‡ ä½•åˆ†å¸ƒï¼šné‡è´åŠªåˆ©å®éªŒï¼Œæ­£é¢ç¬¬ä¸€æ¬¡å‡ºç°æ—¶çš„å®éªŒæ¬¡æ•°ã€‚</p><p>å‡ ä½•åˆ†å¸ƒçš„æé™ï¼šæŒ‡æ•°åˆ†å¸ƒã€‚äº‹ä»¶ç¬¬ä¸€æ¬¡å‘ç”Ÿç­‰å¾…çš„æ—¶é—´ã€‚</p><p>å‡ ä½•åˆ†å¸ƒä¸è´ŸäºŒé¡¹åˆ†å¸ƒçš„å…³ç³»ï¼šè´ŸäºŒé¡¹åˆ†å¸ƒæ˜¯Nä¸ªå‡ ä½•åˆ†å¸ƒçš„å’Œã€‚ç›¸å½“äºåšNæ¬¡å‡ ä½•åˆ†å¸ƒï¼Œäº‹ä»¶æ­£å¥½å‘ç”ŸNæ¬¡ã€‚å„å‡ ä½•åˆ†å¸ƒçš„å®éªŒæ¬¡æ•°ä¹‹å’Œå°±æ˜¯è´ŸäºŒé¡¹åˆ†å¸ƒçš„æ€»æ¬¡æ•°ã€‚</p><p>æŒ‡æ•°åˆ†å¸ƒä¸gammaåˆ†å¸ƒçš„å…³ç³»ï¼šNæ¬¡æŒ‡æ•°åˆ†å¸ƒæ—¶é—´ä¹‹å’Œå°±æ˜¯gammaåˆ†å¸ƒä¸­äº‹ä»¶å‘ç”ŸNæ¬¡ç­‰å¾…æ€»æ—¶é—´ã€‚</p><p>å¦‚æœè¯¾æœ¬èƒ½è¿™æ ·ç»„ç»‡è¿™äº›çŸ¥è¯†ï¼Œä¼°è®¡ä¹Ÿæ²¡æœ‰äººå›°æƒ‘ä¸ºå•¥æ•´è¿™ä¹ˆå¤šå¥‡æ€ªçš„åˆ†å¸ƒï¼Œåˆ°åº•æœ‰ä»€ä¹ˆç”¨ã€‚æ¨å€’è¿‡ç¨‹åè€Œæ²¡é‚£ä¹ˆé‡è¦</p></blockquote><h2 id=central-limit-theorem>Central Limit Theorem<a hidden class=anchor aria-hidden=true href=#central-limit-theorem>#</a></h2><p>The Central Limit Theorem is one of the most important results in statistics, basically saying
that with sufficiently large sample sizes, <em><strong>the sample average</strong></em> approximately follows a normal
distribution.</p><p>In formal mathematical notation, the Central Limit Theorem says: Let $X_1,\dots ,X_n$ be independent and identically distributed with $E(X_i)=\mu \text{ and } Var(X_i)= \sigma^2,0 &lt; \sigma^2 &lt; \infty$, then,</p><p>$$
\frac{\sqrt{n}(\bar{X}-\mu)}{\sigma} \sim N(0,1)
$$</p><p><img loading=lazy src=Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%208.png alt=Untitled></p><p>$$
\varphi = 1+\frac{1} {1+\frac{1} {1+\frac{1} {1+\cdots} } }
$$</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://unclehuzi.github.io/tags/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/>è¯¾ç¨‹ç¬”è®°</a></li><li><a href=https://unclehuzi.github.io/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF/>è´å¶æ–¯</a></li><li><a href=https://unclehuzi.github.io/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6/>ç»Ÿè®¡å­¦</a></li></ul><nav class=paginav><a class=prev href=https://unclehuzi.github.io/posts/python-macos_install_anaconda_by_homebrew/><span class=title>Â« Prev</span><br><span>macOSé€šè¿‡homebrewå®‰è£…anaconda</span></a>
<a class=next href=https://unclehuzi.github.io/posts/da-bayesian_statistics-coursera-from_concept_to_data_analysis/><span class=title>Next Â»</span><br><span>courseraè¯¾ç¨‹-Probability and Bayesâ€™ Theorem</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share courseraè¯¾ç¨‹-Review of distributions on x" href="https://x.com/intent/tweet/?text=coursera%e8%af%be%e7%a8%8b-Review%20of%20distributions&amp;url=https%3a%2f%2funclehuzi.github.io%2fposts%2fda-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions%2f&amp;hashtags=%e8%af%be%e7%a8%8b%e7%ac%94%e8%ae%b0%2c%e8%b4%9d%e5%8f%b6%e6%96%af%2c%e7%bb%9f%e8%ae%a1%e5%ad%a6"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share courseraè¯¾ç¨‹-Review of distributions on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2funclehuzi.github.io%2fposts%2fda-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions%2f&amp;title=coursera%e8%af%be%e7%a8%8b-Review%20of%20distributions&amp;summary=coursera%e8%af%be%e7%a8%8b-Review%20of%20distributions&amp;source=https%3a%2f%2funclehuzi.github.io%2fposts%2fda-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share courseraè¯¾ç¨‹-Review of distributions on reddit" href="https://reddit.com/submit?url=https%3a%2f%2funclehuzi.github.io%2fposts%2fda-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions%2f&title=coursera%e8%af%be%e7%a8%8b-Review%20of%20distributions"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share courseraè¯¾ç¨‹-Review of distributions on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2funclehuzi.github.io%2fposts%2fda-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share courseraè¯¾ç¨‹-Review of distributions on whatsapp" href="https://api.whatsapp.com/send?text=coursera%e8%af%be%e7%a8%8b-Review%20of%20distributions%20-%20https%3a%2f%2funclehuzi.github.io%2fposts%2fda-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share courseraè¯¾ç¨‹-Review of distributions on telegram" href="https://telegram.me/share/url?text=coursera%e8%af%be%e7%a8%8b-Review%20of%20distributions&amp;url=https%3a%2f%2funclehuzi.github.io%2fposts%2fda-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share courseraè¯¾ç¨‹-Review of distributions on ycombinator" href="https://news.ycombinator.com/submitlink?t=coursera%e8%af%be%e7%a8%8b-Review%20of%20distributions&u=https%3a%2f%2funclehuzi.github.io%2fposts%2fda-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://unclehuzi.github.io/>H.W.</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>