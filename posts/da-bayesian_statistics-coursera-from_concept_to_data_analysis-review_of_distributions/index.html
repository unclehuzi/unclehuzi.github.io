<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>coursera课程-Review of distributions | H.W.</title><meta name=keywords content="课程笔记,贝叶斯,统计学"><meta name=description content="coursera上贝叶斯统计专项课程"><meta name=author content="胡子叔叔"><link rel=canonical href=https://unclehuzi.github.io/posts/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/><link crossorigin=anonymous href=/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=https://unclehuzi.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://unclehuzi.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://unclehuzi.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://unclehuzi.github.io/apple-touch-icon.png><link rel=mask-icon href=https://unclehuzi.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload=renderMathInElement(document.body)></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-JZ3C49ZSKM"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-JZ3C49ZSKM",{anonymize_ip:!1})}</script><meta property="og:title" content="coursera课程-Review of distributions"><meta property="og:description" content="coursera上贝叶斯统计专项课程"><meta property="og:type" content="article"><meta property="og:url" content="https://unclehuzi.github.io/posts/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/"><meta property="og:image" content="https://unclehuzi.github.io/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-09-03T17:16:55+08:00"><meta property="article:modified_time" content="2023-09-03T17:16:55+08:00"><meta property="og:site_name" content="胡子叔叔的小站"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://unclehuzi.github.io/"><meta name=twitter:title content="coursera课程-Review of distributions"><meta name=twitter:description content="coursera上贝叶斯统计专项课程"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://unclehuzi.github.io/posts/"},{"@type":"ListItem","position":2,"name":"coursera课程-Review of distributions","item":"https://unclehuzi.github.io/posts/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"coursera课程-Review of distributions","name":"coursera课程-Review of distributions","description":"coursera上贝叶斯统计专项课程","keywords":["课程笔记","贝叶斯","统计学"],"articleBody":"Bernoulli and binomial distributions Bernoulli distribution is used when we have two possible outcomes, such as flipping a coin, where it could be heads and tails, or the cases where we have a success or a failure.\n$X \\sim B(p)$ : A random variable $X$ follows a Bernoulli distribution with probability $p$, where $p$ is probability of success, or probability of heads.\n这里用 Indicator Function 表示$x$ 取值为0,1 的情况\n$$ \\begin{align*} f(X=x \\mid p) \u0026= f(x \\mid p) \\newline \u0026= p^x(1-p)^{1-x} I_{{x \\in {0,1} }}(x) \\newline \\end{align*} $$\n「ChatGPT-3.5」 The indicator function, also referred to as the characteristic function, is a mathematical construct used to represent whether a certain condition is satisfied or not. It is commonly denoted by symbols such as I or 1. The indicator function takes an element from a set and outputs either 1 or 0, depending on whether the element meets a specified condition.\nIn formal terms, for a set A and an element x, the indicator function I_A(x) is defined as:\n$$ \\begin{align*} I_A(x) = \\begin{cases} 1 \u0026 \\text{if $x \\in A$ (x belongs to $A$) } \\newline 0 \u0026 \\text{if $x \\notin A$ (x does not belong to $A$) } \\end{cases} \\end{align*} $$\nIn simpler words, the indicator function serves as a way to “indicate” whether an element is part of a set (condition is true) or not (condition is false).\nIndicator functions find applications in various mathematical fields, including probability theory, statistics, and analysis. They are used to express events, define indicator variables, calculate expected values, and simplify mathematical expressions involving conditions or events.\nIn some textbooks, they make a strong distinction between discrete variables where these were probably mass functions, and continues variables where these are probability density functions.\nBernoulli distribution的期望和方差\n$$ \\begin{align*} E(X) \u0026= \\sum_{x} x \\cdot P(X=x) \\newline \u0026= 1 \\cdot p + 0 \\cdot (1-p) \\newline \u0026= p \\end{align*} $$\n$$ \\begin{align*} Var(X) \u0026= \\sum_{x} (x- E(x))^2 \\cdot P(X=x) \\newline \u0026= (1-p)^2 \\cdot p + (0-p)^2 \\cdot (1-p) \\newline \u0026= p(1-p) \\end{align*} $$\nThe generalization of the Bernoulli when we have N repeated trials is a Binomial. $X \\sim Bin(n,p)$\n$$ P(X = x \\mid p) = \\binom{n}{x} p^x (1 - p)^{n - x} \\newline \\binom{n}{x} = \\frac{n!}{x!(n-x)!} ; \\text{for $x \\in { 0,1,…,n } $} $$\n期望和方差：$E(X)=np, ; Var(X)=np(1-p)$\nUniform distribution We can define a continuous random variable based on its probability density function(PDF).\n以Uniform distribution为例， $X \\sim U(0,1)$\n$$ \\begin{align*} f(x) \u0026= \\begin{cases} 1 \u0026 x \\in [0,1] \\newline 0 \u0026 \\text{otherwise} \\end{cases} \\newline \u0026= I_{{0 \\leq x \\leq 1}}(x) \\end{align*} $$\nPython 生成 $U(0,1)$ PDF\n# FROM ChatGPT-3.5 import numpy as np import matplotlib.pyplot as plt x = np.linspace(0, 1, 1000) # 创建一个横坐标范围从0到1的数据点 y = np.ones_like(x) # 每个数据点的纵坐标值都是1，因为在U(0,1)均匀分布中概率密度是常数 fig, ax = plt.subplots() ax.plot(x, y, color='blue') ax.set_xlabel('x') ax.set_ylabel('$f(x)$') ax.set_title('$X \\sim U(0,1)$') # 设置纵轴上限为1.1 ax.set_ylim(0, 1.25) # 去除上边框和右边框 ax.spines['top'].set_visible(False) ax.spines['right'].set_visible(False) # 绘制垂直线段 plt.plot([0, 0], [0, 1], color='gray', linestyle='dashed', linewidth=1) plt.plot([1, 1], [0, 1], color='gray', linestyle='dashed', linewidth=1) plt.show() $$ P(0","wordCount":"2474","inLanguage":"en","datePublished":"2023-09-03T17:16:55+08:00","dateModified":"2023-09-03T17:16:55+08:00","author":{"@type":"Person","name":"胡子叔叔"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://unclehuzi.github.io/posts/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/"},"publisher":{"@type":"Organization","name":"H.W.","logo":{"@type":"ImageObject","url":"https://unclehuzi.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://unclehuzi.github.io/ accesskey=h title="H.W. (Alt + H)">H.W.</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://unclehuzi.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://unclehuzi.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://unclehuzi.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://unclehuzi.github.io/tags/ title=tags><span>tags</span></a></li><li><a href=https://unclehuzi.github.io/about/ title=about><span>about</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://unclehuzi.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://unclehuzi.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">coursera课程-Review of distributions</h1><div class=post-description>coursera上贝叶斯统计专项课程</div><div class=post-meta><span title='2023-09-03 17:16:55 +0800 +0800'>2023-09-03</span>&nbsp;·&nbsp;胡子叔叔</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#bernoulli-and-binomial-distributions><strong>Bernoulli and binomial distributions</strong></a></li><li><a href=#uniform-distribution>Uniform distribution</a></li><li><a href=#exponential-and-normal-distributions><strong>Exponential and normal distributions</strong></a><ul><li><a href=#exponential-distribution>Exponential distribution</a></li><li><a href=#normal-distribution>Normal distribution</a></li></ul></li><li><a href=#supplementary-material-for-lesson-3><strong>Supplementary material for Lesson 3</strong></a></li><li><a href=#additional-discrete-distributions>Additional Discrete Distributions</a><ul><li><a href=#geometric-distribution>Geometric distribution</a></li><li><a href=#multinomial-distribution>Multinomial distribution</a></li><li><a href=#poisson-distribution>Poisson distribution</a></li></ul></li><li><a href=#continuous-distributions>Continuous Distributions</a><ul><li><a href=#gamma>Gamma</a></li><li><a href=#beta>Beta</a></li><li><a href=#t>t</a></li></ul></li><li><a href=#central-limit-theorem>Central Limit Theorem</a></li></ul></nav></div></details></div><div class=post-content><h2 id=bernoulli-and-binomial-distributions><strong>Bernoulli and binomial distributions</strong><a hidden class=anchor aria-hidden=true href=#bernoulli-and-binomial-distributions>#</a></h2><p><strong>Bernoulli distribution</strong> is used when we have <strong>two possible outcomes</strong>, such as flipping a coin, where it could be heads and tails, or the cases where we have a success or a failure.</p><p>$X \sim B(p)$ : A random variable $X$ follows a Bernoulli distribution with probability $p$, where $p$ is probability of success, or probability of heads.</p><p>这里用 <strong>Indicator Function</strong> 表示$x$ 取值为0,1 的情况</p><p>$$
\begin{align*}
f(X=x \mid p) &= f(x \mid p) \newline
&= p^x(1-p)^{1-x} I_{{x \in {0,1} }}(x) \newline
\end{align*}
$$</p><blockquote><p>「ChatGPT-3.5」
The indicator function, also referred to as the characteristic function, is a mathematical construct used to <strong>represent whether a certain condition is satisfied or not.</strong> It is commonly denoted by symbols such as <code>I</code> or <code>1</code>. The indicator function takes an element from a set and outputs either 1 or 0, depending on whether the element meets a specified condition.</p><p>In formal terms, for a set <code>A</code> and an element <code>x</code>, the indicator function <code>I_A(x)</code> is defined as:</p><p>$$
\begin{align*}
I_A(x) =
\begin{cases}
1 & \text{if $x \in A$ (x belongs to $A$) } \newline
0 & \text{if $x \notin A$ (x does not belong to $A$) }
\end{cases}
\end{align*}
$$</p><p>In simpler words, the indicator function serves as a way to &ldquo;indicate&rdquo; whether an element is part of a set (condition is true) or not (condition is false).</p><p>Indicator functions find applications in various mathematical fields, including probability theory, statistics, and analysis. They are used to express events, define indicator variables, calculate expected values, and simplify mathematical expressions involving conditions or events.</p></blockquote><blockquote><p>In some textbooks, they make a strong distinction between <strong>discrete variables</strong> where these were <em><strong>probably mass functions</strong></em>, and <strong>continues variables</strong> where these are <em><strong>probability density functions</strong></em>.</p></blockquote><p><strong>Bernoulli distribution</strong>的期望和方差</p><p>$$
\begin{align*}
E(X) &= \sum_{x} x \cdot P(X=x) \newline
&= 1 \cdot p + 0 \cdot (1-p) \newline
&= p
\end{align*}
$$</p><p>$$
\begin{align*}
Var(X) &= \sum_{x} (x- E(x))^2 \cdot P(X=x) \newline
&= (1-p)^2 \cdot p + (0-p)^2 \cdot (1-p) \newline
&= p(1-p)
\end{align*}
$$</p><p>The generalization of the Bernoulli when we have <em><strong>N repeated trials</strong></em> is a <strong>Binomial</strong>. $X \sim Bin(n,p)$</p><p>$$
P(X = x \mid p) = \binom{n}{x} p^x (1 - p)^{n - x} \newline
\binom{n}{x} = \frac{n!}{x!(n-x)!} ; \text{for $x \in { 0,1,&mldr;,n } $}
$$</p><p>期望和方差：$E(X)=np, ; Var(X)=np(1-p)$</p><h2 id=uniform-distribution>Uniform distribution<a hidden class=anchor aria-hidden=true href=#uniform-distribution>#</a></h2><p>We can define a continuous random variable based on its <strong>probability density function</strong>(<strong>PDF</strong>).</p><p>以Uniform distribution为例， $X \sim U(0,1)$</p><p>$$
\begin{align*}
f(x) &=
\begin{cases}
1 & x \in [0,1] \newline
0 & \text{otherwise}
\end{cases} \newline
&= I_{{0 \leq x \leq 1}}(x)
\end{align*}
$$</p><p><img loading=lazy src=Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled.png alt=Untitled></p><ul><li><p>Python 生成 $U(0,1)$ PDF</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># FROM ChatGPT-3.5</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1000</span><span class=p>)</span>  <span class=c1># 创建一个横坐标范围从0到1的数据点</span>
</span></span><span class=line><span class=cl><span class=n>y</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>ones_like</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>  <span class=c1># 每个数据点的纵坐标值都是1，因为在U(0,1)均匀分布中概率密度是常数</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=p>,</span> <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;blue&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;x&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;$f(x)$&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;$X \sim U(0,1)$&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 设置纵轴上限为1.1</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>set_ylim</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mf>1.25</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 去除上边框和右边框</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;top&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 绘制垂直线段</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>([</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;gray&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;dashed&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;gray&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;dashed&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div></li></ul><p>$$
P(0&lt;x&lt; \frac{1}{2})=\int_{0}^{\frac{1}{2}} f(x) , dx=\frac{1}{2}=P(0 \leq x \leq \frac{1}{2}) \newline
P(x=\frac{1}{2})=0
$$</p><p>Some key rules for probability density functions: $\int_{-\infty}^{\infty} f(x) , dx=1$；$f(x) \geq 0$</p><p>通用型Uniform distribution，$X \sim U(\theta_1,\theta_2)$ ⇒ $f(x|\theta_1,\theta_2)=\frac{1}{\theta_2-\theta_1}I_{{\theta_1 \leq x \leq \theta_2 }}(x)$</p><p>关于连续型随机变量的期望 the expected value for a continuous random variable</p><p>$$
\begin{align*}
& E(X)=\int_{-\infty}^{\infty} x f(x) , dx \newline
& E(g(X))=\int g(x)f(x) , dx \newline
& E(CX)=cE(x) \text{,$c$为常数} \newline
& E(X+Y) = E(X) + E(Y) \newline
& \text{if $X \perp Y$, } E(XY)=E(X)E(Y)
\end{align*}
$$</p><h2 id=exponential-and-normal-distributions><strong>Exponential and normal distributions</strong><a hidden class=anchor aria-hidden=true href=#exponential-and-normal-distributions>#</a></h2><h3 id=exponential-distribution>Exponential distribution<a hidden class=anchor aria-hidden=true href=#exponential-distribution>#</a></h3><blockquote><p>「ChatGPT-3.5」</p><p>The <strong>Exponential distribution</strong> is a mathematical model often used to <strong>describe the time</strong> <em>between events in situations</em> where <em>events occur randomly and independently at a constant average rate.</em> It&rsquo;s commonly used in fields like queuing theory, reliability analysis, and telecommunications.</p><p>Key points about the Exponential distribution:</p><ul><li><strong>Probability Density Function (PDF)</strong>: The distribution is defined by the equation ( $f(x | \lambda) = \lambda e^{-\lambda x} ，\text{for $x \geq 0$}$ ), where ($x$) is the time between events, and ($\lambda$) is the rate parameter.</li><li><strong>Memorylessness</strong>: It has the property that the <strong>probability</strong> of <em>an event occurring in a given interval</em> is <strong>not influenced by the past</strong>. This means that the distribution of time until the next event remains the same, <em><strong>regardless of</strong> how much time has already passed.</em></li><li><strong>Cumulative Distribution Function (CDF)</strong>: The CDF is ( $F(x | \lambda) = 1 - e^{-\lambda x}$ ), which provides the probability that an event will occur <em>before a certain time</em> ($x$).</li><li><strong>Mean and Variance</strong>: The mean (average) time between events is ($1/\lambda$), and the variance is ($1/\lambda^2$).</li></ul><p>The Exponential distribution is widely used due to its simplicity and relevance in modeling various real-world scenarios involving random occurrences over time.</p></blockquote><p><img loading=lazy src=Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%201.png alt=Untitled></p><ul><li><p>code</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>scipy.stats</span> <span class=k>as</span> <span class=nn>stats</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Parameters for the exponential distributions (rate)</span>
</span></span><span class=line><span class=cl><span class=n>params</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mf>0.5</span><span class=p>,</span> <span class=s1>&#39;λ=0.5&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=s1>&#39;λ=1&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=s1>&#39;λ=2&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Create a figure and axis</span>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=p>,</span> <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Plotting</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>lambd</span><span class=p>,</span> <span class=n>label</span> <span class=ow>in</span> <span class=n>params</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>lambd</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=o>-</span><span class=n>lambd</span> <span class=o>*</span> <span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=c1>#y = stats.expon(scale=1/lambd).pdf(x)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=n>label</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;x&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;Probability Density&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;Exponential Distribution&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 去除上边框和右边框</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;top&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Display the plot</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div></li></ul><h3 id=normal-distribution>Normal distribution<a hidden class=anchor aria-hidden=true href=#normal-distribution>#</a></h3><blockquote><p>「ChatGPT-3.5」</p><p>The <strong>Normal distribution</strong>, also known as the Gaussian distribution, is a bell-shaped curve that describes the distribution of many types of data. It is symmetrical and its mean, median, and mode are all equal.</p><p>Key points:</p><ul><li><strong>Bell-shaped</strong>: Its graph is a symmetrical bell-shaped curve.</li><li><strong>Parameters</strong>: It is defined by two parameters: the mean ($\mu$) and the standard deviation ($\sigma$).</li><li><strong>68-95-99.7 Rule</strong>: About 68% of the data falls within one standard deviation of the mean, 95% within two standard deviations, and 99.7% within three.</li><li><strong>Applications</strong>: It&rsquo;s widely used in statistics, science, and engineering due to many natural phenomena and processes being approximately normally distributed.</li></ul><p>The formula for its probability density function (PDF) is:</p><p>$$
f(x | \mu, \sigma) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}
$$</p><p>However, for many practical applications, understanding its bell shape and the 68-95-99.7 rule is often more crucial than knowing its exact formula.</p></blockquote><p><img loading=lazy src=Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%202.png alt=Untitled></p><ul><li><p>code</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>scipy.stats</span> <span class=k>as</span> <span class=nn>stats</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Parameters for the normal distributions</span>
</span></span><span class=line><span class=cl><span class=n>params</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=s1>&#39;$\mu=0, \sigma=1$&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>,</span> <span class=s1>&#39;$\mu=2, \sigma=0.5$&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=o>-</span><span class=mi>2</span><span class=p>,</span> <span class=mf>2.5</span><span class=p>,</span> <span class=s1>&#39;$\mu=-2, \sigma=2.5$&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=p>,</span> <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>mu</span><span class=p>,</span> <span class=n>sigma</span><span class=p>,</span> <span class=n>label</span> <span class=ow>in</span> <span class=n>params</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=n>mu</span> <span class=o>-</span> <span class=mi>3</span><span class=o>*</span><span class=n>sigma</span><span class=p>,</span> <span class=n>mu</span> <span class=o>+</span> <span class=mi>3</span><span class=o>*</span><span class=n>sigma</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>norm</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>mu</span><span class=p>,</span> <span class=n>sigma</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=n>label</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 去除上边框和右边框</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;top&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;x&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Probability Density&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Normal Distribution&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div></li></ul><h2 id=supplementary-material-for-lesson-3><strong>Supplementary material for Lesson 3</strong><a hidden class=anchor aria-hidden=true href=#supplementary-material-for-lesson-3>#</a></h2><p><a href="https://d3c33hcgiwev3.cloudfront.net/_29f7eaaba3ac0d35ee74f8bd61aafc39_L3_supp.pdf?Expires=1692144000&amp;Signature=KA2KF0vx3gwhBdV~Qp1XAF3vmfziOf~pLoeyXkGI1sDGXz5P33eynAVVDQoyGfg3mFzxs0Jil10bamlf2z6rm8fb3cqMK7mVH5D~BjvT-W0MxKqjKUKvJsiiq6g1u23yDIWzSOxb39qZp1ISLzVL27Pqkdb6YgaqxrjsxaFAaOE_&amp;Key-Pair-Id=APKAJLTNE6QMUY6HBC5A">https://d3c33hcgiwev3.cloudfront.net/<em>29f7eaaba3ac0d35ee74f8bd61aafc39_L3_supp.pdf?Expires=1692144000&amp;Signature=KA2KF0vx3gwhBdV~Qp1XAF3vmfziOf~pLoeyXkGI1sDGXz5P33eynAVVDQoyGfg3mFzxs0Jil10bamlf2z6rm8fb3cqMK7mVH5D~BjvT-W0MxKqjKUKvJsiiq6g1u23yDIWzSOxb39qZp1ISLzVL27Pqkdb6YgaqxrjsxaFAaOE</em>&amp;Key-Pair-Id=APKAJLTNE6QMUY6HBC5A</a></p><h2 id=additional-discrete-distributions>Additional Discrete Distributions<a hidden class=anchor aria-hidden=true href=#additional-discrete-distributions>#</a></h2><h3 id=geometric-distribution>Geometric distribution<a hidden class=anchor aria-hidden=true href=#geometric-distribution>#</a></h3><p>The geometric distribution is <em><strong>the number of trials</strong></em> needed to get the first success, i.e., the number of Bernoulli events until a success is observed, such as the first head when flipping a coin. It takes values on the positive integers starting with one (since at least one trial is needed to observe a success).</p><p>$$
X \sim Geo(p) \newline
P(X=x|p)=p(1-p)^{x-1} \text{for $x=1,2,&mldr;$} \newline
E(X)=\frac{1}{p}
$$</p><p>If the probability of getting a success is $p$, then the expected number of trials until the first
success is $\frac{1}{p}$.</p><p>🌰 <strong>Example</strong>: What is the probability that we flip a fair coin four times and don’t see any heads?
This is the same as asking what is $P(X > 4)$ where $X \sim Geo(1/2)$ .</p><p>$$
\begin{align*}
P(X>4) &= 1-P(X=1)-P(X=2)-P(X=3)-p(X=4) \newline
&=1-\frac{1}{2}-\frac{1}{2} (\frac{1}{2})-\frac{1}{2} (\frac{1}{2})^2-\frac{1}{2} (\frac{1}{2})^3 \newline
&= \frac{1}{16}
\end{align*}
$$</p><p><img loading=lazy src=Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%203.png alt=Untitled></p><ul><li><p>code</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>scipy.stats</span> <span class=kn>import</span> <span class=n>geom</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Parameters for the geometric distribution</span>
</span></span><span class=line><span class=cl><span class=n>params</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mf>0.3</span><span class=p>,</span> <span class=s1>&#39;$p=0.3$&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mf>0.5</span><span class=p>,</span> <span class=s1>&#39;$p=0.5$&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mf>0.7</span><span class=p>,</span> <span class=s1>&#39;$p=0.7$&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=p>,</span> <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>p</span><span class=p>,</span> <span class=n>label</span> <span class=ow>in</span> <span class=n>params</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>16</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>geom</span><span class=o>.</span><span class=n>pmf</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>p</span><span class=p>)</span>   <span class=c1># Probability mass function</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>marker</span><span class=o>=</span><span class=s1>&#39;o&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;-&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=n>label</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Remove top and right borders</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;top&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Number of Trials&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Probability&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Geometric Distribution&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div></li></ul><h3 id=multinomial-distribution>Multinomial distribution<a hidden class=anchor aria-hidden=true href=#multinomial-distribution>#</a></h3><p>Another generalization of the Bernoulli and the binomial is the <em><strong>multinomial distribution</strong></em>, which is <em><strong>like a binomial</strong></em> when there are <em><strong>more than two possible outcomes</strong></em>.</p><p>Suppose we have $n$ trials and there are $k$ different possible outcomes which occur with probabilities $p_1,p_2,&mldr;,p_k$ .</p><p>For example, we are rolling a six-sided die that might be loaded so that the sides are not equally likely, then $n$ is the total number of rolls, $k=6$, $p_1$ is the probability of rolling a one, and we denote by $x_1,&mldr;,x_6$ a possible outcome for <strong>the number of times</strong> we observe rolls of each of one through six, where $\sum\limits_{i=1}^{6}x_i=n \text{ and } \sum\limits_{i=1}^{6}p_i=1$.</p><p>$$
f(x_1,\dots ,x_k|p_1,\dots ,p_k)=\frac{n!}{x_1!\dots x_k !}p_1^{x_1}\dots p_k^{x_k}
$$</p><p><img loading=lazy src=Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%204.png alt=Untitled></p><ul><li><p>模拟code</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>scipy.stats</span> <span class=kn>import</span> <span class=n>multinomial</span>
</span></span><span class=line><span class=cl><span class=c1># set seed for reproductibility</span>
</span></span><span class=line><span class=cl><span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>999</span><span class=p>)</span> 
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Parameters for the multinomial distribution</span>
</span></span><span class=line><span class=cl><span class=n>k</span> <span class=o>=</span> <span class=mi>3</span>
</span></span><span class=line><span class=cl><span class=n>n</span> <span class=o>=</span> <span class=mi>12</span> <span class=c1># number of trials (games in one tourment)</span>
</span></span><span class=line><span class=cl><span class=n>pvals</span> <span class=o>=</span> <span class=p>[</span><span class=mf>0.4</span><span class=p>,</span> <span class=mf>0.35</span><span class=p>,</span> <span class=mf>0.25</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>sizes</span> <span class=o>=</span><span class=p>[]</span> <span class=c1># number of tournments played</span>
</span></span><span class=line><span class=cl><span class=n>p</span> <span class=o>=</span> <span class=p>[]</span>    <span class=c1># a list to hold ratios (converge to prob) that player 1 wins 7 times, player 2 wins 2 times and 3 ties</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 公式计算</span>
</span></span><span class=line><span class=cl><span class=n>f_x</span> <span class=o>=</span> <span class=nb>round</span><span class=p>(</span><span class=n>multinomial</span><span class=o>.</span><span class=n>pmf</span><span class=p>([</span><span class=mi>7</span><span class=p>,</span><span class=mi>2</span><span class=p>,</span><span class=mi>3</span><span class=p>],</span><span class=n>n</span><span class=o>=</span><span class=n>n</span><span class=p>,</span><span class=n>p</span><span class=o>=</span><span class=n>pvals</span><span class=p>),</span><span class=mi>4</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 模拟</span>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=p>,</span> <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>4</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>size</span> <span class=ow>in</span> <span class=n>np</span><span class=o>.</span><span class=n>logspace</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span><span class=mi>4</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># the line below is where we actually generate discrete random variables according the multinomial distribution</span>
</span></span><span class=line><span class=cl>    <span class=n>outcomes</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>multinomial</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=n>pvals</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=nb>int</span><span class=p>(</span><span class=n>size</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># let&#39;s count the ratio of the expected outcome over all the outcomes - this will lastly converge to the probability</span>
</span></span><span class=line><span class=cl>    <span class=n>prob</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>((</span><span class=n>outcomes</span><span class=p>[:,</span><span class=mi>0</span><span class=p>]</span><span class=o>==</span><span class=mi>7</span><span class=p>)</span><span class=o>&amp;</span><span class=p>(</span><span class=n>outcomes</span><span class=p>[:,</span><span class=mi>1</span><span class=p>]</span><span class=o>==</span><span class=mi>2</span><span class=p>)</span><span class=o>&amp;</span><span class=p>(</span><span class=n>outcomes</span><span class=p>[:,</span><span class=mi>2</span><span class=p>]</span><span class=o>==</span><span class=mi>3</span><span class=p>))</span><span class=o>/</span><span class=nb>len</span><span class=p>(</span><span class=n>outcomes</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>p</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>prob</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>sizes</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=nb>int</span><span class=p>(</span><span class=n>size</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>sizes</span><span class=p>,</span><span class=n>p</span><span class=p>,</span><span class=s1>&#39;o-&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>sizes</span><span class=p>,[</span><span class=n>f_x</span><span class=p>]</span><span class=o>*</span><span class=nb>len</span><span class=p>(</span><span class=n>sizes</span><span class=p>),</span><span class=s1>&#39;--r&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>line1</span> <span class=o>=</span> <span class=sa>r</span><span class=s2>&#34;$p_1,p_2,p_3=(0.4, 0.35, 0.25)$&#34;</span>  <span class=c1># 文本内容</span>
</span></span><span class=line><span class=cl><span class=n>line2</span> <span class=o>=</span> <span class=sa>r</span><span class=s2>&#34;$x_1,x_2,x_3=(7,2,3)$&#34;</span>  <span class=c1># 文本内容</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>x_pos</span> <span class=o>=</span> <span class=mf>0.95</span>  <span class=c1># x 坐标位置（相对于轴范围的比例）</span>
</span></span><span class=line><span class=cl><span class=n>y_pos</span> <span class=o>=</span> <span class=mf>0.95</span>  <span class=c1># y 坐标位置（相对于轴范围的比例）</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>text</span><span class=p>(</span><span class=n>x_pos</span><span class=p>,</span> <span class=n>y_pos</span><span class=p>,</span> <span class=n>line2</span><span class=o>+</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>&#34;</span><span class=o>+</span><span class=n>line1</span><span class=p>,</span> <span class=n>transform</span><span class=o>=</span><span class=n>ax</span><span class=o>.</span><span class=n>transAxes</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>12</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>ha</span><span class=o>=</span><span class=s1>&#39;right&#39;</span><span class=p>,</span> <span class=n>va</span><span class=o>=</span><span class=s1>&#39;top&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># Remove top and right borders</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;top&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlim</span><span class=p>(</span><span class=n>xmin</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Number of Drawings&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;$p(x_1,x_2,x_3|p_1,p_2,p_3)$&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Theoretical $f(x_1,x_2,x_3|p_1,p_2,p_3)=</span><span class=si>{}</span><span class=s1>$&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>f_x</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#plt.grid(True)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div></li></ul><h3 id=poisson-distribution>Poisson distribution<a hidden class=anchor aria-hidden=true href=#poisson-distribution>#</a></h3><p>The Poisson distribution is used for counts, and arises in a variety of situations. The parameter $\lambda > 0$ is the <em><strong>rate</strong></em> at which we expect to observe the thing we are counting.</p><p>$$
X \sim Pois(\lambda) \newline
P(X=x|\lambda)=\frac{\lambda^xexp(- \lambda)}{x!} \text{ for $x=0,1,2,\dots$} \newline
E(X)=\lambda \newline
Var(X) =\lambda
$$</p><p>🌰 <strong>Example</strong>: Significant earthquakes occur in the Western United States approximately following a Poisson process with rate of two earthquakes per week. What is the probability there will be at least 3 earthquakes in the next two weeks?</p><p>未来两周发生地震的次数记为$X$，由题意得，$X \sim Pois(4)$.</p><p>$$
\begin{align*}
P(X\geq 3) &= 1-P(X\leq2) \newline
&=1- P(X=0)- P(X=1)- P(X=2) \newline
&=1 - \frac{4^0 exp(- 4)}{0!} -\frac{4^1 exp(- 4)}{1!} - \frac{4^2 exp(- 4)}{2!} \newline
&= 1-13e^{-4} \newline
&=0.762
\end{align*}
$$</p><h2 id=continuous-distributions>Continuous Distributions<a hidden class=anchor aria-hidden=true href=#continuous-distributions>#</a></h2><h3 id=gamma>Gamma<a hidden class=anchor aria-hidden=true href=#gamma>#</a></h3><p>If $X_1,X_2,\dots,X_n$ are independent (and identically distributed $Exp(\lambda)$) <em><strong>waiting times</strong></em> between successive events, then the total waiting time for all n events to occur $Y=\sum_{i=1}^{n}X_i$ will follow a gamma distribution with shape parameter $\alpha=n$ and rate parameter $\beta=\lambda$.</p><p>$$
Y \sim Gamma(\alpha,\beta) \newline
f(y|\alpha,\beta)=\frac{\beta^\alpha}{\Gamma(\alpha)}y^{\alpha-1}e^{-\beta y}I_{ {y \geq0}}(y) \newline
E(Y) = \frac{\alpha}{\beta} \newline
Var(Y) = \frac{\alpha}{\beta^2}
$$</p><p>where $\Gamma(·)$ is the gamma function, a generalization of the factorial function which can accept non-integer arguments. If $n$ is a positive integer, then $\Gamma(n) = (n − 1)!$ . Note also that $\alpha> 0$ and $\beta > 0$ .</p><p>The exponential distribution is a special case of the gamma distribution with $\alpha = 1$. The gamma distribution commonly appears in statistical problems, as we will see in this course. It is used to model positive-valued, continuous quantities whose distribution is right-skewed. As $\alpha$ increases, the gamma distribution more closely resembles the normal distribution.</p><p><img loading=lazy src=Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%205.png alt=Untitled></p><ul><li><p>code</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>scipy.stats</span> <span class=kn>import</span> <span class=n>gamma</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Parameters for the gamma distribution</span>
</span></span><span class=line><span class=cl><span class=n>params</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>,</span> <span class=s1>&#39;$</span><span class=se>\\</span><span class=s1>alpha=1, </span><span class=se>\\</span><span class=s1>beta=0.5$&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=s1>&#39;$</span><span class=se>\\</span><span class=s1>alpha=5, </span><span class=se>\\</span><span class=s1>beta=1$&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mi>8</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=s1>&#39;$</span><span class=se>\\</span><span class=s1>alpha=8, </span><span class=se>\\</span><span class=s1>beta=2$&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=p>,</span> <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>alpha</span><span class=p>,</span> <span class=n>beta</span><span class=p>,</span> <span class=n>label</span> <span class=ow>in</span> <span class=n>params</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=n>gamma</span><span class=o>.</span><span class=n>ppf</span><span class=p>(</span><span class=mf>0.001</span><span class=p>,</span> <span class=n>alpha</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mi>1</span><span class=o>/</span><span class=n>beta</span><span class=p>),</span> <span class=n>gamma</span><span class=o>.</span><span class=n>ppf</span><span class=p>(</span><span class=mf>0.999</span><span class=p>,</span> <span class=n>alpha</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mi>1</span><span class=o>/</span><span class=n>beta</span><span class=p>),</span> <span class=mi>100</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>gamma</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>alpha</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mi>1</span><span class=o>/</span><span class=n>beta</span><span class=p>)</span>   <span class=c1># Probability density function</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;-&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=n>label</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Remove top and right borders</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;top&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;X&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Probability Density&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Gamma Distribution&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div></li></ul><h3 id=beta>Beta<a hidden class=anchor aria-hidden=true href=#beta>#</a></h3><p>The beta distribution is used for random variables which <strong>take on values between 0 and 1</strong>. For this reason (and other reasons we will see later in the course), the beta distribution is commonly used to model probabilities</p><p>$$
X \sim Beta(\alpha,\beta) \newline
f(x|\alpha,\beta)=\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha-1}(1-x)^{\beta -1}I_{ {0&lt;x&lt;1}}(x) \newline
E(X) = \frac{\alpha}{\alpha + \beta} \newline
Var(X) = \frac{\alpha \beta}{(\alpha+\beta)^2(\alpha+\beta+1)}
$$</p><p>where $\Gamma(·)$ is the gamma function introduced with the gamma distribution. Note also that $\alpha> 0$ and $\beta > 0$ . The standard Uniform(0, 1) distribution is a special case of the betadistribution with $\alpha=\beta=1$ .</p><p><img loading=lazy src=Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%206.png alt=Untitled></p><ul><li><p>code</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>scipy.stats</span> <span class=kn>import</span> <span class=n>beta</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Parameters for the Beta distribution</span>
</span></span><span class=line><span class=cl><span class=n>params</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=s1>&#39;$</span><span class=se>\\</span><span class=s1>alpha=2, </span><span class=se>\\</span><span class=s1>beta=5$&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=s1>&#39;$</span><span class=se>\\</span><span class=s1>alpha=5, </span><span class=se>\\</span><span class=s1>beta=1$&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=s1>&#39;$</span><span class=se>\\</span><span class=s1>alpha=2, </span><span class=se>\\</span><span class=s1>beta=2$&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=p>,</span> <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>,</span> <span class=n>label</span> <span class=ow>in</span> <span class=n>params</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>beta</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>)</span>   <span class=c1># Probability density function</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=n>label</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Remove top and right borders</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;top&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Value&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Probability Density&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Beta Distribution&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div></li></ul><h3 id=t>t<a hidden class=anchor aria-hidden=true href=#t>#</a></h3><p>If we have normal data, we can use $\bar{X} \sim N(\mu,\frac{\sigma^2}{n})$ to help us estimate the mean $\mu$. 标准正态分布： $\frac{\bar{X} - \mu}{\sigma/ \sqrt{n}} \sim N(0,1)$. However, we may not know the value of $\sigma$. If we estimate it from data, we can replace it with $S=\sqrt{\sum_i(X_i - \bar{X})^2/(n-1)}$ , the sample standard deviation. This causes the $\frac{\bar{X} - \mu}{\sigma/ \sqrt{n}}$ to no longer be distributed as standard normal, but as a standard t distribution with $\nu=n-1$ degrees of freedom.</p><p>$$
Y \sim t_{\nu} \newline
f(y) = \frac{\Gamma(\frac{\nu +1}{2})}{\Gamma(\frac{\nu}{2}) \sqrt{\nu \pi}}(1+\frac{y^2}{\nu})^{-(\frac{\nu + 1}{2})} \newline
E(Y) = 0 \text{, if $\nu > 1$ } \newline
Var(Y) = \frac{\nu}{\nu - 2} \text{, if $\nu > 2$}
$$</p><p><img loading=lazy src=Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%207.png alt=Untitled></p><ul><li><p>code</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>scipy.stats</span> <span class=kn>import</span> <span class=n>t</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Parameters for the t distribution</span>
</span></span><span class=line><span class=cl><span class=n>params</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=s1>&#39;$df=2$&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=s1>&#39;$df=5$&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=s1>&#39;$df=10$&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=p>,</span> <span class=n>axes</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Plot probability density function</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;t Distribution - Probability Density Function&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>df</span><span class=p>,</span> <span class=n>label</span> <span class=ow>in</span> <span class=n>params</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=o>-</span><span class=mi>4</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>t</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>df</span><span class=p>)</span>   <span class=c1># Probability density function</span>
</span></span><span class=line><span class=cl>    <span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=n>label</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Plot cumulative distribution function</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;t Distribution - Cumulative Distribution Function&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>df</span><span class=p>,</span> <span class=n>label</span> <span class=ow>in</span> <span class=n>params</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=o>-</span><span class=mi>4</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>t</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>df</span><span class=p>)</span>   <span class=c1># Cumulative distribution function</span>
</span></span><span class=line><span class=cl>    <span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=n>label</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Remove top and right borders</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>ax</span> <span class=ow>in</span> <span class=n>axes</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;top&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=p>[</span><span class=s1>&#39;right&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;Value&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;Probability Density&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;Value&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;Cumulative Probability&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div></li></ul><blockquote><p>作者：吴端</p><p>链接：https://www.zhihu.com/question/34866983/answer/1540230125</p><p>来源：知乎</p><p>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p><p>分布分为离散分布和连续分布。连续分布几乎都能找到对应的离散分布。因为连续分布本质上就是把离散分布中投硬币的次数，变成连续的时间长度。把每次投硬币的正反面概率，变成单位时间内出现正面的概率密度。</p><p>下面我从贝努利实验出发，把所有分布的关系梳理出来：</p><p>贝努利实验：投硬币，正面反面概率分别为p，1-p</p><p>二项分布：如果把贝努利实验连续做n次，出现正面的次数服从的分布。</p><p>二项分布的极限：泊松分布。给定时间内时间发生次数的分布。</p><p>负二项分布：在贝努利实验中，如果想让正面出现n次，需要做的实验次数的分布。</p><p>负二项分布的极限：gamma分布。问如果指定事件出现N次，需要等待的时间。</p><p>二项分布与负二项分布的关系：二项分布是在固定实验次数情况下，问结果分布。负二项分布是在固定结果情况下问实验次数分布。一个是在固定投入问产出，一个是在固定产出下问投入。</p><p>几何分布：n重贝努利实验，正面第一次出现时的实验次数。</p><p>几何分布的极限：指数分布。事件第一次发生等待的时间。</p><p>几何分布与负二项分布的关系：负二项分布是N个几何分布的和。相当于做N次几何分布，事件正好发生N次。各几何分布的实验次数之和就是负二项分布的总次数。</p><p>指数分布与gamma分布的关系：N次指数分布时间之和就是gamma分布中事件发生N次等待总时间。</p><p>如果课本能这样组织这些知识，估计也没有人困惑为啥整这么多奇怪的分布，到底有什么用。推倒过程反而没那么重要</p></blockquote><h2 id=central-limit-theorem>Central Limit Theorem<a hidden class=anchor aria-hidden=true href=#central-limit-theorem>#</a></h2><p>The Central Limit Theorem is one of the most important results in statistics, basically saying
that with sufficiently large sample sizes, <em><strong>the sample average</strong></em> approximately follows a normal
distribution.</p><p>In formal mathematical notation, the Central Limit Theorem says: Let $X_1,\dots ,X_n$ be independent and identically distributed with $E(X_i)=\mu \text{ and } Var(X_i)= \sigma^2,0 &lt; \sigma^2 &lt; \infty$, then,</p><p>$$
\frac{\sqrt{n}(\bar{X}-\mu)}{\sigma} \sim N(0,1)
$$</p><p><img loading=lazy src=Review%20of%20distributions%20d8d220dc54f149cc9516e97e5dab39d5/Untitled%208.png alt=Untitled></p><p>$$
\varphi = 1+\frac{1} {1+\frac{1} {1+\frac{1} {1+\cdots} } }
$$</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://unclehuzi.github.io/tags/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/>课程笔记</a></li><li><a href=https://unclehuzi.github.io/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF/>贝叶斯</a></li><li><a href=https://unclehuzi.github.io/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6/>统计学</a></li></ul><nav class=paginav><a class=prev href=https://unclehuzi.github.io/posts/python-macos_install_anaconda_by_homebrew/><span class=title>« Prev</span><br><span>macOS通过homebrew安装anaconda</span></a>
<a class=next href=https://unclehuzi.github.io/posts/da-bayesian_statistics-coursera-from_concept_to_data_analysis/><span class=title>Next »</span><br><span>coursera课程-Probability and Bayes’ Theorem</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share coursera课程-Review of distributions on x" href="https://x.com/intent/tweet/?text=coursera%e8%af%be%e7%a8%8b-Review%20of%20distributions&amp;url=https%3a%2f%2funclehuzi.github.io%2fposts%2fda-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions%2f&amp;hashtags=%e8%af%be%e7%a8%8b%e7%ac%94%e8%ae%b0%2c%e8%b4%9d%e5%8f%b6%e6%96%af%2c%e7%bb%9f%e8%ae%a1%e5%ad%a6"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share coursera课程-Review of distributions on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2funclehuzi.github.io%2fposts%2fda-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions%2f&amp;title=coursera%e8%af%be%e7%a8%8b-Review%20of%20distributions&amp;summary=coursera%e8%af%be%e7%a8%8b-Review%20of%20distributions&amp;source=https%3a%2f%2funclehuzi.github.io%2fposts%2fda-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share coursera课程-Review of distributions on reddit" href="https://reddit.com/submit?url=https%3a%2f%2funclehuzi.github.io%2fposts%2fda-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions%2f&title=coursera%e8%af%be%e7%a8%8b-Review%20of%20distributions"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share coursera课程-Review of distributions on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2funclehuzi.github.io%2fposts%2fda-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share coursera课程-Review of distributions on whatsapp" href="https://api.whatsapp.com/send?text=coursera%e8%af%be%e7%a8%8b-Review%20of%20distributions%20-%20https%3a%2f%2funclehuzi.github.io%2fposts%2fda-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share coursera课程-Review of distributions on telegram" href="https://telegram.me/share/url?text=coursera%e8%af%be%e7%a8%8b-Review%20of%20distributions&amp;url=https%3a%2f%2funclehuzi.github.io%2fposts%2fda-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share coursera课程-Review of distributions on ycombinator" href="https://news.ycombinator.com/submitlink?t=coursera%e8%af%be%e7%a8%8b-Review%20of%20distributions&u=https%3a%2f%2funclehuzi.github.io%2fposts%2fda-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://unclehuzi.github.io/>H.W.</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>