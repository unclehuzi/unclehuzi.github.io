[{"categories":["数据分析","生活"],"content":" === buy me a coffe :) === ","date":"2024-07-05","objectID":"/2024/07/life-hupai/:0:0","tags":["上海","沪牌"],"title":"沪牌数据记录","uri":"/2024/07/life-hupai/"},{"categories":["生活"],"content":"目前更多是记录自己了解到的信息 写在前面： 就记录红蓝绿三大厂 红-李宁 蓝-victor 绿-Yonex 各家球拍基本按照 全面、各针对性类型分类 基于Notion维护 === buy me a coffe :) === ","date":"2024-07-01","objectID":"/2024/07/life-badminton_equipments/:0:0","tags":["羽毛球拍"],"title":"我希望选购羽毛球相关的看这一篇就够了","uri":"/2024/07/life-badminton_equipments/"},{"categories":["生活"],"content":"总算是持证了… ‍ 实际接触到的是 教练，建议找熟人推荐，图中教练是飞哥羽毛球俱乐部的一个球友、也是校友推荐的 ​​ ‍ 费用组成：教练费用 + ¥362 教练 或 驾校 学费。这部分我单独给了教练，没接触驾校 考试模拟费，这部分可以和教练谈好，打包在一起 这部分是为了方便了解下真实的考场，主要是科目二 车管所等单位要求的相关费用 理论学习费用，¥12 微信公众号：上海计时驾培服务平台 APP：长三角车生活 体检费，正常 ¥120 正常在医院体检是¥120： ¥60（视力等常规检测）+¥60（拍照） 特殊情况、特殊路子是另外的费用 考试费：$¥40 \\times 3= ¥ 120$ 驾驶证工本费：¥10 陌生领域，还是得找有经验的人咨询，所以记录在此 === buy me a coffe :) === ","date":"2024-06-17","objectID":"/2024/06/life-driving_license_pre/:0:0","tags":["驾驶证"],"title":"上海驾考报名费用记录","uri":"/2024/06/life-driving_license_pre/"},{"categories":["生活"],"content":"上海浦东邮佳考点 ","date":"2024-06-12","objectID":"/2024/06/%E7%A7%91%E7%9B%AE%E4%B8%89%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/:0:0","tags":["驾驶证","科目三"],"title":"科目三_道路行驶","uri":"/2024/06/%E7%A7%91%E7%9B%AE%E4%B8%89%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/"},{"categories":["生活"],"content":"个人考试情况 考了两次😂，这篇文档是在第一次没过的情况下整理的，算是自己捋一捋注意事项，分为通用性的 和 实际考点路线的 第一次是 2024年05月27日 失误点 路口忘记减速踩刹车 直线行驶不稳 我自己没感受到，复盘原因应该是躺着的坐姿比较慵懒、影响前方事项 第二次是 2024年06月13日 体验很不好，车管所系统出了BUG，信息录不上，等了3个半小时吧…… 失误点 没想到夜间灯光项目刚开始就挂了😂 人行横道得打下双闪 好在第二把过了😂 实话，有点紧张的 好在整理了这篇文档，还意外发现0527的请假类型选的是事假😂 紧急联系了下公司人事给改了过来，感谢～ ‍ ","date":"2024-06-12","objectID":"/2024/06/%E7%A7%91%E7%9B%AE%E4%B8%89%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/:1:0","tags":["驾驶证","科目三"],"title":"科目三_道路行驶","uri":"/2024/06/%E7%A7%91%E7%9B%AE%E4%B8%89%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/"},{"categories":["生活"],"content":"通用性注意事项： 全程背部挺直，要有精气神，不要躺着开，会影响（直线行驶）视线 起步。左转向灯，踩刹车后，挂档，手刹 只要打了转向灯，就必须等跳了6下后再动方向盘 顺车掉头打的是**左转向灯**，打错了没关系，等跳了6下后再改正 看到路口、公交站、学校，就放慢速度（\u003c30），快到的样子，重踩刹车 直线行驶的时候，动了一点方向盘后立马就要回正 靠边停车双保险（小镜子、后视镜；雨刮器与边线的关系） 留意每个考场，自行加速⏩ 40～60的地段 ‍ ","date":"2024-06-12","objectID":"/2024/06/%E7%A7%91%E7%9B%AE%E4%B8%89%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/:2:0","tags":["驾驶证","科目三"],"title":"科目三_道路行驶","uri":"/2024/06/%E7%A7%91%E7%9B%AE%E4%B8%89%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/"},{"categories":["生活"],"content":"各考试路线 ‍ ","date":"2024-06-12","objectID":"/2024/06/%E7%A7%91%E7%9B%AE%E4%B8%89%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/:3:0","tags":["驾驶证","科目三"],"title":"科目三_道路行驶","uri":"/2024/06/%E7%A7%91%E7%9B%AE%E4%B8%89%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/"},{"categories":["生活"],"content":"2️⃣号线 路口记得踩刹车、打左转向灯⬅️ 超过6下，再动方向盘 左转弯过来之后，速度放慢，有公交站，踩刹车、速度30以内 过了公交站，加速⏩ 40～60的速度 靠右行驶，准备右转弯 右转弯后速度放慢，准备做“超车”项目 “顺车掉头”项目 左转向灯（记得要跳6下） 向 右侧 借道，一把掉头 掉头后，立马就有个学校，踩刹车 左转后看见灯塔一样的东西，准备开始“直线行驶”项目 “直线行驶”结束后，有个公交站，刹车 右转后靠边停车，P档、手刹、熄火、安全带、下车 ​​ ","date":"2024-06-12","objectID":"/2024/06/%E7%A7%91%E7%9B%AE%E4%B8%89%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/:3:1","tags":["驾驶证","科目三"],"title":"科目三_道路行驶","uri":"/2024/06/%E7%A7%91%E7%9B%AE%E4%B8%89%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/"},{"categories":["生活"],"content":"4️⃣号线 ​​ 直行 🚥 ，左转弯， 🚥 公交车站 右转弯 🚥，发动机盖没过柏油马路边线打方向 加速⏩ 40～60的速度，准备直线行驶项目 “顺车掉头” 向右变道，速度逐渐减慢，经过学校 “超车”项目，向左变道，准备左转弯 公交车站，点刹，准备右转弯 靠边停车项目 ","date":"2024-06-12","objectID":"/2024/06/%E7%A7%91%E7%9B%AE%E4%B8%89%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/:3:2","tags":["驾驶证","科目三"],"title":"科目三_道路行驶","uri":"/2024/06/%E7%A7%91%E7%9B%AE%E4%B8%89%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/"},{"categories":["生活"],"content":"1️⃣号线 ​​ 左转弯之后 就整“加速⏩40～60”项目 公交站点刹，靠右行驶准备右转弯 右转弯结束后，速度慢，准备“超车”项目 “顺车掉头”项目、学校点刹 过了红绿灯后，车摆正 准备直线行驶 右转后，公交车站，点刹 看到大圆镜后，准备靠边停车 ‍ ‍ === buy me a coffe :) === ","date":"2024-06-12","objectID":"/2024/06/%E7%A7%91%E7%9B%AE%E4%B8%89%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/:3:3","tags":["驾驶证","科目三"],"title":"科目三_道路行驶","uri":"/2024/06/%E7%A7%91%E7%9B%AE%E4%B8%89%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/"},{"categories":["生活"],"content":" === buy me a coffe :) === ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p3/:0:0","tags":["驾驶证","科目一"],"title":"临考急救宝典","uri":"/2024/03/life-driving_license_p3/"},{"categories":["生活"],"content":"科目一精髓课【下篇】_哔哩哔哩_bilibili 通行原则 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:0:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"会车让行题 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:1:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"左侧超车 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:2:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"禁止停车 口5 站3 xx口 50米内不能停车 xx站 30米内不能停车 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:3:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"变道 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:4:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"校车让行 复杂路段 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:5:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"避开特殊路上的坑 上坡挂抵挡 ⇒ 高动力 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:6:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"坡道-停车方向盘 特殊天气 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:7:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"雨天、雾天 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:8:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"雪天、大风天 速度 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:9:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"速度高低 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:10:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"无线城3公4、有线城5公7 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:11:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"特殊速度找30 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:12:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"高速公路行车速度 同向4车道：110，90，90 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:13:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"高速 低能见度时的速度 灯光仪表 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:14:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"打什么灯？ ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:15:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"仪表 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:16:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"4个常考的照明信号 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:17:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"操纵装置 左灯右水 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:18:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"简单 仪表指示灯 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:19:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"易错 仪表指示灯 事故处理 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:20:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"爆胎题 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:21:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"故障停车 - 4考点 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:22:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"自己协商还是报警？ 现场急救 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:23:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"急救 先救命后治伤 信号灯 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:24:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"交通信号灯 易错4个点 路口以外 交警手势 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:25:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"停止信号 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:26:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"直行信号 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:27:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"左转弯待转 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:28:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"减速慢行信号 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:29:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"变道信号 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:30:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"转弯信号 标志 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:31:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"警告标志 没有追尾，是指事故易发 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:32:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"禁令标志 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:33:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"易混标志 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:34:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"新标志 标线 === buy me a coffe :) === ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p2/:35:0","tags":["驾驶证","科目一"],"title":"通行原则、标志标线","uri":"/2024/03/life-driving_license_p2/"},{"categories":["生活"],"content":"科目一3小时精髓课【十月新规】_哔哩哔哩_bilibili 扣分 1、3、6、9、12 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:0:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"1分关键词 驾驶机动车载货长度、宽度、高度超过规定的 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:1:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"3分关键词 驾驶机动车在高速公路、城市快速路上倒车、逆行、穿越中央分隔带掉头的 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:2:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"6分关键词 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:3:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"9分关键词 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:4:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"12分关键词 饮酒12分，醉酒要吊销驾照 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:5:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"场景汇总 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:6:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"号牌扣分 3、9、12 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:6:1","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"9种超速扣分 高速上超速就两档：6、12 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:6:2","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"7种超员扣分总结 校、公、旅车只有两档： 20%以下 6分 20%以上 12分 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:6:3","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"货车超载 1、3、6 罚款 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:6:4","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"200元以下找车相关 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:7:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"20-200元罚款关键词 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:8:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"200-500元罚款关键词 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:9:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"200-2000元罚款关键词（常考） 吊销的是驾驶证 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:10:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"500、2000元罚款关键词 撤3是指3年内不能申领 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:11:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"审验相关处罚 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:12:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"代记分三五倍 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:13:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"酒驾罚多少钱？ 驾驶证 新规 申请人隐瞒有关情况或者提供虚假材料申领机动车驾驶证的，公安机关交通管理部门不予受理或者不予办理，处五百元以下罚款；申请人在一年内不得再次申领机动车驾驶证。 申请人在考试过程中有贿赂、舞弊行为的，取消考试资格，已经通过考试的其他科目成绩无效，公安机关交通管理部门处二千元以下罚款；申请人在一年内不得再次申领机动车驾驶证。 申请人以欺骗、贿赂等不正当手段取得机动车驾驶证的，公安机关交通管理部门收缴机动车驾驶证，撤销机动车驾驶许可，处二千元以下罚款；申请人在三年内不得再次申领机动车驾驶证。 组织、参与实施前三款行为之一牟取经济利益的，由公安机关交通管理部门处违法所得三倍以上五倍以下罚款，但最高不超过十万元。 伪造、变造或者使用伪造、变造的机动车登记证书、号牌、行驶证、驾驶证的，由公安机关交通管理部门予以收缴，扣留该机动车，处15日以下拘留，并处2000元以上5000元以下罚款;构成犯罪的，依法追究刑事责任 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:14:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"驾驶考试要求 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:15:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"常考准驾车型 备注：C6只能通过增驾获得 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:16:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"吊销几年？几年不得申领？ ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:17:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"补证、换证去哪儿？ ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:18:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"驾驶证审验 驾驶证 是和 人 相关 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:19:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"实习期 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:20:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"时间相关 未满12分 ⇒ 有效期递增 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:21:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"申请增加准驾车型 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:22:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"机动车注册、变更登记 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:23:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"上路必带两证两标一号牌 不存在扣行驶证 的说法 驾驶证和行驶证是两种不同的证件，它们分别用于不同的目的： 驾驶证 定义：驾驶证，全称为机动车驾驶证，是证明持证人具有驾驶机动车的合法资格的证件。 用途：驾驶证用来证明一个人具备了驾驶机动车辆的能力和资格，包括摩托车、汽车等不同类别的机动车。 考取：想要获得驾驶证，申请人需要通过理论考试和实际驾驶考试来证明其驾驶技能和对交通法规的了解。 有效期：驾驶证是有有效期的，需要定期进行审验和续期。 行驶证 定义：行驶证，全称为机动车行驶证，是证明机动车合法上路行驶的证件。 用途：行驶证上记录了机动车的基本信息，如车辆类型、车辆识别代号、发动机号、车主信息等，是车辆合法上路的必要证件之一。 获取：购买机动车后，车辆需要接受交通管理部门的登记，通过后会颁发行驶证。 有效期：行驶证本身长期有效，但车辆需要定期进行年检（新车可免检几年），并在检验合格后更新行驶证上的检验标记。 区别总结 对象不同：驾驶证是针对驾驶人的，证明其驾驶资格；行驶证是针对车辆的，证明车辆符合行驶要求。 用途不同：驾驶证用于证明个人的驾驶能力和资格；行驶证用于证明车辆的合法性和技术状态。 获取方式不同：驾驶证需要通过考试获得；行驶证是在车辆购买并登记后由交通管理部门颁发。 简而言之，驾驶证和行驶证分别是驾驶员和机动车的“身份证”，二者缺一不可，共同确保了道路交通的安全和有序。 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:24:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"满分教育 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:25:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"学法减分 实习期不能参与 学法减分 责任判定 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:26:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"危险驾驶、交通肇事罪 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:27:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"赔偿责任 ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:28:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"判刑判几年？ === buy me a coffe :) === ","date":"2024-03-04","objectID":"/2024/03/life-driving_license_p1/:29:0","tags":["驾驶证","科目一"],"title":"扣分、罚款、判刑汇总","uri":"/2024/03/life-driving_license_p1/"},{"categories":["生活"],"content":"跟踪下每天的碎碎念，是不是依然在原地踏步，什么时候能换换？？？ ","date":"2024-02-16","objectID":"/2024/02/life-muttering_daily/:0:0","tags":["碎碎念"],"title":"这一天天的碎碎念","uri":"/2024/02/life-muttering_daily/"},{"categories":["生活"],"content":"202407 ","date":"2024-02-16","objectID":"/2024/02/life-muttering_daily/:1:0","tags":["碎碎念"],"title":"这一天天的碎碎念","uri":"/2024/02/life-muttering_daily/"},{"categories":["生活"],"content":"20240726 是真的蠢，24K纯傻逼。背景是这样的，老板说让同事A给我一批样本，让我帮忙回溯我之前上线的规则，听完具体需求后，我说不用回溯，我有现成的。结果同事A哇啦哇啦的：什么是全量的么？等等一系列问题。开始几个问题我还意思意思象征性的回复下。最后我实在是不耐烦了，（无奈的假笑），我说你先看了表里的数据再说话吧。能力不咋滴，又要面子。真的是垃圾 老板咔咔咔需求也说半天了，我听完评估后也说了不用回溯有现成的。 而且，真是的没有对比就没有伤害，之前同事B也找我要过规则的标签，我同样是说表里有现成的，同事B就没有这儿那儿的事儿 🤷 好了，骂完舒坦了 ","date":"2024-02-16","objectID":"/2024/02/life-muttering_daily/:1:1","tags":["碎碎念"],"title":"这一天天的碎碎念","uri":"/2024/02/life-muttering_daily/"},{"categories":["生活"],"content":"20240701 这是个有趣的跟踪，年后那一个月记录些事儿，之后长达3个月的时间里，就基本没咋更新了😂 真是个有趣的现象 今天是2024年下半年的第一天，是的呢，得是个好的开始才对呀。而我今天一早开始就很丧😂 不想上班的情绪拉到的极值，一度想辞职…周末又再一次梦见自己裸辞😂 又看到半年度绩效跟踪开始了，就是个笑话，论资排辈的草台班子。有种很强烈的感觉：在精力最旺盛的年纪，无所事事… 工作上也没什么盼头，也没什么🉑干的。就这样吧，关于这个绩效流程啥的，要是没人提，我就不写了😂 写了又能怎样呢？ 乐观点，对自己负责？对自己过去半年时间负责？（嗯 我觉得也不是不行噢） 之所以没实际落地裸辞，主要是还是在于机会成本吧，还有辞职之后做什么🤔 多看看新买的小沙弥，开心点😄 ","date":"2024-02-16","objectID":"/2024/02/life-muttering_daily/:1:2","tags":["碎碎念"],"title":"这一天天的碎碎念","uri":"/2024/02/life-muttering_daily/"},{"categories":["生活"],"content":"202403 ","date":"2024-02-16","objectID":"/2024/02/life-muttering_daily/:2:0","tags":["碎碎念"],"title":"这一天天的碎碎念","uri":"/2024/02/life-muttering_daily/"},{"categories":["生活"],"content":"20240326 搞了个数据治理啥的，从郑州过来，调研？也是挺搞笑😂 不知道说了个啥。没有啥逻辑 ","date":"2024-02-16","objectID":"/2024/02/life-muttering_daily/:2:1","tags":["碎碎念"],"title":"这一天天的碎碎念","uri":"/2024/02/life-muttering_daily/"},{"categories":["生活"],"content":"20240301 周五了。晚上看封面点开了一个电视剧😂 看到句台词，可真有意思： 公司死的鱼多了，但这个网永远都没破 ","date":"2024-02-16","objectID":"/2024/02/life-muttering_daily/:2:2","tags":["碎碎念"],"title":"这一天天的碎碎念","uri":"/2024/02/life-muttering_daily/"},{"categories":["生活"],"content":"202402 ","date":"2024-02-16","objectID":"/2024/02/life-muttering_daily/:3:0","tags":["碎碎念"],"title":"这一天天的碎碎念","uri":"/2024/02/life-muttering_daily/"},{"categories":["生活"],"content":"20240220 重新定义今天 前天说今天vpn能好；昨天也说今天vpn能好；今天又是一个新的今天 :) 真拉垮，说是家持牌金融机构，然后把网络安全的基建外包。然后2天过去了，还没搞定😂 重新定义今天 收集问题做做样子 入职后填了好几个团队发的什么问题收集问卷。刚开始的时候挺积极的，也希望能改善些。结果最后都不了了之，填个der 就TM做做样子，给老板交个作业。推的动？笑der 噢，还可以来个人告诉你现在的样子，教你现在的系统怎么用 （干得漂亮） ","date":"2024-02-16","objectID":"/2024/02/life-muttering_daily/:3:1","tags":["碎碎念"],"title":"这一天天的碎碎念","uri":"/2024/02/life-muttering_daily/"},{"categories":["生活"],"content":"20240219 春节后开工第二天，工作环境让我很无语😓 公司发的电脑连不上公司的Wi-Fi 为什么不找公司的IT？ 我觉得公司的IT是大爷。这种小事要找大爷么？ 打过几次交道，实在是无语，不然也不会抛弃公司发的所有办公设备。现在办公用的电脑、外接显示器全是自己的。真的呵呵，自费打工 mac版 SDP 无法使用 公司发的电脑连不上Wi-Fi这个事儿，我可能是个例。但 mac版类似VPN的东西用不了，是所有人都这样 真的是笑死 这是个啥问题呢？谁来背锅呢？扣扣供应商的钱就完事儿了？会不会扣钱都是另一回事儿 信贷行业，还有哪家公司模型系统和引擎耦合是如此严重的？？？ 转正材料的建议里详细阐述了这个问题。并用公司楼下标准化流程的manner咖啡店形象比喻表达耦合误事。 有一种风险叫操作风险。这边策略引擎应用个模型分，还需要策略人员额外配置？？？ 这是个重复劳动的重体力活：假设N个大规则集用到了同一个模型A，那就要配置N次。还没包括模型那边又改了哪个地方 严重耦合不说，这一来一回的都是操作风险啊，笑der 再展开下。。。 系统、数据环境是难用的一批，相关利益方可能应该是做了优化，就觉得现在是最好的了。先不说有没有在市场上调研别家成熟的情况，交互逻辑本身就有问题😂 提了建议也没啥卵用，来个人教你现在这个咋用，笑der 然后，我每次就都说，我当然会在现有的环境下寻求方案处理，但我想说的是那样更好😊 更有意思的公司开大会，好像是科技的啥领导发言，说公司以科技优先啥的。我真的是笑der，就现在的系统、数据环境哪儿就上升到这个高度了，市场上那么成熟的，抄作业不行么，再不济，买一个好点的不行么？ ","date":"2024-02-16","objectID":"/2024/02/life-muttering_daily/:3:2","tags":["碎碎念"],"title":"这一天天的碎碎念","uri":"/2024/02/life-muttering_daily/"},{"categories":["生活"],"content":"20240216 百亿补贴，可能是个很好的洗钱路子！ 还能挂名“平台补贴”。 我不懂，可能这在洗钱里是低劣手法了 === buy me a coffe :) === ","date":"2024-02-16","objectID":"/2024/02/life-muttering_daily/:3:3","tags":["碎碎念"],"title":"这一天天的碎碎念","uri":"/2024/02/life-muttering_daily/"},{"categories":["生活"],"content":"最近得知前司曾经的团队因为年终绩效考核的事儿搞得花里胡哨，局面一度陷入尴尬 了解到一些“茶艺表演”后，不由的心生感叹：幸好我离开，了？ 这里是两层意思：1）是基于现在的我陈述想法，庆幸自己离开了，没有卷入乱七八糟的琐事中；2）是对未知的敬畏，就像是中国的宫斗剧、美国的纸牌屋，而前团队发生的这事儿也算是低级的缩影吧，也心存疑问，是不是也要面对下🤔 事件简述：同事A拿到了好绩效；同事B搞得“鸡飞狗跳”，捅到了整个大事业部的HRBP。至于同事B为啥整这么一出，应该也是出于某些利益吧。或许也有别的相关背景，但无论如何，我觉得同事B在该岗位的专业能力都比较拉垮，这个好绩效轮不上同事B，也不应该给同事B，简而言之我相当不认可同事B在该业务阶段该岗位的专业能力，甚至不理解为什么当初老板们会发这个offer 当下这个业务团队更需要的还是老实干活的人，团队业务整体其实是攻坚期，是需要大家劲往一处使，打江山的时候。但一个完善的团队某种程度上也是需要同事B的某些特性的，这个就像唐僧师徒里的浓缩版猪八戒。为啥说是浓缩版呢，因为猪八戒至少还会36变，好歹也是天蓬元帅，专业能力还是可以的。而且，前期唐僧是先收的孙悟空，不是猪八戒。唐僧还没和悟空磨合好就收猪八戒，最后就变成了一颗老鼠屎坏了一锅汤。并且，猪八戒知道自己的斤两，出了问题还是要找大师兄的，也就压根没觉得自己是孙悟空，这叫清楚自己的定位。 当时选择离开，一定程度上也是比较膈应这个同事B，不认可其言语、行为以及能力，隐隐约约觉得以后事儿多。这个真不是马后炮了😂 所以，当知道这个同事B搞事情后，就觉得 幸好我离职了。 以上是第一层意思。至于第二层，是在于我对工作的理解，目前来看，我的职场经验尚浅，但隐约始终觉得，有人的地方就有江湖，越往上走考验的是人性，竞争可能更激烈、冲突更明显、令人作恶的事儿可能更多。有时候就在想，是不是有必要也接触下这些东西，等真的面临时，抵触情绪不会那么大。所以，站在这个角度来看，我的离开，可能是种逃避，逃避我所讨厌的未来似乎可能又要面对的。 与各式各样的人相处，终究是门学问…… 始终相信，人的行为最终都是为了追求幸福感、爽感，行动自然就印证了偏好 道阻且长，依然坚信由艺入道，每一次经历都是成长的素材。不是要逃避，而是要理性的分析、知道，所待地方综合来看，是否获得了幸福感，而不同的人生阶段，幸福感的维度以及分配的权重都不一样。只能说“搞事情”不在目前我幸福感的维度里 ✌️ ","date":"2024-01-29","objectID":"/2024/01/life-hualihushao/:0:0","tags":["总结与展望","blog"],"title":"幸好我离职，了？","uri":"/2024/01/life-hualihushao/"},{"categories":["写作"],"content":"RT，在网站中显示notebook Python代码 类似这个 review_of_distributions 之所以会有这个需求也是因为之前整理笔记的时候需要用Python画图，同时也想在post至网站时保存代码。一个比较直接的方案就是在本地运行成功后进一步在每张图下面加上code。虽然用于笔记的code有一定的临时性，但有个在线可运行跨平台的地方保存着也算是有个归宿了，同时以notebook的方式与笔记建立关联后，也保持着可复现性与一致性。 在线可运行代码且跨平台的地方便是Google的colab产品了，代码可保存至google云盘；剩下的就是将notebook嵌入至网站文章中了。这里采用的是GitHub的gist。整个流程便是 ","date":"2023-09-30","objectID":"/2023/09/blog-google_colab_embedded/:0:0","tags":["blog","jupyter notebook"],"title":"将google-colab的代码嵌入网站","uri":"/2023/09/blog-google_colab_embedded/"},{"categories":["写作"],"content":"colab 别的不说，colab可免费使用GPU 这一点就很强了。基建性质的产品，还得是大厂 可以召唤些好玩的 ","date":"2023-09-30","objectID":"/2023/09/blog-google_colab_embedded/:1:0","tags":["blog","jupyter notebook"],"title":"将google-colab的代码嵌入网站","uri":"/2023/09/blog-google_colab_embedded/"},{"categories":["写作"],"content":"Github gist 如图所示，文件另存为 github gist 登录、关联GitHub 之后就会看到colab的notebook左上角有一个GitHub 的logo。这就表示成功了 ","date":"2023-09-30","objectID":"/2023/09/blog-google_colab_embedded/:2:0","tags":["blog","jupyter notebook"],"title":"将google-colab的代码嵌入网站","uri":"/2023/09/blog-google_colab_embedded/"},{"categories":["写作"],"content":"嵌入网站文章 在刚才带有GitHub logo的页面，“文件” - “View on GitHub” 复制右上角的的代码，并嵌入文章中，like \u003cp\u003e \u003cscript src=\"https://gist.github.com/unclehuzi/83aacb56ce8750b793a0619294fd183d.js\"\u003e\u003c/script\u003e \u003c/p\u003e ","date":"2023-09-30","objectID":"/2023/09/blog-google_colab_embedded/:3:0","tags":["blog","jupyter notebook"],"title":"将google-colab的代码嵌入网站","uri":"/2023/09/blog-google_colab_embedded/"},{"categories":["写作"],"content":"References https://pythonviz.com/colab-jupyter/google-colab-notebook-save-to-github-gist/ ","date":"2023-09-30","objectID":"/2023/09/blog-google_colab_embedded/:4:0","tags":["blog","jupyter notebook"],"title":"将google-colab的代码嵌入网站","uri":"/2023/09/blog-google_colab_embedded/"},{"categories":["数据分析"],"content":"RT，记录下安装流程，防止迷路 最近电脑的Python环境总有些问题，之前刚好了解了homebrew，就干脆把之前的Anaconda卸载了，重新用homebrew安装 ","date":"2023-09-16","objectID":"/2023/09/python-macos_install_anaconda_by_homebrew/:0:0","tags":["Python"],"title":"macOS通过homebrew安装anaconda","uri":"/2023/09/python-macos_install_anaconda_by_homebrew/"},{"categories":["数据分析"],"content":"卸载Anaconda anaconda的官方文档有详细的卸载过程：https://docs.anaconda.com/free/anaconda/install/uninstall/ 通过 anaconda-clean 卸载 删文件夹、删文件 删环境变量 ","date":"2023-09-16","objectID":"/2023/09/python-macos_install_anaconda_by_homebrew/:1:0","tags":["Python"],"title":"macOS通过homebrew安装anaconda","uri":"/2023/09/python-macos_install_anaconda_by_homebrew/"},{"categories":["数据分析"],"content":"homebrew ","date":"2023-09-16","objectID":"/2023/09/python-macos_install_anaconda_by_homebrew/:2:0","tags":["Python"],"title":"macOS通过homebrew安装anaconda","uri":"/2023/09/python-macos_install_anaconda_by_homebrew/"},{"categories":["数据分析"],"content":"安装homebrew 解决网络的问题 执行 “终端代理命令”，让终端也能突破限制 或者 走国内镜像 安装homebrew ","date":"2023-09-16","objectID":"/2023/09/python-macos_install_anaconda_by_homebrew/:2:1","tags":["Python"],"title":"macOS通过homebrew安装anaconda","uri":"/2023/09/python-macos_install_anaconda_by_homebrew/"},{"categories":["数据分析"],"content":"homebrew安装anaconda brew install --cask anaconda ","date":"2023-09-16","objectID":"/2023/09/python-macos_install_anaconda_by_homebrew/:2:2","tags":["Python"],"title":"macOS通过homebrew安装anaconda","uri":"/2023/09/python-macos_install_anaconda_by_homebrew/"},{"categories":["数据分析"],"content":"配置环境 安装完后终端输入 Python 或 conda list 之类的命令是没有反应的，还需要配置下系统环境变量。Windows环境下通过UI界面安装时可直接勾选☑️ # if you're using bash echo 'export PATH=\"/usr/local/anaconda3/bin:$PATH\"' \u003e\u003e ~/.bash_profile # if you're using zsh echo 'export PATH=\"/usr/local/anaconda3/bin:$PATH\"' \u003e\u003e ~/.zshrc source ~/.bash_profile conda init # or... if you're using zsh source ~/.zshrc conda init zsh # ！！！ conda init is available in conda versions 4.6.12 and later. ","date":"2023-09-16","objectID":"/2023/09/python-macos_install_anaconda_by_homebrew/:3:0","tags":["Python"],"title":"macOS通过homebrew安装anaconda","uri":"/2023/09/python-macos_install_anaconda_by_homebrew/"},{"categories":["数据分析"],"content":"配置阿里镜像源 conda 修改 .condarc 文件 channels: - defaults show_channel_urls: true default_channels: - http://mirrors.aliyun.com/anaconda/pkgs/main - http://mirrors.aliyun.com/anaconda/pkgs/r - http://mirrors.aliyun.com/anaconda/pkgs/msys2 custom_channels: conda-forge: http://mirrors.aliyun.com/anaconda/cloud msys2: http://mirrors.aliyun.com/anaconda/cloud bioconda: http://mirrors.aliyun.com/anaconda/cloud menpo: http://mirrors.aliyun.com/anaconda/cloud pytorch: http://mirrors.aliyun.com/anaconda/cloud simpleitk: http://mirrors.aliyun.com/anaconda/cloud pip 修改 .pip/pip.conf 文件 [global] index-url = http://mirrors.aliyun.com/pypi/simple/ [install] trusted-host=mirrors.aliyun.com ","date":"2023-09-16","objectID":"/2023/09/python-macos_install_anaconda_by_homebrew/:3:1","tags":["Python"],"title":"macOS通过homebrew安装anaconda","uri":"/2023/09/python-macos_install_anaconda_by_homebrew/"},{"categories":["数据分析"],"content":"References Uninstalling Anaconda Distribution Homebrew brew update 长时间没反应（或卡在 Updating Homebrew…） Get your anaconda ready after brew install | inDev. Journal 阿里云Anaconda镜像 阿里云pip镜像 ","date":"2023-09-16","objectID":"/2023/09/python-macos_install_anaconda_by_homebrew/:4:0","tags":["Python"],"title":"macOS通过homebrew安装anaconda","uri":"/2023/09/python-macos_install_anaconda_by_homebrew/"},{"categories":["数据分析","读书笔记"],"content":"coursera上贝叶斯统计专项课程","date":"2023-09-03","objectID":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/","tags":["课程笔记","贝叶斯","统计学"],"title":"coursera课程-Review of distributions","uri":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/"},{"categories":["数据分析","读书笔记"],"content":"Bernoulli and binomial distributions Bernoulli distribution is used when we have two possible outcomes, such as flipping a coin, where it could be heads and tails, or the cases where we have a success or a failure. $X \\sim B(p)$ : A random variable $X$ follows a Bernoulli distribution with probability $p$, where $p$ is probability of success, or probability of heads. 这里用 Indicator Function 表示$x$ 取值为0,1 的情况 $$ \\begin{align*} f(X=x \\mid p) \u0026= f(x \\mid p) \\newline \u0026= p^x(1-p)^{1-x} I_{{x \\in {0,1} }}(x) \\newline \\end{align*} $$ 「ChatGPT-3.5」 The indicator function, also referred to as the characteristic function, is a mathematical construct used to represent whether a certain condition is satisfied or not. It is commonly denoted by symbols such as I or 1. The indicator function takes an element from a set and outputs either 1 or 0, depending on whether the element meets a specified condition. In formal terms, for a set A and an element x, the indicator function I_A(x) is defined as: $$ \\begin{align*} I_A(x) = \\begin{cases} 1 \u0026 \\text{if $x \\in A$ (x belongs to $A$) } \\newline 0 \u0026 \\text{if $x \\notin A$ (x does not belong to $A$) } \\end{cases} \\end{align*} $$ In simpler words, the indicator function serves as a way to “indicate” whether an element is part of a set (condition is true) or not (condition is false). Indicator functions find applications in various mathematical fields, including probability theory, statistics, and analysis. They are used to express events, define indicator variables, calculate expected values, and simplify mathematical expressions involving conditions or events. In some textbooks, they make a strong distinction between discrete variables where these were probably mass functions, and continues variables where these are probability density functions. Bernoulli distribution的期望和方差 $$ \\begin{align*} E(X) \u0026= \\sum_{x} x \\cdot P(X=x) \\newline \u0026= 1 \\cdot p + 0 \\cdot (1-p) \\newline \u0026= p \\end{align*} $$ $$ \\begin{align*} Var(X) \u0026= \\sum_{x} (x- E(x))^2 \\cdot P(X=x) \\newline \u0026= (1-p)^2 \\cdot p + (0-p)^2 \\cdot (1-p) \\newline \u0026= p(1-p) \\end{align*} $$ The generalization of the Bernoulli when we have N repeated trials is a Binomial. $X \\sim Bin(n,p)$ $$ P(X = x \\mid p) = \\binom{n}{x} p^x (1 - p)^{n - x} \\newline \\binom{n}{x} = \\frac{n!}{x!(n-x)!} ; \\text{for $x \\in { 0,1,…,n } $} $$ 期望和方差：$E(X)=np, ; Var(X)=np(1-p)$ ","date":"2023-09-03","objectID":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/:1:0","tags":["课程笔记","贝叶斯","统计学"],"title":"coursera课程-Review of distributions","uri":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/"},{"categories":["数据分析","读书笔记"],"content":"Uniform distribution We can define a continuous random variable based on its probability density function(PDF). 以Uniform distribution为例， $X \\sim U(0,1)$ $$ \\begin{align*} f(x) \u0026= \\begin{cases} 1 \u0026 x \\in [0,1] \\newline 0 \u0026 \\text{otherwise} \\end{cases} \\newline \u0026= I_{{0 \\leq x \\leq 1}}(x) \\end{align*} $$ Python 生成 $U(0,1)$ PDF # FROM ChatGPT-3.5 import numpy as np import matplotlib.pyplot as plt x = np.linspace(0, 1, 1000) # 创建一个横坐标范围从0到1的数据点 y = np.ones_like(x) # 每个数据点的纵坐标值都是1，因为在U(0,1)均匀分布中概率密度是常数 fig, ax = plt.subplots() ax.plot(x, y, color='blue') ax.set_xlabel('x') ax.set_ylabel('$f(x)$') ax.set_title('$X \\sim U(0,1)$') # 设置纵轴上限为1.1 ax.set_ylim(0, 1.25) # 去除上边框和右边框 ax.spines['top'].set_visible(False) ax.spines['right'].set_visible(False) # 绘制垂直线段 plt.plot([0, 0], [0, 1], color='gray', linestyle='dashed', linewidth=1) plt.plot([1, 1], [0, 1], color='gray', linestyle='dashed', linewidth=1) plt.show() $$ P(0\u003cx\u003c \\frac{1}{2})=\\int_{0}^{\\frac{1}{2}} f(x) , dx=\\frac{1}{2}=P(0 \\leq x \\leq \\frac{1}{2}) \\newline P(x=\\frac{1}{2})=0 $$ Some key rules for probability density functions: $\\int_{-\\infty}^{\\infty} f(x) , dx=1$；$f(x) \\geq 0$ 通用型Uniform distribution，$X \\sim U(\\theta_1,\\theta_2)$ ⇒ $f(x|\\theta_1,\\theta_2)=\\frac{1}{\\theta_2-\\theta_1}I_{{\\theta_1 \\leq x \\leq \\theta_2 }}(x)$ 关于连续型随机变量的期望 the expected value for a continuous random variable $$ \\begin{align*} \u0026 E(X)=\\int_{-\\infty}^{\\infty} x f(x) , dx \\newline \u0026 E(g(X))=\\int g(x)f(x) , dx \\newline \u0026 E(CX)=cE(x) \\text{,$c$为常数} \\newline \u0026 E(X+Y) = E(X) + E(Y) \\newline \u0026 \\text{if $X \\perp Y$, } E(XY)=E(X)E(Y) \\end{align*} $$ ","date":"2023-09-03","objectID":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/:2:0","tags":["课程笔记","贝叶斯","统计学"],"title":"coursera课程-Review of distributions","uri":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/"},{"categories":["数据分析","读书笔记"],"content":"Exponential and normal distributions ","date":"2023-09-03","objectID":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/:3:0","tags":["课程笔记","贝叶斯","统计学"],"title":"coursera课程-Review of distributions","uri":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/"},{"categories":["数据分析","读书笔记"],"content":"Exponential distribution 「ChatGPT-3.5」 The Exponential distribution is a mathematical model often used to describe the time between events in situations where events occur randomly and independently at a constant average rate. It’s commonly used in fields like queuing theory, reliability analysis, and telecommunications. Key points about the Exponential distribution: Probability Density Function (PDF): The distribution is defined by the equation ( $f(x | \\lambda) = \\lambda e^{-\\lambda x} ，\\text{for $x \\geq 0$}$ ), where ($x$) is the time between events, and ($\\lambda$) is the rate parameter. Memorylessness: It has the property that the probability of an event occurring in a given interval is not influenced by the past. This means that the distribution of time until the next event remains the same, regardless of how much time has already passed. Cumulative Distribution Function (CDF): The CDF is ( $F(x | \\lambda) = 1 - e^{-\\lambda x}$ ), which provides the probability that an event will occur before a certain time ($x$). Mean and Variance: The mean (average) time between events is ($1/\\lambda$), and the variance is ($1/\\lambda^2$). The Exponential distribution is widely used due to its simplicity and relevance in modeling various real-world scenarios involving random occurrences over time. code import numpy as np import matplotlib.pyplot as plt import scipy.stats as stats # Parameters for the exponential distributions (rate) params = [ (0.5, 'λ=0.5'), (1, 'λ=1'), (2, 'λ=2') ] # Create a figure and axis fig, ax = plt.subplots(figsize=(10, 6)) # Plotting for lambd, label in params: x = np.linspace(0, 10, 100) y = lambd * np.exp(-lambd * x) #y = stats.expon(scale=1/lambd).pdf(x) ax.plot(x, y, label=label) ax.set_xlabel('x') ax.set_ylabel('Probability Density') ax.set_title('Exponential Distribution') ax.legend() ax.grid(True) # 去除上边框和右边框 ax.spines['top'].set_visible(False) ax.spines['right'].set_visible(False) # Display the plot plt.show() ","date":"2023-09-03","objectID":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/:3:1","tags":["课程笔记","贝叶斯","统计学"],"title":"coursera课程-Review of distributions","uri":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/"},{"categories":["数据分析","读书笔记"],"content":"Normal distribution 「ChatGPT-3.5」 The Normal distribution, also known as the Gaussian distribution, is a bell-shaped curve that describes the distribution of many types of data. It is symmetrical and its mean, median, and mode are all equal. Key points: Bell-shaped: Its graph is a symmetrical bell-shaped curve. Parameters: It is defined by two parameters: the mean ($\\mu$) and the standard deviation ($\\sigma$). 68-95-99.7 Rule: About 68% of the data falls within one standard deviation of the mean, 95% within two standard deviations, and 99.7% within three. Applications: It’s widely used in statistics, science, and engineering due to many natural phenomena and processes being approximately normally distributed. The formula for its probability density function (PDF) is: $$ f(x | \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} $$ However, for many practical applications, understanding its bell shape and the 68-95-99.7 rule is often more crucial than knowing its exact formula. code import numpy as np import matplotlib.pyplot as plt import scipy.stats as stats # Parameters for the normal distributions params = [ (0, 1, '$\\mu=0, \\sigma=1$'), (2, 0.5, '$\\mu=2, \\sigma=0.5$'), (-2, 2.5, '$\\mu=-2, \\sigma=2.5$') ] fig, ax = plt.subplots(figsize=(10, 6)) for mu, sigma, label in params: x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100) y = stats.norm.pdf(x, mu, sigma) ax.plot(x, y, label=label) # 去除上边框和右边框 ax.spines['top'].set_visible(False) ax.spines['right'].set_visible(False) plt.xlabel('x') plt.ylabel('Probability Density') plt.title('Normal Distribution') plt.legend() plt.grid(True) plt.show() ","date":"2023-09-03","objectID":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/:3:2","tags":["课程笔记","贝叶斯","统计学"],"title":"coursera课程-Review of distributions","uri":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/"},{"categories":["数据分析","读书笔记"],"content":"Supplementary material for Lesson 3 https://d3c33hcgiwev3.cloudfront.net/29f7eaaba3ac0d35ee74f8bd61aafc39_L3_supp.pdf?Expires=1692144000\u0026Signature=KA2KF0vx3gwhBdV~Qp1XAF3vmfziOf~pLoeyXkGI1sDGXz5P33eynAVVDQoyGfg3mFzxs0Jil10bamlf2z6rm8fb3cqMK7mVH5D~BjvT-W0MxKqjKUKvJsiiq6g1u23yDIWzSOxb39qZp1ISLzVL27Pqkdb6YgaqxrjsxaFAaOE\u0026Key-Pair-Id=APKAJLTNE6QMUY6HBC5A ","date":"2023-09-03","objectID":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/:4:0","tags":["课程笔记","贝叶斯","统计学"],"title":"coursera课程-Review of distributions","uri":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/"},{"categories":["数据分析","读书笔记"],"content":"Additional Discrete Distributions ","date":"2023-09-03","objectID":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/:5:0","tags":["课程笔记","贝叶斯","统计学"],"title":"coursera课程-Review of distributions","uri":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/"},{"categories":["数据分析","读书笔记"],"content":"Geometric distribution The geometric distribution is the number of trials needed to get the first success, i.e., the number of Bernoulli events until a success is observed, such as the first head when flipping a coin. It takes values on the positive integers starting with one (since at least one trial is needed to observe a success). $$ X \\sim Geo(p) \\newline P(X=x|p)=p(1-p)^{x-1} \\text{for $x=1,2,…$} \\newline E(X)=\\frac{1}{p} $$ If the probability of getting a success is $p$, then the expected number of trials until the first success is $\\frac{1}{p}$. 🌰 Example: What is the probability that we flip a fair coin four times and don’t see any heads? This is the same as asking what is $P(X \u003e 4)$ where $X \\sim Geo(1/2)$ . $$ \\begin{align*} P(X\u003e4) \u0026= 1-P(X=1)-P(X=2)-P(X=3)-p(X=4) \\newline \u0026=1-\\frac{1}{2}-\\frac{1}{2} (\\frac{1}{2})-\\frac{1}{2} (\\frac{1}{2})^2-\\frac{1}{2} (\\frac{1}{2})^3 \\newline \u0026= \\frac{1}{16} \\end{align*} $$ code import numpy as np import matplotlib.pyplot as plt from scipy.stats import geom # Parameters for the geometric distribution params = [ (0.3, '$p=0.3$'), (0.5, '$p=0.5$'), (0.7, '$p=0.7$') ] fig, ax = plt.subplots(figsize=(10, 6)) for p, label in params: x = np.arange(1, 16) y = geom.pmf(x, p) # Probability mass function ax.plot(x, y, marker='o', linestyle='-', label=label) # Remove top and right borders ax.spines['top'].set_visible(False) ax.spines['right'].set_visible(False) plt.xlabel('Number of Trials') plt.ylabel('Probability') plt.title('Geometric Distribution') plt.legend() plt.grid(True) plt.show() ","date":"2023-09-03","objectID":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/:5:1","tags":["课程笔记","贝叶斯","统计学"],"title":"coursera课程-Review of distributions","uri":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/"},{"categories":["数据分析","读书笔记"],"content":"Multinomial distribution Another generalization of the Bernoulli and the binomial is the multinomial distribution, which is like a binomial when there are more than two possible outcomes. Suppose we have $n$ trials and there are $k$ different possible outcomes which occur with probabilities $p_1,p_2,…,p_k$ . For example, we are rolling a six-sided die that might be loaded so that the sides are not equally likely, then $n$ is the total number of rolls, $k=6$, $p_1$ is the probability of rolling a one, and we denote by $x_1,…,x_6$ a possible outcome for the number of times we observe rolls of each of one through six, where $\\sum\\limits_{i=1}^{6}x_i=n \\text{ and } \\sum\\limits_{i=1}^{6}p_i=1$. $$ f(x_1,\\dots ,x_k|p_1,\\dots ,p_k)=\\frac{n!}{x_1!\\dots x_k !}p_1^{x_1}\\dots p_k^{x_k} $$ 模拟code import numpy as np import matplotlib.pyplot as plt from scipy.stats import multinomial # set seed for reproductibility np.random.seed(999) # Parameters for the multinomial distribution k = 3 n = 12 # number of trials (games in one tourment) pvals = [0.4, 0.35, 0.25] sizes =[] # number of tournments played p = [] # a list to hold ratios (converge to prob) that player 1 wins 7 times, player 2 wins 2 times and 3 ties # 公式计算 f_x = round(multinomial.pmf([7,2,3],n=n,p=pvals),4) # 模拟 fig, ax = plt.subplots(figsize=(10, 4)) for size in np.logspace(2,4): # the line below is where we actually generate discrete random variables according the multinomial distribution outcomes = np.random.multinomial(n, pvals, size=int(size)) # let's count the ratio of the expected outcome over all the outcomes - this will lastly converge to the probability prob = sum((outcomes[:,0]==7)\u0026(outcomes[:,1]==2)\u0026(outcomes[:,2]==3))/len(outcomes) p.append(prob) sizes.append(int(size)) ax.plot(sizes,p,'o-') ax.plot(sizes,[f_x]*len(sizes),'--r') line1 = r\"$p_1,p_2,p_3=(0.4, 0.35, 0.25)$\" # 文本内容 line2 = r\"$x_1,x_2,x_3=(7,2,3)$\" # 文本内容 x_pos = 0.95 # x 坐标位置（相对于轴范围的比例） y_pos = 0.95 # y 坐标位置（相对于轴范围的比例） ax.text(x_pos, y_pos, line2+\"\\n\"+line1, transform=ax.transAxes, fontsize=12, ha='right', va='top') # Remove top and right borders ax.spines['top'].set_visible(False) ax.spines['right'].set_visible(False) plt.xlim(xmin=0) plt.xlabel('Number of Drawings') plt.ylabel('$p(x_1,x_2,x_3|p_1,p_2,p_3)$') plt.title('Theoretical $f(x_1,x_2,x_3|p_1,p_2,p_3)={}$'.format(f_x)) #plt.grid(True) plt.show() ","date":"2023-09-03","objectID":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/:5:2","tags":["课程笔记","贝叶斯","统计学"],"title":"coursera课程-Review of distributions","uri":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/"},{"categories":["数据分析","读书笔记"],"content":"Poisson distribution The Poisson distribution is used for counts, and arises in a variety of situations. The parameter $\\lambda \u003e 0$ is the rate at which we expect to observe the thing we are counting. $$ X \\sim Pois(\\lambda) \\newline P(X=x|\\lambda)=\\frac{\\lambda^xexp(- \\lambda)}{x!} \\text{ for $x=0,1,2,\\dots$} \\newline E(X)=\\lambda \\newline Var(X) =\\lambda $$ 🌰 Example: Significant earthquakes occur in the Western United States approximately following a Poisson process with rate of two earthquakes per week. What is the probability there will be at least 3 earthquakes in the next two weeks? 未来两周发生地震的次数记为$X$，由题意得，$X \\sim Pois(4)$. $$ \\begin{align*} P(X\\geq 3) \u0026= 1-P(X\\leq2) \\newline \u0026=1- P(X=0)- P(X=1)- P(X=2) \\newline \u0026=1 - \\frac{4^0 exp(- 4)}{0!} -\\frac{4^1 exp(- 4)}{1!} - \\frac{4^2 exp(- 4)}{2!} \\newline \u0026= 1-13e^{-4} \\newline \u0026=0.762 \\end{align*} $$ ","date":"2023-09-03","objectID":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/:5:3","tags":["课程笔记","贝叶斯","统计学"],"title":"coursera课程-Review of distributions","uri":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/"},{"categories":["数据分析","读书笔记"],"content":"Continuous Distributions ","date":"2023-09-03","objectID":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/:6:0","tags":["课程笔记","贝叶斯","统计学"],"title":"coursera课程-Review of distributions","uri":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/"},{"categories":["数据分析","读书笔记"],"content":"Gamma If $X_1,X_2,\\dots,X_n$ are independent (and identically distributed $Exp(\\lambda)$) waiting times between successive events, then the total waiting time for all n events to occur $Y=\\sum_{i=1}^{n}X_i$ will follow a gamma distribution with shape parameter $\\alpha=n$ and rate parameter $\\beta=\\lambda$. $$ Y \\sim Gamma(\\alpha,\\beta) \\newline f(y|\\alpha,\\beta)=\\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}y^{\\alpha-1}e^{-\\beta y}I_{ {y \\geq0}}(y) \\newline E(Y) = \\frac{\\alpha}{\\beta} \\newline Var(Y) = \\frac{\\alpha}{\\beta^2} $$ where $\\Gamma(·)$ is the gamma function, a generalization of the factorial function which can accept non-integer arguments. If $n$ is a positive integer, then $\\Gamma(n) = (n − 1)!$ . Note also that $\\alpha\u003e 0$ and $\\beta \u003e 0$ . The exponential distribution is a special case of the gamma distribution with $\\alpha = 1$. The gamma distribution commonly appears in statistical problems, as we will see in this course. It is used to model positive-valued, continuous quantities whose distribution is right-skewed. As $\\alpha$ increases, the gamma distribution more closely resembles the normal distribution. code import numpy as np import matplotlib.pyplot as plt from scipy.stats import gamma # Parameters for the gamma distribution params = [ (1, 0.5, '$\\\\alpha=1, \\\\beta=0.5$'), (5, 1, '$\\\\alpha=5, \\\\beta=1$'), (8, 2, '$\\\\alpha=8, \\\\beta=2$') ] fig, ax = plt.subplots(figsize=(10, 6)) for alpha, beta, label in params: x = np.linspace(gamma.ppf(0.001, alpha, scale=1/beta), gamma.ppf(0.999, alpha, scale=1/beta), 100) y = gamma.pdf(x, alpha, scale=1/beta) # Probability density function ax.plot(x, y, linestyle='-', label=label) # Remove top and right borders ax.spines['top'].set_visible(False) ax.spines['right'].set_visible(False) plt.xlabel('X') plt.ylabel('Probability Density') plt.title('Gamma Distribution') plt.legend() plt.grid(True) plt.show() ","date":"2023-09-03","objectID":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/:6:1","tags":["课程笔记","贝叶斯","统计学"],"title":"coursera课程-Review of distributions","uri":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/"},{"categories":["数据分析","读书笔记"],"content":"Beta The beta distribution is used for random variables which take on values between 0 and 1. For this reason (and other reasons we will see later in the course), the beta distribution is commonly used to model probabilities $$ X \\sim Beta(\\alpha,\\beta) \\newline f(x|\\alpha,\\beta)=\\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}x^{\\alpha-1}(1-x)^{\\beta -1}I_{ {0\u003cx\u003c1}}(x) \\newline E(X) = \\frac{\\alpha}{\\alpha + \\beta} \\newline Var(X) = \\frac{\\alpha \\beta}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)} $$ where $\\Gamma(·)$ is the gamma function introduced with the gamma distribution. Note also that $\\alpha\u003e 0$ and $\\beta \u003e 0$ . The standard Uniform(0, 1) distribution is a special case of the betadistribution with $\\alpha=\\beta=1$ . code import numpy as np import matplotlib.pyplot as plt from scipy.stats import beta # Parameters for the Beta distribution params = [ (2, 5, '$\\\\alpha=2, \\\\beta=5$'), (5, 1, '$\\\\alpha=5, \\\\beta=1$'), (2, 2, '$\\\\alpha=2, \\\\beta=2$') ] fig, ax = plt.subplots(figsize=(10, 6)) for a, b, label in params: x = np.linspace(0, 1, 100) y = beta.pdf(x, a, b) # Probability density function ax.plot(x, y, label=label) # Remove top and right borders ax.spines['top'].set_visible(False) ax.spines['right'].set_visible(False) plt.xlabel('Value') plt.ylabel('Probability Density') plt.title('Beta Distribution') plt.legend() plt.grid(True) plt.show() ","date":"2023-09-03","objectID":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/:6:2","tags":["课程笔记","贝叶斯","统计学"],"title":"coursera课程-Review of distributions","uri":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/"},{"categories":["数据分析","读书笔记"],"content":"t If we have normal data, we can use $\\bar{X} \\sim N(\\mu,\\frac{\\sigma^2}{n})$ to help us estimate the mean $\\mu$. 标准正态分布： $\\frac{\\bar{X} - \\mu}{\\sigma/ \\sqrt{n}} \\sim N(0,1)$. However, we may not know the value of $\\sigma$. If we estimate it from data, we can replace it with $S=\\sqrt{\\sum_i(X_i - \\bar{X})^2/(n-1)}$ , the sample standard deviation. This causes the $\\frac{\\bar{X} - \\mu}{\\sigma/ \\sqrt{n}}$ to no longer be distributed as standard normal, but as a standard t distribution with $\\nu=n-1$ degrees of freedom. $$ Y \\sim t_{\\nu} \\newline f(y) = \\frac{\\Gamma(\\frac{\\nu +1}{2})}{\\Gamma(\\frac{\\nu}{2}) \\sqrt{\\nu \\pi}}(1+\\frac{y^2}{\\nu})^{-(\\frac{\\nu + 1}{2})} \\newline E(Y) = 0 \\text{, if $\\nu \u003e 1$ } \\newline Var(Y) = \\frac{\\nu}{\\nu - 2} \\text{, if $\\nu \u003e 2$} $$ code import numpy as np import matplotlib.pyplot as plt from scipy.stats import t # Parameters for the t distribution params = [ (2, '$df=2$'), (5, '$df=5$'), (10, '$df=10$') ] fig, axes = plt.subplots(1, 2, figsize=(12, 6)) # Plot probability density function axes[0].set_title('t Distribution - Probability Density Function') for df, label in params: x = np.linspace(-4, 4, 100) y = t.pdf(x, df) # Probability density function axes[0].plot(x, y, label=label) # Plot cumulative distribution function axes[1].set_title('t Distribution - Cumulative Distribution Function') for df, label in params: x = np.linspace(-4, 4, 100) y = t.cdf(x, df) # Cumulative distribution function axes[1].plot(x, y, label=label) # Remove top and right borders for ax in axes: ax.spines['top'].set_visible(False) ax.spines['right'].set_visible(False) axes[0].set_xlabel('Value') axes[0].set_ylabel('Probability Density') axes[1].set_xlabel('Value') axes[1].set_ylabel('Cumulative Probability') axes[0].legend() axes[1].legend() axes[0].grid(True) axes[1].grid(True) plt.tight_layout() plt.show() 作者：吴端 链接：https://www.zhihu.com/question/34866983/answer/1540230125 来源：知乎 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 分布分为离散分布和连续分布。连续分布几乎都能找到对应的离散分布。因为连续分布本质上就是把离散分布中投硬币的次数，变成连续的时间长度。把每次投硬币的正反面概率，变成单位时间内出现正面的概率密度。 下面我从贝努利实验出发，把所有分布的关系梳理出来： 贝努利实验：投硬币，正面反面概率分别为p，1-p 二项分布：如果把贝努利实验连续做n次，出现正面的次数服从的分布。 二项分布的极限：泊松分布。给定时间内时间发生次数的分布。 负二项分布：在贝努利实验中，如果想让正面出现n次，需要做的实验次数的分布。 负二项分布的极限：gamma分布。问如果指定事件出现N次，需要等待的时间。 二项分布与负二项分布的关系：二项分布是在固定实验次数情况下，问结果分布。负二项分布是在固定结果情况下问实验次数分布。一个是在固定投入问产出，一个是在固定产出下问投入。 几何分布：n重贝努利实验，正面第一次出现时的实验次数。 几何分布的极限：指数分布。事件第一次发生等待的时间。 几何分布与负二项分布的关系：负二项分布是N个几何分布的和。相当于做N次几何分布，事件正好发生N次。各几何分布的实验次数之和就是负二项分布的总次数。 指数分布与gamma分布的关系：N次指数分布时间之和就是gamma分布中事件发生N次等待总时间。 如果课本能这样组织这些知识，估计也没有人困惑为啥整这么多奇怪的分布，到底有什么用。推倒过程反而没那么重要 ","date":"2023-09-03","objectID":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/:6:3","tags":["课程笔记","贝叶斯","统计学"],"title":"coursera课程-Review of distributions","uri":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/"},{"categories":["数据分析","读书笔记"],"content":"Central Limit Theorem The Central Limit Theorem is one of the most important results in statistics, basically saying that with sufficiently large sample sizes, the sample average approximately follows a normal distribution. In formal mathematical notation, the Central Limit Theorem says: Let $X_1,\\dots ,X_n$ be independent and identically distributed with $E(X_i)=\\mu \\text{ and } Var(X_i)= \\sigma^2,0 \u003c \\sigma^2 \u003c \\infty$, then, $$ \\frac{\\sqrt{n}(\\bar{X}-\\mu)}{\\sigma} \\sim N(0,1) $$ ","date":"2023-09-03","objectID":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/:7:0","tags":["课程笔记","贝叶斯","统计学"],"title":"coursera课程-Review of distributions","uri":"/2023/09/da-bayesian_statistics-coursera-from_concept_to_data_analysis-review_of_distributions/"},{"categories":["数据分析","读书笔记"],"content":"coursera上贝叶斯统计专项课程","date":"2023-08-10","objectID":"/2023/08/da-bayesian_statistics-coursera-from_concept_to_data_analysis/","tags":["课程笔记","贝叶斯","统计学"],"title":"coursera课程-Probability and Bayes’ Theorem","uri":"/2023/08/da-bayesian_statistics-coursera-from_concept_to_data_analysis/"},{"categories":["数据分析","读书笔记"],"content":"coursera课程-简单回顾Probability and Bayes’ Theorem ","date":"2023-08-10","objectID":"/2023/08/da-bayesian_statistics-coursera-from_concept_to_data_analysis/:0:0","tags":["课程笔记","贝叶斯","统计学"],"title":"coursera课程-Probability and Bayes’ Theorem","uri":"/2023/08/da-bayesian_statistics-coursera-from_concept_to_data_analysis/"},{"categories":["数据分析","读书笔记"],"content":"Module overview https://d3c33hcgiwev3.cloudfront.net/CE-7SC5rEeayHwq9iLdlAw.processed/full/720p/index.mp4?Expires=1690502400\u0026Signature=Bk1Qel4SY~MS5TN3fDOtD0JtZfs0T1itCrm4OGXHCKcfowhAZKg8TRGt8CZjZLSSfUn69bJU473N8NDhJt4THk5xg06KnOP~8AJio6GuKXR-SiqUJgxQM24xxmMLwWF80tJDrnqSyqlaHSRJRG6WOKRQWLHXFOwzbUNmeSAqPSM_\u0026Key-Pair-Id=APKAJLTNE6QMUY6HBC5A There are two main philosophies of probability and statistics, Bayesian and Frequentist. Probability 模块儿会快速回顾些 frequent distant inference 视频内容方面比较少，更多是在exercises，labeled as quizzes ","date":"2023-08-10","objectID":"/2023/08/da-bayesian_statistics-coursera-from_concept_to_data_analysis/:1:0","tags":["课程笔记","贝叶斯","统计学"],"title":"coursera课程-Probability and Bayes’ Theorem","uri":"/2023/08/da-bayesian_statistics-coursera-from_concept_to_data_analysis/"},{"categories":["数据分析","读书笔记"],"content":"Probability ","date":"2023-08-10","objectID":"/2023/08/da-bayesian_statistics-coursera-from_concept_to_data_analysis/:2:0","tags":["课程笔记","贝叶斯","统计学"],"title":"coursera课程-Probability and Bayes’ Theorem","uri":"/2023/08/da-bayesian_statistics-coursera-from_concept_to_data_analysis/"},{"categories":["数据分析","读书笔记"],"content":"Background for Lesson 1 https://d3c33hcgiwev3.cloudfront.net/2ffa04a4be97e282ca9e65d96897a77c_L1_background.pdf?Expires=1690502400\u0026Signature=Hn2xEnhq7C9UuERyL6S~XR0GNxNuupCf9ryTJHFVF92tpesy502YndG2csd5ae0kVQEXDveKgs-fUBb9VJss6gJrc8hdZTYlDNEX4~047I3mqHYbw40UqMNsDPWSmR~rcb7ZhgAU9qfVsPbzmIAxNkmJO6Umik86H4oo5zawwvI\u0026Key-Pair-Id=APKAJLTNE6QMUY6HBC5A Rules of Probability Probabilities must be between zero and one, i.e., 0 ≤ P(A) ≤ 1 for any event A. Probabilities add to one, i.e., if we add up the probabilities of all possible events, those probabilities must add to one. The complement of an event, $A^ \\complement$, means that the event does not happen. Since probabilities must add to one, $P(A^\\complement)=1-P(A)$ （之前见的是 $\\overline{A}$） $P(A \\cup B)=P(A)+P(B)-P(A \\cap B)$. where $\\cup$ represents union (“or”) and $\\cap$ represents intersection (“and”) Odds The odds for event A, denoted $\\mathcal{O}(A)$ is defined as $\\mathcal{O}(A)=\\frac{P(A)}{P(A^ \\complement)}=\\frac{P(A)}{1-P(A)}$ Expectation The expected value of a random variable $X$ is a weighted average of values $X$ can take, with weights given by the probabilities of those values. $$ E(X)=\\sum_{i=1}^{n} x_i \\cdot P(X=x_i) $$ For example, the expected value of a fair six-sided die would be $$ E(X)=\\sum_{i=1}^{n} x_i \\cdot P(X=x_i)=\\sum_{i=1}^{n} i \\cdot \\frac{1}{6}=3.5 $$ Note that the die cannot achieve this value, but if you were to roll the die many times and average the values, the result would likely be close to $3.5$. ","date":"2023-08-10","objectID":"/2023/08/da-bayesian_statistics-coursera-from_concept_to_data_analysis/:2:1","tags":["课程笔记","贝叶斯","统计学"],"title":"coursera课程-Probability and Bayes’ Theorem","uri":"/2023/08/da-bayesian_statistics-coursera-from_concept_to_data_analysis/"},{"categories":["数据分析","读书笔记"],"content":"Classical, frequentist and bayesian probability There are three different frameworks under which we can define probabilities. Classical framework outcomes that are equally likely have equal probabilities. Frequentist framework Frequentist definition, requires us to have a hypothetical infinite sequence of events, and then we look at the relevant frequency, in that hypothetical infinite sequence. Bayesian framework 偏主观。尽管如此，大多数情况下结果也优于“频率学派” Bayesian perspective is one of personal perspective. Your probability represents your own perspective, it’s your measure of uncertainty, and it takes into account what you know about a particular problem. So inherently a subjective approach to probability, but it can work well in a mathematically rigorous foundation, and it leads to much more intuitive results in many cases than the Frequentist approach. Suppose you’d be willing to take the bet that if it rains tomorrow, you win \\$4. If it doesn’t rain tomorrow, you lose \\$1, or whatever your local currency is. 若认为公平，换个说法理应也会参加：if it rains, you lose $4. And if no rain, you win a \\$1.（插播：行为经济学告诉你，大多数人面对这俩说法的态度是不一样的，不一定就会选择后者，因为后者放大了损失。尽管数学上这俩收益的期望=0） ","date":"2023-08-10","objectID":"/2023/08/da-bayesian_statistics-coursera-from_concept_to_data_analysis/:2:2","tags":["课程笔记","贝叶斯","统计学"],"title":"coursera课程-Probability and Bayes’ Theorem","uri":"/2023/08/da-bayesian_statistics-coursera-from_concept_to_data_analysis/"},{"categories":["数据分析","读书笔记"],"content":"Bayes’ theorem Bayes’ theorem is the theoretical underpinning of most of what we do within the Bayesian statistical framework. ","date":"2023-08-10","objectID":"/2023/08/da-bayesian_statistics-coursera-from_concept_to_data_analysis/:3:0","tags":["课程笔记","贝叶斯","统计学"],"title":"coursera课程-Probability and Bayes’ Theorem","uri":"/2023/08/da-bayesian_statistics-coursera-from_concept_to_data_analysis/"},{"categories":["数据分析","读书笔记"],"content":"Conditional probability Conditional probability is when we’re trying to consider two events that are related to each other. $$ P(A \\mid B)=\\frac{P(A \\cap B)}{P(B)} $$ 🌰 一个例子：30个学生，9个女生；12个学计算机，学计算机中4个女生。 $$ \\begin{align*} \u0026 P(Female)=\\frac{9}{30}=\\frac{3}{10} \\newline \u0026 P(CS)=\\frac{12}{30}=\\frac{2}{5} \\newline \u0026 P(Female \\cap CS)=\\frac{4}{30}=\\frac{2}{15} \\newline \u0026 P(Female \\mid CS)=\\frac{4}{12}=\\frac{1}{3} \\newline \\end{align*} $$ ⇒ $$ \\begin{align*} P(CS \\mid Female) \u0026= \\frac{P(CS \\cap Female)}{P(Female)} \\newline \u0026 = \\frac{\\frac{2}{15}}{\\frac{3}{10}}=\\frac{4}{9} \\newline P(Female \\mid CS^{\\complement}) \u0026= \\frac{P(Female \\cap CS^{\\complement})}{P(CS^{\\complement})} \\newline \u0026= \\frac{\\frac{5}{30}}{\\frac{18}{30}}=\\frac{5}{18} \\end{align*} $$ There’s a concept of independence, which is when one event doesn’t depend on the other. When two events are independent, we have that the probability of A given B is equal to just the probability of A, it doesn’t matter whether, or not B occurred. When this is true, we also get that the probability of A and B happening is just the probability of A times the probability of B. 事件A、B独立，⇒ $P(A \\mid B)=P(A)$； $P(A\\cap B)=P(A) \\times P(B)$ ","date":"2023-08-10","objectID":"/2023/08/da-bayesian_statistics-coursera-from_concept_to_data_analysis/:3:1","tags":["课程笔记","贝叶斯","统计学"],"title":"coursera课程-Probability and Bayes’ Theorem","uri":"/2023/08/da-bayesian_statistics-coursera-from_concept_to_data_analysis/"},{"categories":["数据分析","读书笔记"],"content":"Bayes’ theorem $$ P(A \\mid B)=\\frac{P(A \\cap B)}{P(B)}=\\frac{P(B \\mid A)\\times P(A)}{P(B \\mid A)\\times P(A)+P(B \\mid A^{\\complement})\\times P(A^{\\complement})} $$ 🌰 一个例子：test for HIV antibodies known as the ELISA test 已知，$P(+ \\mid HIV)=0.977,P(- \\mid no HIV)=0.926,P(HIV)=0.0026$ ⇒ $$ \\begin{align*} P(HIV \\mid +) \u0026= \\frac{P(HIV \\cap +)}{P(+)} \\newline \u0026=\\frac{P(+ \\mid HIV)\\times P(HIV)}{P(+ \\mid HIV)\\times P(HIV)+P(+ \\mid noHIV)\\times P(noHIV)} \\newline \u0026= 0.033 \\end{align*} $$ Bayes’ Theorem is an important part of our approach to Bayesian statistics. We can use it to update our information. We start with prior beliefs, we’ll collect data, we’ll then condition on the data to lead to our posterior beliefs. Bayes’ Theorem is the coherent way to do this updating. ","date":"2023-08-10","objectID":"/2023/08/da-bayesian_statistics-coursera-from_concept_to_data_analysis/:3:2","tags":["课程笔记","贝叶斯","统计学"],"title":"coursera课程-Probability and Bayes’ Theorem","uri":"/2023/08/da-bayesian_statistics-coursera-from_concept_to_data_analysis/"},{"categories":["数据分析","读书笔记"],"content":"Supplementary material for Lesson 2 https://d3c33hcgiwev3.cloudfront.net/J9_9-JhwEeiAaxI_EQt0HA_2844d980987011e8a5a229e907589355_L2_supp-v2.pdf?Expires=1690761600\u0026Signature=Etha8OmIFpPupX~gFpyvTVPM8PvzfuS5x6roInaqU4-15-Qgeq7nXFw3ifQuDCbCeHmB6YeX4-mDx0oiG8k1ZGmPAG0ZwghFpWuhy0NvVbTQRAGAbft0LoMurbdJL5HnRIstl3tRFWN8IPFq-zhZJj8cHXy7ONQv868oxALqtwM_\u0026Key-Pair-Id=APKAJLTNE6QMUY6HBC5A ","date":"2023-08-10","objectID":"/2023/08/da-bayesian_statistics-coursera-from_concept_to_data_analysis/:3:3","tags":["课程笔记","贝叶斯","统计学"],"title":"coursera课程-Probability and Bayes’ Theorem","uri":"/2023/08/da-bayesian_statistics-coursera-from_concept_to_data_analysis/"},{"categories":["数据分析"],"content":"结合关系型数据库的思想，基于Notion实现及维护信贷风险领域特征 整理信贷风险主题下的（常用）特征是我一直想做的一件事儿，但之前一直没捋清楚由下至上的实现、维护的逻辑及方式。最近被老板领着研究人行报告，交流过程中思路、框架慢慢成型，便从人行报告相关变量出发，依托Notion搭建信贷风险特征框架，供后续策略、模型等业务场景使用 ","date":"2023-07-24","objectID":"/2023/07/da-my_features_market/:0:0","tags":["知识管理","信贷风险"],"title":"信贷风险特征维护框架","uri":"/2023/07/da-my_features_market/"},{"categories":["数据分析"],"content":"为什么做这件事？ 当处于一个成熟的团队、业务也达到一定规模，在迭代策略、建模时，一切似乎都很敏捷，然后就误把平台能力的强大归为自己的能力，尤其是模型、数据团队很强的时候。但可能自己并不了解所用特征是如何加工的或者说不会去细盘逻辑，尤其是在样本量足够大的时候。之后，当你换到一个新环境，甚至是接触一个冷启动的产品，那将面临巧妇难为无米之炊的情况，一度陷入“特征荒”的局面。 简而言之，由下至上抽象出日常工作中的特征，将平台能力赋能自我成长。另外，玄学来讲，策略打法也会因产品阶段、外部环境的变化而变化，似乎也需要记录些什么。 ","date":"2023-07-24","objectID":"/2023/07/da-my_features_market/:1:0","tags":["知识管理","信贷风险"],"title":"信贷风险特征维护框架","uri":"/2023/07/da-my_features_market/"},{"categories":["数据分析"],"content":"怎么做？ 首先，顶层的强假设在于我们的短中期职业规划在于信贷风控领域，这个特征（/变量）也是围绕着信贷风控领域的。同时，我们在这短中期窗口内可能会经历多家公司或多个产品。所以，变量整理、维护的思路依然沿用了卡片笔记的思想：由下至上规整，同时由上至下反哺，以此形成正循环♻️ 在策略、模型工作中，往往都是局部最优的结果，会遇到些有效的特征以满足当时的需求，在这个时点我们记录下这些特征，以及在A公司环境下实现的方案。正如上文所述，我们短中期仍聚焦信贷风控领域且未来也可能会换工作，为了方便，我们就需要一个再上一层的架构，凌驾于公司之上、关注特征本身。如下图所示 同时考虑到后续维护的便捷性，这里基于关系型数据库的思想主要建立了三张表： 一是信贷风控领域可用的数据源及其分类； 二是对应的特征； 三是基于所在公司数据环境的落地方案 这里又有点“数据集市”的味道。仍可以在各张表中加入各自的属性，比如特征表中可标明调额、过退等应用场景。 ","date":"2023-07-24","objectID":"/2023/07/da-my_features_market/:2:0","tags":["知识管理","信贷风险"],"title":"信贷风险特征维护框架","uri":"/2023/07/da-my_features_market/"},{"categories":["数据分析"],"content":"为什么是Notion 其实在工具选择上也纠结和很久，也想用能呈现关系网的思源等软件。但其实能满足以下俩条件即可 上文所述的框架 支持跨设备等便捷性 而我最终选择Notion，其实更多是在于转化成本。截至目前，Notion已经是我All In One的生产力工具，唯一担心的就是Notion哪天黄了，数据全没了o.o ","date":"2023-07-24","objectID":"/2023/07/da-my_features_market/:2:1","tags":["知识管理","信贷风险"],"title":"信贷风险特征维护框架","uri":"/2023/07/da-my_features_market/"},{"categories":["数据分析","读书笔记"],"content":"课程笔记- 《ChatGPT Prompt Engineering for Developers》 ","date":"2023-05-22","objectID":"/2023/05/notes-chatgpt_prompt_engineering_for_developers/:0:0","tags":["大模型时代下的求生","ChatGPT"],"title":"笔记-ChatGPT Prompt Engineering for Developers","uri":"/2023/05/notes-chatgpt_prompt_engineering_for_developers/"},{"categories":["数据分析","读书笔记"],"content":"L1-Introduction 目的、定位：使用 API 调用到 LLM，以快速构建软件应用程序。 随着大型语言模型（LLM）的发展，LLM 大致可以分为两种类型，即基础LLM和指令微调LLM。基础LLM是基于文本训练数据，训练出预测下一个单词能力的模型，其通常是在互联网和其他来源的大量数据上训练的。例如，如果你以“从前有一只独角兽”作为提示，基础LLM可能会继续预测“生活在一个与所有独角兽朋友的神奇森林中”。但是，如果你以“法国的首都是什么”为提示，则基础LLM可能会根据互联网上的文章，将答案预测为“法国最大的城市是什么？法国的人口是多少？”，因为互联网上的文章很可能是有关法国国家的问答题目列表。 许多 LLMs 的研究和实践的动力正在指令调整的 LLMs 上。指令调整的 LLMs 已经被训练来遵循指令。因此，如果你问它，“法国的首都是什么？”，它更有可能输出“法国的首都是巴黎”。指令调整的 LLMs 的训练通常是从已经训练好的基本 LLMs 开始，该模型已经在大量文本数据上进行了训练。然后，使用输入是指令、输出是其应该返回的结果的数据集来对其进行微调，要求它遵循这些指令。然后通常使用一种称为 RLHF（reinforcement learning from human feedback，人类反馈强化学习）的技术进行进一步改进，使系统更能够有帮助地遵循指令。 ","date":"2023-05-22","objectID":"/2023/05/notes-chatgpt_prompt_engineering_for_developers/:1:0","tags":["大模型时代下的求生","ChatGPT"],"title":"笔记-ChatGPT Prompt Engineering for Developers","uri":"/2023/05/notes-chatgpt_prompt_engineering_for_developers/"},{"categories":["数据分析","读书笔记"],"content":"L2-Guidelines ","date":"2023-05-22","objectID":"/2023/05/notes-chatgpt_prompt_engineering_for_developers/:2:0","tags":["大模型时代下的求生","ChatGPT"],"title":"笔记-ChatGPT Prompt Engineering for Developers","uri":"/2023/05/notes-chatgpt_prompt_engineering_for_developers/"},{"categories":["数据分析","读书笔记"],"content":"Setup 本教程使用 OpenAI 所开放的 ChatGPT API，因此你需要首先拥有一个 ChatGPT 的 API_KEY openai: pip install openai dotenv: pip install -U python-dotenv ","date":"2023-05-22","objectID":"/2023/05/notes-chatgpt_prompt_engineering_for_developers/:2:1","tags":["大模型时代下的求生","ChatGPT"],"title":"笔记-ChatGPT Prompt Engineering for Developers","uri":"/2023/05/notes-chatgpt_prompt_engineering_for_developers/"},{"categories":["数据分析","读书笔记"],"content":"Prompting Principles Principle 1: Write clear and specific instructions Tactic 1: Use delimiters to clearly indicate distinct parts of the input Delimiters can be anything like: ```, “”\", \u003c \u003e, \u003ctag\u003e \u003c/tag\u003e, : Tactic 2: Ask for a structured output JSON, HTML Tactic 3: Ask the model to check whether conditions are satisfied 如果任务做出的假设不一定满足，我们可以告诉模型先检查这些假设，如果不满足，指示并停止执行。你还可以考虑潜在的边缘情况以及模型应该如何处理它们，以避免意外的错误或结果。 Tactic 4: “Few-shot” prompting 即在要求模型执行实际任务之前，提供给它少量成功执行任务的示例。 Principle 2: Give the model time to “think” Tactic 1: Specify the steps required to complete a task 相当于告诉小弟为了实现目标A，拆解到1、2、3分别是啥结果，最后汇总以实现目标A （这也衍生出问题的拆解、设计能力目前还算是人类的核心竞争力） Tactic 2: Instruct the model to work out its own solution before rushing to a conclusion 在明确指导模型在做决策之前要思考解决方案时，我们会得到更好的结果。 ","date":"2023-05-22","objectID":"/2023/05/notes-chatgpt_prompt_engineering_for_developers/:2:2","tags":["大模型时代下的求生","ChatGPT"],"title":"笔记-ChatGPT Prompt Engineering for Developers","uri":"/2023/05/notes-chatgpt_prompt_engineering_for_developers/"},{"categories":["数据分析","读书笔记"],"content":"Model Limitations: Hallucinations 如果模型在训练过程中接触了大量的知识，它并没有完全记住所见的信息，因此它并不很清楚自己知识的边界。这意味着它可能会尝试回答有关晦涩主题的问题，并编造听起来合理但实际上并不正确的答案。我们称这些编造的想法为幻觉。 If the model is being exposed to a vast amount of knowledge during its training process, it has not perfectly memorised the information it’s seen, and so it doesn’t know the boundary of its knowledge very well. This means that it might try to answer questions about obscure topics and can make things up that sound plausible but are not actually true. And we call these fabricated ideas hallucinations. 要求模型找到文本中的任何相关引用，然后要求它使用这些引用来回答问题，这种追溯源文档的方法通常对减少幻觉非常有帮助。（比如现在的 New Bing） ","date":"2023-05-22","objectID":"/2023/05/notes-chatgpt_prompt_engineering_for_developers/:2:3","tags":["大模型时代下的求生","ChatGPT"],"title":"笔记-ChatGPT Prompt Engineering for Developers","uri":"/2023/05/notes-chatgpt_prompt_engineering_for_developers/"},{"categories":["数据分析","读书笔记"],"content":"L3-Iterative 需要好的迭代过程来不断改进 Prompt。 类比机器学习开发的流程。通常是先有一个想法，然后再实现它：编写代码，获取数据，训练模型，这会给您一个实验结果。然后您可以查看输出结果，进行错误分析，找出它在哪里起作用或不起作用，甚至可以更改您想要解决的问题的确切思路或方法，然后更改实现并运行另一个实验等等，反复迭代，以获得有效的机器学习模型。 🌰 generate marketing copy from a product fact sheet ","date":"2023-05-22","objectID":"/2023/05/notes-chatgpt_prompt_engineering_for_developers/:3:0","tags":["大模型时代下的求生","ChatGPT"],"title":"笔记-ChatGPT Prompt Engineering for Developers","uri":"/2023/05/notes-chatgpt_prompt_engineering_for_developers/"},{"categories":["数据分析","读书笔记"],"content":"L4-Summarizing 文本概括 + 关键信息提取 Python调用接口 import openai import os OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\") openai.api_key = OPENAI_API_KEY def get_completion(prompt, model=\"gpt-3.5-turbo\"): messages = [{\"role\": \"user\", \"content\": prompt}] response = openai.ChatCompletion.create( model=model, messages=messages, temperature=0, # 值越低则输出文本随机性越低 ) return response.choices[0].message[\"content\"] ","date":"2023-05-22","objectID":"/2023/05/notes-chatgpt_prompt_engineering_for_developers/:4:0","tags":["大模型时代下的求生","ChatGPT"],"title":"笔记-ChatGPT Prompt Engineering for Developers","uri":"/2023/05/notes-chatgpt_prompt_engineering_for_developers/"},{"categories":["数据分析","读书笔记"],"content":"L5-Inferring 「推断」infer sentiment and topics from product reviews and news articles. 🌰 情感分析、类型判断、信息提取等task 也举了个是否match特定主题的例子 ⇒ 想想咋变现，体现人类善于利用工具的点 ","date":"2023-05-22","objectID":"/2023/05/notes-chatgpt_prompt_engineering_for_developers/:5:0","tags":["大模型时代下的求生","ChatGPT"],"title":"笔记-ChatGPT Prompt Engineering for Developers","uri":"/2023/05/notes-chatgpt_prompt_engineering_for_developers/"},{"categories":["数据分析","读书笔记"],"content":"L6-Transforming use Large Language Models for text transformation tasks such as language translation, spelling and grammar checking, tone adjustment, and format conversion. 🌰 文本翻译+拼写纠正+风格调整+格式转换 对以下```之间的英文评论文本，进行以下操作： （1）针对拼写及语法纠错； （2）将其转化成中文； （3）将翻译后的中文文本转化成优质淘宝评论的风格，从各种角度出发，分别说明产品的优点与缺点，并进行总结。同时润色一下描述，使评论更具有吸引力。 第3个任务输出结果格式为： 【优点】xxx 【缺点】xxx 【总结】xxx 注意，只需填写xxx部分，并分段以markdown格式输出。 Got this for my daughter for her birthday cuz she keeps taking mine from my room. Yes, adults also like pandas too. She takes it everywhere with her, and it’s super soft and cute. One of the ears is a bit lower than the other, and I don’t think that was designed to be asymmetrical. It’s a bit small for what I paid for it though. I think there might be other options that are bigger for the same price. It arrived a day earlier than expected, so I got to play with it myself before I gave it to my daughter. ","date":"2023-05-22","objectID":"/2023/05/notes-chatgpt_prompt_engineering_for_developers/:6:0","tags":["大模型时代下的求生","ChatGPT"],"title":"笔记-ChatGPT Prompt Engineering for Developers","uri":"/2023/05/notes-chatgpt_prompt_engineering_for_developers/"},{"categories":["数据分析","读书笔记"],"content":"L7-Expanding 调用接口的时候可以通过设置 temperature 参数以决定response的多样性 ","date":"2023-05-22","objectID":"/2023/05/notes-chatgpt_prompt_engineering_for_developers/:7:0","tags":["大模型时代下的求生","ChatGPT"],"title":"笔记-ChatGPT Prompt Engineering for Developers","uri":"/2023/05/notes-chatgpt_prompt_engineering_for_developers/"},{"categories":["数据分析","读书笔记"],"content":"L8-Chatbot 关于 role 的介绍与说明 system、assistant、user 角色的设定更多是面向开发者。webUI交互时可以说扮演xxx角色 ","date":"2023-05-22","objectID":"/2023/05/notes-chatgpt_prompt_engineering_for_developers/:8:0","tags":["大模型时代下的求生","ChatGPT"],"title":"笔记-ChatGPT Prompt Engineering for Developers","uri":"/2023/05/notes-chatgpt_prompt_engineering_for_developers/"},{"categories":["数据分析","读书笔记"],"content":"OrderBot We can automate the collection of user prompts and assistant responses to build a OrderBot. The OrderBot will take orders at a pizza restaurant. 基于notebook的交互代码 import os import openai from dotenv import load_dotenv, find_dotenv _ = load_dotenv(find_dotenv()) # read local .env file openai.api_key = os.getenv('OPENAI_API_KEY') def get_completion(prompt, model=\"gpt-3.5-turbo\"): messages = [{\"role\": \"user\", \"content\": prompt}] response = openai.ChatCompletion.create( model=model, messages=messages, temperature=0, # this is the degree of randomness of the model's output ) return response.choices[0].message[\"content\"] def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature=0): response = openai.ChatCompletion.create( model=model, messages=messages, temperature=temperature, # this is the degree of randomness of the model's output ) # print(str(response.choices[0].message)) return response.choices[0].message[\"content\"] import panel as pn # GUI pn.extension() panels = [] # collect display context = [ {'role':'system', 'content':\"\"\" You are OrderBot, an automated service to collect orders for a pizza restaurant. \\ You first greet the customer, then collects the order, \\ and then asks if it's a pickup or delivery. \\ You wait to collect the entire order, then summarize it and check for a final \\ time if the customer wants to add anything else. \\ If it's a delivery, you ask for an address. \\ Finally you collect the payment.\\ Make sure to clarify all options, extras and sizes to uniquely \\ identify the item from the menu.\\ You respond in a short, very conversational friendly style. \\ The menu includes \\ pepperoni pizza 12.95, 10.00, 7.00 \\ cheese pizza 10.95, 9.25, 6.50 \\ eggplant pizza 11.95, 9.75, 6.75 \\ fries 4.50, 3.50 \\ greek salad 7.25 \\ Toppings: \\ extra cheese 2.00, \\ mushrooms 1.50 \\ sausage 3.00 \\ canadian bacon 3.50 \\ AI sauce 1.50 \\ peppers 1.00 \\ Drinks: \\ coke 3.00, 2.00, 1.00 \\ sprite 3.00, 2.00, 1.00 \\ bottled water 5.00 \\ \"\"\"} ] # accumulate messages inp = pn.widgets.TextInput(value=\"Hi\", placeholder='Enter text here…') button_conversation = pn.widgets.Button(name=\"Chat!\") def collect_messages(_): prompt = inp.value_input inp.value = '' context.append({'role':'user', 'content':f\"{prompt}\"}) response = get_completion_from_messages(context) context.append({'role':'assistant', 'content':f\"{response}\"}) panels.append( pn.Row('User:', pn.pane.Markdown(prompt, width=600))) panels.append( pn.Row('Assistant:', pn.pane.Markdown(response, width=600, style={'background-color': '#F6F6F6'}))) return pn.Column(*panels) interactive_conversation = pn.bind(collect_messages, button_conversation) dashboard = pn.Column( inp, pn.Row(button_conversation), pn.panel(interactive_conversation, loading_indicator=True, height=300), ) dashboard 样式形如👇 ","date":"2023-05-22","objectID":"/2023/05/notes-chatgpt_prompt_engineering_for_developers/:8:1","tags":["大模型时代下的求生","ChatGPT"],"title":"笔记-ChatGPT Prompt Engineering for Developers","uri":"/2023/05/notes-chatgpt_prompt_engineering_for_developers/"},{"categories":["数据分析","读书笔记"],"content":"Reference ChatGPT Prompt Engineering for Developers - DeepLearning.AI https://github.com/datawhalechina/prompt-engineering-for-developers ","date":"2023-05-22","objectID":"/2023/05/notes-chatgpt_prompt_engineering_for_developers/:9:0","tags":["大模型时代下的求生","ChatGPT"],"title":"笔记-ChatGPT Prompt Engineering for Developers","uri":"/2023/05/notes-chatgpt_prompt_engineering_for_developers/"},{"categories":["生活"],"content":"我被微信管制了，微信又被谁管制呢？ 2022-11-27 晚7点左右，我发现我不能在微信群里发消息 测试后发现我 无法接发微信群消息；不能发表朋友圈；不能在朋友圈点赞、评论 我尝试申诉并询问为什么被管制，但微信的回复一直是 👇 之后，某微信群的群主在群里发消息时被微信告知群被限制使用 🚫 并给我发来截图 我才大胆推测，可能是因为上午在群里说的3句话： 就这样，两个地名外加一个北大，被管制了…… 试问这是贼喊捉贼么？无独有偶，因为有一首歌的歌名叫《四通桥》而被勒令下架 o.o 但是，群功能被限制后，感觉倒也没什么？… 不过朋友们之间确实也少了些言语，本不咋言语的我，更加不咋说话了 不禁感叹生活的无奈，我希望有一天我真的有能力无视这世俗，像信一样，不用微信这些社交软件 本想依托该主题简单总结下近半年在看的 塔勒布 关于不确定性的一些思想，谁知最后又偏到了离开社交上面…上一秒还想说希望能有个微信的替代品，下一秒就觉得一个人待着也挺好，不需要像关系网一样建议关系/联系… 被微信管制后，确实也胡思乱想过微信替代品的样子，以及目前垂类产品真的没希望了么… 首先，我就觉得现在搞个微信替代品难度真的挺大的。还是想用之前实体终端的想法来阐述这件事。21世纪第一个10年，那会儿的QQ发展迅猛，那会儿是网吧的PC时代，QQ始终不是即时通讯，他依托的是网吧的电脑。进而到了21世纪第二个10年，算是来到了手机的时代，随着基建的成熟，手机的普及率也是蒸蒸日上，同时手机市场的竞争也日渐白热化。手机作为常用终端的时代，微信是个产物，只能说是恰巧是腾讯。而这个即时通讯软件恰巧是赶在了终端更迭的时代，也是新一代人接受新事物的时代。而正当很多关系/联系都建立在微信的基础上时，用户的转化成本已然很高。真正的替代品或许需要下一个即时通讯的终端。未来充满了好多不确定性 有时候会想，腾讯继续在下一个终端开发一个“微信”不就好了么…但问题是10年前的QQ当时在终端更迭为手机时开发了手机QQ呀… 这么说，社交软件真的没垂类了么？ 这里我想沿用我所理解的“炫耀性消费”理论来思考🤔 目前我认为，某样东西之所以带有“炫耀性”的属性，其必要条件之一便是基于某个圈子、需要圈内玩家的认同。不然就是对牛弹琴咯。 类比社交软件，其实也是依赖某个圈子，目前微信的转化成本高，更多也是很多好友都通过微信联系。而这个圈子同时也是垂类APP的切入点，试想存在这么个APP，因为某个圈子聚集在一起，比如我需要买车，在这个APP里我能找到围绕买车这个主题的圈子；我要考研，同时在这个APP里能找到考研相关主题的圈子等等，社交的同时一定程度上还能解决一些信息不对称的问题。 目前国内好像应该是没有这么个APP。但场景/需求我觉得是存在的。譬如，拿疫情微信群而言，在被封控期间，以物换物、团购群而言，很难及时的发现所在小区有哪些“团购”群，有时候往往需要一些机缘巧合进入需要的团购群。比如看到有在分发某样你需要的物品，上前问问；偶然在你所在的群里看到了链接等等 生活中大大小小的事情或需求，都能在这个APP上找到你要的圈子、找到你的同路人。让你的好友列表不再单调；让你的生活也不再单调。知道自己生活中充斥着哪些圈子；知道自己的好友列表中都是哪个圈子的。既然是关系网，就都交给这个APP吧，释放你的大脑，让这个APP记住你是在哪个圈子结识的这个好友 而微信就让他成为一个网络时代的即时通讯工具吧… 我们每个人是个独立的个体，而个体之间之所以会有连线，便是因为“关系”，而圈子的存在便是帮助个体之间建立连线 简单来说，微信目前仅仅是个体层面、是个“点”，而上文所勾勒的这个APP是凌驾于微信之上的，他是由“点”、“线”所组成的“面”、“体”，是降维打击微信的。为此，他也便需要事先具备升维的基础条件，除了技术本身，比如还有宏观层面：个体知识储备的上升，这一点可以通过国家硕士研究生扩招来进行评估。 简单切实际落地来说，就是微信的联系人页面，这个页面的布局及设计理念已经是上个世纪的事了，从未变革过，而这个联系人页面的底层逻辑便是上文所说的“点”。同时联系人独立一个页面是有多浪费，但实际点开这个页面的频率又是怎样呢？过去二十年互联网的发展，我一直依托于终端的更迭，是，终端的更迭确实是个机遇（如 现在的watch），但同时取代微信的产品也是可以不用等到终端的更迭的。 真的是越想越激动… 希望哪天能看见成品 😄 有没有可能创业呢？ ","date":"2022-12-03","objectID":"/2022/12/notes-black_swan/:0:0","tags":["碎碎念"],"title":"我被微信管制了...","uri":"/2022/12/notes-black_swan/"},{"categories":["数据分析"],"content":"在服务器上部署JupyterLab供远程访问并Coding 可能是当前全网关于访问服务器JupyterLab比较新的版本了，jupyter notebook则类似 「备注」This is not the multi-user server you are looking for. If you want a multi-user server, the official solution is JupyterHub. ","date":"2022-09-18","objectID":"/2022/09/jupyter_notebook_on_server/:0:0","tags":["Python","jupyter notebook"],"title":"服务器部署JupyterLab以供远程访问","uri":"/2022/09/jupyter_notebook_on_server/"},{"categories":["数据分析"],"content":"前期准备 OS：Ubuntu Server 20.04 # Installs the package globally in your python installation, i.e. for all users. sudo pip install jupyterlab sudo pip install jupyter notebook sudo pip 的方式以后服务器新建用户就不用再配置环境了，不然针对某个用户装的jupyterlab或jupyter notebook还需要加入PATH ","date":"2022-09-18","objectID":"/2022/09/jupyter_notebook_on_server/:1:0","tags":["Python","jupyter notebook"],"title":"服务器部署JupyterLab以供远程访问","uri":"/2022/09/jupyter_notebook_on_server/"},{"categories":["数据分析"],"content":"各种配置 ","date":"2022-09-18","objectID":"/2022/09/jupyter_notebook_on_server/:2:0","tags":["Python","jupyter notebook"],"title":"服务器部署JupyterLab以供远程访问","uri":"/2022/09/jupyter_notebook_on_server/"},{"categories":["数据分析"],"content":"设置密码登录 notebook 5.0版本开始，可以通过以下命令直接生成密码 jupyter lab password Enter password: **** # 以后可直接通过这个密码 login Verify password: **** [NotebookPasswordApp] Wrote hashed password to /Users/you/.jupyter/jupyter_server_config.json 密码会保存至 jupyter_server_config.json 文件 官方参考路径： Windows: C:\\Users\\USERNAME\\.jupyter\\jupyter_notebook_config.py OS X: /Users/USERNAME/.jupyter/jupyter_notebook_config.py Linux: /home/USERNAME/.jupyter/jupyter_notebook_config.py ","date":"2022-09-18","objectID":"/2022/09/jupyter_notebook_on_server/:2:1","tags":["Python","jupyter notebook"],"title":"服务器部署JupyterLab以供远程访问","uri":"/2022/09/jupyter_notebook_on_server/"},{"categories":["数据分析"],"content":"其他一些配置 { \"ServerApp\": { \"ip\":\"*\" ,\"port\":8888 ,\"open_browser\":false ,\"password\": \"上文自动生成的部分\" } } 端口默认是8888，不管如何都需要确认下服务器防火墙端口是否开放 ","date":"2022-09-18","objectID":"/2022/09/jupyter_notebook_on_server/:2:2","tags":["Python","jupyter notebook"],"title":"服务器部署JupyterLab以供远程访问","uri":"/2022/09/jupyter_notebook_on_server/"},{"categories":["数据分析"],"content":"启动与关闭 通过以下命令在后台运行服务，ssh窗口关闭后仍能正常访问 nohup jupyter-lab \u0026 浏览器通过 服务器公网IP:端口（如，12.456.78.321:8888）的形式访问 ps -aux | grep jupyter 找到 jupyter 服务的pid 使用 kill -9 pid方式关闭运行中的jupyter服务 ","date":"2022-09-18","objectID":"/2022/09/jupyter_notebook_on_server/:3:0","tags":["Python","jupyter notebook"],"title":"服务器部署JupyterLab以供远程访问","uri":"/2022/09/jupyter_notebook_on_server/"},{"categories":["数据分析"],"content":"Reference Running a notebook server - Jupyter Notebook 6.4.12 documentation Linux服务器上创建新用户_攻城狮Bell的博客-CSDN博客_linux服务器创建用户 如何访问服务器的 Jupyter notebook 搭建Jupyter Notebook远程云服务器 使用nohup 和 \u0026 后台运行jupyter notebook程序，查看、kill 进程_Donald Su的博客-CSDN博客_查看jupyter进程 ","date":"2022-09-18","objectID":"/2022/09/jupyter_notebook_on_server/:4:0","tags":["Python","jupyter notebook"],"title":"服务器部署JupyterLab以供远程访问","uri":"/2022/09/jupyter_notebook_on_server/"},{"categories":["FEM"],"content":"台大经济学原理 课程笔记之“Firms in Competitive Market” 竞争市场上的企业从供给曲线的背后来看企业如何做出生产决策 ","date":"2022-09-03","objectID":"/2022/09/notes-principles-of-economics-ch14-firms_in_competitive_market/:0:0","tags":["经济学","课程笔记"],"title":"Ch14-竞争市场上的企业","uri":"/2022/09/notes-principles-of-economics-ch14-firms_in_competitive_market/"},{"categories":["FEM"],"content":"什么是竞争市场 ","date":"2022-09-03","objectID":"/2022/09/notes-principles-of-economics-ch14-firms_in_competitive_market/:1:0","tags":["经济学","课程笔记"],"title":"Ch14-竞争市场上的企业","uri":"/2022/09/notes-principles-of-economics-ch14-firms_in_competitive_market/"},{"categories":["FEM"],"content":"竞争的含义 竞争市场（competitive market）又称完全竞争市场，有俩特征： 市场上有许多买者和卖者 各个卖者提供的物品大体上是相同的 这使得竞争市场中，买卖双方都是价格接受者 同时还有一个在长期均衡方面的强大力量，有时也会作为竞争市场的特征： 企业可以自由的进入或退出市场 ","date":"2022-09-03","objectID":"/2022/09/notes-principles-of-economics-ch14-firms_in_competitive_market/:1:1","tags":["经济学","课程笔记"],"title":"Ch14-竞争市场上的企业","uri":"/2022/09/notes-principles-of-economics-ch14-firms_in_competitive_market/"},{"categories":["FEM"],"content":"竞争企业的收益 平均收益（average revenue, AR）是总收益除以产量。对于所有企业而言，平均收益=物品的价格 边际收益（marginal revenue, MR）是增加一单位销售量所引起的总收益变动量。 $$ MR=\\frac{\\Delta TR}{\\Delta Q}=\\frac{P_1Q_1-P_0Q_0}{Q_1-Q_0} $$ 竞争市场中买卖双方均为价格接受者，那么由上表达式可知，对于竞争企业而言横截面数据（即不考虑时间问题）$P_1=P_0$ ，即 边际收益=物品的价格 ","date":"2022-09-03","objectID":"/2022/09/notes-principles-of-economics-ch14-firms_in_competitive_market/:1:2","tags":["经济学","课程笔记"],"title":"Ch14-竞争市场上的企业","uri":"/2022/09/notes-principles-of-economics-ch14-firms_in_competitive_market/"},{"categories":["FEM"],"content":"利润最大化与竞争企业的供给曲线 企业的目标是利润最大化，利润=总收益-总成本 ","date":"2022-09-03","objectID":"/2022/09/notes-principles-of-economics-ch14-firms_in_competitive_market/:2:0","tags":["经济学","课程笔记"],"title":"Ch14-竞争市场上的企业","uri":"/2022/09/notes-principles-of-economics-ch14-firms_in_competitive_market/"},{"categories":["FEM"],"content":"一个简单的利润最大化例子 ","date":"2022-09-03","objectID":"/2022/09/notes-principles-of-economics-ch14-firms_in_competitive_market/:2:1","tags":["经济学","课程笔记"],"title":"Ch14-竞争市场上的企业","uri":"/2022/09/notes-principles-of-economics-ch14-firms_in_competitive_market/"},{"categories":["FEM"],"content":"边际成本曲线和企业的供给决策 边际成本曲线在边际收益曲线之上，说明边际成本大于边际收益，类似$Q_2$产量对应的$MC_2$，此时通过降低产量来增加利润。而$Q_1$产量对应的$MC_1$ 则相反。同时利润最大化的产量水平时，边际收益=边际成本 ","date":"2022-09-03","objectID":"/2022/09/notes-principles-of-economics-ch14-firms_in_competitive_market/:2:2","tags":["经济学","课程笔记"],"title":"Ch14-竞争市场上的企业","uri":"/2022/09/notes-principles-of-economics-ch14-firms_in_competitive_market/"},{"categories":["FEM"],"content":"企业的短期停止营业决策 暂时停止营业 🆚 永久性退出市场 停止营业指由于当前的市场条件而在某个特定时期不生产任何东西的短期决策。退出指离开市场的长期决策。长期决策和短期决策不同在于大多数企业在短期内不可避开固定成本，而在长期中可以避开。 短期内，如果企业停止营业，他就失去了出售自己产品的全部收益。但同时也节省了可变成本部分。所以说，如果生产得到的收益小于可变成本，企业就停止营业。即价格低于平均可变成本 $$ TR\u003cVC \\Leftrightarrow \\frac{TR}{Q}\u003c\\frac{VC}{Q} \\Leftrightarrow P\u003cAVC $$ 竞争企业的短期供给曲线是边际成本曲线位于平均可变成本曲线之上的部分 ","date":"2022-09-03","objectID":"/2022/09/notes-principles-of-economics-ch14-firms_in_competitive_market/:2:3","tags":["经济学","课程笔记"],"title":"Ch14-竞争市场上的企业","uri":"/2022/09/notes-principles-of-economics-ch14-firms_in_competitive_market/"},{"categories":["FEM"],"content":"企业退出或进入一个市场的长期决策 如果企业退出则失去全部收益（TR），但也节省了可变成本和固定成本。所以，如果从生产中得到的收益小于总成本，企业就应退出市场。即价格低于平均总成本 $$ TR\u003cTC \\Leftrightarrow \\frac{TR}{Q}\u003c\\frac{TC}{Q} \\Leftrightarrow P\u003cATC $$ 竞争企业的长期供给曲线是边际成本曲线位于平均总成本曲线之上的部分。 ","date":"2022-09-03","objectID":"/2022/09/notes-principles-of-economics-ch14-firms_in_competitive_market/:2:4","tags":["经济学","课程笔记"],"title":"Ch14-竞争市场上的企业","uri":"/2022/09/notes-principles-of-economics-ch14-firms_in_competitive_market/"},{"categories":["FEM"],"content":"用竞争企业图形来衡量利润 $$ \\begin{aligned} 利润 \u0026= TR-TC \\ \u0026= (\\frac{TR}{Q} - \\frac{TC}{Q}) \\times Q \\ \u0026= (P-ATC) \\times Q \\end{aligned} $$ ","date":"2022-09-03","objectID":"/2022/09/notes-principles-of-economics-ch14-firms_in_competitive_market/:2:5","tags":["经济学","课程笔记"],"title":"Ch14-竞争市场上的企业","uri":"/2022/09/notes-principles-of-economics-ch14-firms_in_competitive_market/"},{"categories":["FEM"],"content":"竞争市场的供给曲线 分两种情况讨论： 有固定数量企业的市场（对应短期） 企业数量会随着老企业退出和新企业进入而变动的市场（对应长期） ","date":"2022-09-03","objectID":"/2022/09/notes-principles-of-economics-ch14-firms_in_competitive_market/:3:0","tags":["经济学","课程笔记"],"title":"Ch14-竞争市场上的企业","uri":"/2022/09/notes-principles-of-economics-ch14-firms_in_competitive_market/"},{"categories":["FEM"],"content":"短期：有固定数量企业的市场供给 短期来看，只要价格高于平均可变成本，每个企业的边际成本曲线就是其供给曲线 ","date":"2022-09-03","objectID":"/2022/09/notes-principles-of-economics-ch14-firms_in_competitive_market/:3:1","tags":["经济学","课程笔记"],"title":"Ch14-竞争市场上的企业","uri":"/2022/09/notes-principles-of-economics-ch14-firms_in_competitive_market/"},{"categories":["FEM"],"content":"长期：有进入与退出的市场供给 理想状态下，在不断的进入、退出过程结束时，仍然留在市场中的企业经济利润必定为零。 而 $利润= (P-ATC) \\times Q$，此时 $P=ATC$ ；同时基于前文所述的 $P=MC$ 使得利润最大化。那么此时 $ATC=MC$ ，对应的是平均总成本最低点，同时对应的生产水平为有效规模。所以说，在可以自由进入与退出的竞争市场的长期均衡种，企业一定是在其有效规模上运营。 市场长期供给曲线是完全富有弹性的供给曲线 如果竞争企业利润为零，为什么他们要留在市场上？说这里聊的是经济利润。还涉及机会成本。 ","date":"2022-09-03","objectID":"/2022/09/notes-principles-of-economics-ch14-firms_in_competitive_market/:3:2","tags":["经济学","课程笔记"],"title":"Ch14-竞争市场上的企业","uri":"/2022/09/notes-principles-of-economics-ch14-firms_in_competitive_market/"},{"categories":["FEM"],"content":"短期与长期内的需求移动 （价格作为一种信号，实现资源配置） 但其实长期供给曲线也是有可能向右上方倾斜的。主要原因有二：（1）用于生产的资源本身也是有限的。（2）不同企业有不同的成本。 但一般来讲，因为企业在长期中比在短期种更容易进入和退出，所以长期供给曲线一般比短期供给曲线更富弹性。 ","date":"2022-09-03","objectID":"/2022/09/notes-principles-of-economics-ch14-firms_in_competitive_market/:3:3","tags":["经济学","课程笔记"],"title":"Ch14-竞争市场上的企业","uri":"/2022/09/notes-principles-of-economics-ch14-firms_in_competitive_market/"},{"categories":["数据分析"],"content":"RT，关于jupyter notebook导出为PDF的那些事儿 ","date":"2022-08-07","objectID":"/2022/08/jupyter_notebook-convert_to_pdf/:0:0","tags":["Python","jupyter notebook","LaTex"],"title":"最新版jupyter notebook导出为PDF","uri":"/2022/08/jupyter_notebook-convert_to_pdf/"},{"categories":["数据分析"],"content":"背景 自己在用Python 分析数据时总会依赖jupyter notebook（以下简称 notebook） 交互式的界面，然后把报告中需要的数据复制出来贴在Excel里 这波操作里，就不想贴数据了，而且在notebook里写结论也能直接定位到操作过程，或者说日后能复现、方便管理。所以可以考虑使用 notebook 导出的功能。虽然目前支持多种格式（html、markdown、pdf等），但又想兼顾各设备（电脑、手机）打开的便捷性，所以导出为pdf是个不错的选择。 但是，在导出为PDF的过程中遇到了以下几个问题/需求： 不显示中文 Code Free 对外展示的时候只需要结果即可 添加报告的目录 pandas.DataFrame Style格式导出后直接不显示 … 以上遇到的几个问题/需求，结合notebook导出为pdf的流程来看主要对应 notebook2LaTex 和 LaTex2PDF 两个阶段的事。但使用感知依然还是一件事，即notebook导出为PDF （「Mark」目前还有个先转html再转pdf的方式 to webpdf） Choose to convert using latex or chrome web browser when converting to pdf. Output is significantly different for each. Use ’latex’ when you desire a formal report. Use ‘browser’ to get output similar to that when printing to pdf within a chrome web browser. 上文所列的 2、4便对应notebook2LaTex阶段，而剩下的第1、3个问题便是LaTex2PDF阶段的问题 在此均使用 jupyter nbconver 终端命令实现导出，且略过需要提前配置好的 Pandoc 和 Tex ","date":"2022-08-07","objectID":"/2022/08/jupyter_notebook-convert_to_pdf/:1:0","tags":["Python","jupyter notebook","LaTex"],"title":"最新版jupyter notebook导出为PDF","uri":"/2022/08/jupyter_notebook-convert_to_pdf/"},{"categories":["数据分析"],"content":"notebook2LaTex ","date":"2022-08-07","objectID":"/2022/08/jupyter_notebook-convert_to_pdf/:2:0","tags":["Python","jupyter notebook","LaTex"],"title":"最新版jupyter notebook导出为PDF","uri":"/2022/08/jupyter_notebook-convert_to_pdf/"},{"categories":["数据分析"],"content":"Code Free 关于不需要input中的代码问题，终端命令是能顺利实现的 jupyter nbconvert notebook.ipynb --to pdf --no-input 但这样导出的pdf会遇到表格数据串行的问题，而且pandas.DataFrame 加上一些渲染后再导出也无法显示，即第4个问题 ","date":"2022-08-07","objectID":"/2022/08/jupyter_notebook-convert_to_pdf/:2:1","tags":["Python","jupyter notebook","LaTex"],"title":"最新版jupyter notebook导出为PDF","uri":"/2022/08/jupyter_notebook-convert_to_pdf/"},{"categories":["数据分析"],"content":"DataFrames2images （当目前问题解决不了的时候，那就装个包：dataframe-image） 但是这个包没有封装--no-input的选项，好在这个包的pdfExporter部分也是从nbconvert继承过来的，所以改下dataframe-image的源代码（_convert.py文件）也是能实现code-free的 pdf = PDFExporter(config={'NbConvertBase': {'display_data_priority': self.DISPLAY_DATA_PRIORITY} }) # 改为 from traitlets.config import Config c = Config({\"NbConvertBase\": { \"display_data_priority\": self.DISPLAY_DATA_PRIORITY }}) c.PDFExporter.exclude_input_prompt = True c.PDFExporter.exclude_input = True pdf = PDFExporter(config=c) ","date":"2022-08-07","objectID":"/2022/08/jupyter_notebook-convert_to_pdf/:2:2","tags":["Python","jupyter notebook","LaTex"],"title":"最新版jupyter notebook导出为PDF","uri":"/2022/08/jupyter_notebook-convert_to_pdf/"},{"categories":["数据分析"],"content":"LaTex2PDF ","date":"2022-08-07","objectID":"/2022/08/jupyter_notebook-convert_to_pdf/:3:0","tags":["Python","jupyter notebook","LaTex"],"title":"最新版jupyter notebook导出为PDF","uri":"/2022/08/jupyter_notebook-convert_to_pdf/"},{"categories":["数据分析"],"content":"中文及目录问题 这个问题放在LaTex2PDF这个阶段就好理解了，这个是跟LaTex有关，这玩意儿一开始就是老外整出来的，要显示中文得修改base.tex.j2文件，加载一些宏包。（网上说要改article.tplx文件的都是比较老的版本了，目前nbconvert不那么整了） \\usepackage[slantfont, boldfont]{xeCJK} % 其他一些问题 % %加水印 \\usepackage{draftwatermark, everypage} \\SetWatermarkText{DRAFT} \\SetWatermarkLightness{0.95} \\SetWatermarkScale{0.4} % %中文时间 \\usepackage{zhnumber} \\date{\\zhtoday} % %目录 \\tableofcontents 之后工作中遇到新需求、问题再继续更新～ ","date":"2022-08-07","objectID":"/2022/08/jupyter_notebook-convert_to_pdf/:3:1","tags":["Python","jupyter notebook","LaTex"],"title":"最新版jupyter notebook导出为PDF","uri":"/2022/08/jupyter_notebook-convert_to_pdf/"},{"categories":["数据分析"],"content":"Reference https://pypi.org/project/dataframe-image/ https://nbconvert.readthedocs.io/en/latest/index.html ","date":"2022-08-07","objectID":"/2022/08/jupyter_notebook-convert_to_pdf/:4:0","tags":["Python","jupyter notebook","LaTex"],"title":"最新版jupyter notebook导出为PDF","uri":"/2022/08/jupyter_notebook-convert_to_pdf/"},{"categories":["FEM"],"content":"台大经济学原理 课程笔记之“The Costs of Production” ","date":"2022-05-28","objectID":"/2022/05/notes-principles-of-economics-ch13-the_costs_of_production/:0:0","tags":["经济学","课程笔记"],"title":"Ch13-生产成本","uri":"/2022/05/notes-principles-of-economics-ch13-the_costs_of_production/"},{"categories":["FEM"],"content":"什么是成本 总收益（total revenue）：企业出售其产品所得到的货币量 总成本（total cost）：企业用于生产的投入品的市场价值。企业为购买投入品所支付的货币量 利润（profit）：总收益减去总成本 显性成本（explicit costs）：需要企业支出货币的投入成本 隐性成本（implicit costs）：不需要企业支出货币的投入成本 经济利润（economic profit）：总收益减总成本（显性+隐性） 会计利润（accounting profit）：总收益减总显性成本 经济利润 🆚 会计利润 ","date":"2022-05-28","objectID":"/2022/05/notes-principles-of-economics-ch13-the_costs_of_production/:1:0","tags":["经济学","课程笔记"],"title":"Ch13-生产成本","uri":"/2022/05/notes-principles-of-economics-ch13-the_costs_of_production/"},{"categories":["FEM"],"content":"生产与成本 生产函数（production function）：用于生产一种物品的投入量与该物品产量之间的关系 边际产量（marginal product）：增加一单位投入所引起的产量增加 边际产量递减（diminishing marginal product）：一种投入的边际产量随着投入的增加而减少的特征。正如上图（a）生产函数的斜率不断减小 ","date":"2022-05-28","objectID":"/2022/05/notes-principles-of-economics-ch13-the_costs_of_production/:2:0","tags":["经济学","课程笔记"],"title":"Ch13-生产成本","uri":"/2022/05/notes-principles-of-economics-ch13-the_costs_of_production/"},{"categories":["FEM"],"content":"成本的各种衡量指标 Term Definition Math 固定成本 不随产量变动而变动的成本，企业不生产也要发生的成本 Fixed Costs, FC 可变成本 随着产量变动而变动的成本 Variable Costs, VC 平均总成本 总成本除以产量 Average Total Cost, $ATC=\\frac{TC}{Q}$ 平均固定成本 固定成本除以产量 Average Fixed Cost, AFC 平均可变成本 可变成本除以产量 Average Variable Cost, AVC 边际成本 额外一单位产量所引起的总成本增加 Marginal Cost, $MC=\\frac{\\Delta TC}{\\Delta Q}$ 书中说企业总成本是固定成本和可变成本之和。上文又说到总成本为显性成本和隐性成本之和。那么固定成本、可变成本和显性成本、隐性成本之间的关系又是啥？（私认为固定成本和可变成本均为会计层面的成本即显性成本，即企业家（或当事人）做出选择后的结果） 各成本和产量之间的关系 MC对应生产曲线各点的切线斜率；ATC对应生产曲线各点与坐标轴原点连线的斜率。存在生产曲线上一点的切线过原点，此时平均总成本（ATC）最小，对应的产量称为企业的有效规模（Efficient Scale） 典型企业的成本曲线 随着产量增加，边际成本最终会上升 平均成本曲线是U形 边际成本曲线与平均总成本曲线在平均总成本曲线的最低点处相交 ","date":"2022-05-28","objectID":"/2022/05/notes-principles-of-economics-ch13-the_costs_of_production/:3:0","tags":["经济学","课程笔记"],"title":"Ch13-生产成本","uri":"/2022/05/notes-principles-of-economics-ch13-the_costs_of_production/"},{"categories":["FEM"],"content":"短期成本与长期成本 企业的成本取决于所考察的时间范围。即总成本在固定成本和可变成本之间的划分取决于时间范围。比如对汽车制造商而言，目前在个把月的时间里很难调整工厂的数量和规模，此时工厂的成本便是固定成本。时间拉长了看，新建、关闭工厂，此时又是可变成本了 规模经济（economies of scale）：长期平均总成本随着产量增加而减少的特性。分工带来的的专业化 规模不经济（diseconomies of scale）：长期平均总成本随着产量增加而增加的特性。规模不经济的产生可能由于任何一个大型组织中固有的协调问题。 规模收益不变（constant returns to scale）：长期平均总成本在产量变动时保持不变的特性 ","date":"2022-05-28","objectID":"/2022/05/notes-principles-of-economics-ch13-the_costs_of_production/:4:0","tags":["经济学","课程笔记"],"title":"Ch13-生产成本","uri":"/2022/05/notes-principles-of-economics-ch13-the_costs_of_production/"},{"categories":["写作"],"content":"Gitee这波仓库开源需审核的这波操作是有点秀的 到底是啥原因？政府？公司盈利问题？ 如何看待2022年 5 月 18 日 Gitee 仓库开源须审核，已开源部分仓库暂时关闭，审核通过后再次公开？ 我用Gitee主要是两个原因： 解决Github下载慢的问题 图床 我是希望基于Markdown写作并且能一文多发的，有一天我发现存在Gitee的图片微信公众号能加载成功，此后我便依赖Gitee搞了个图床，博客的很多图片也存在Gitee上面。 发生这件事儿后，我本以为实名认证下，提交下审核就没事儿，仓库依然能正常开源的了，结果…万万没想到 这就直接导致了此博客基于Gitee的图片都无法加载… 和朋友吐槽了这事儿，他提供了一个很好的方案。先把Gitee的图片挪到GitHub，再替换下图片链接 from pathlib import Path p = Path(\"folderPath\") # e.g. /content/posts/ FileList=list(p.glob(\"**/*.md\")) def alter(file,old_str,new_str): \"\"\" 替换文件中的字符串 :param file:文件名 :param old_str:就字符串 :param new_str:新字符串 Reference: https://blog.csdn.net/qq_30068487/article/details/90297814 \"\"\" file_data = \"\" with open(file, \"r\", encoding=\"utf-8\") as f: for line in f: if old_str in line: line = line.replace(old_str,new_str) file_data += line with open(file,\"w\",encoding=\"utf-8\") as f: f.write(file_data) o_s = \"https://gitee.com/unclehuzi/picture/raw/master/img\" n_s = \"https://raw.githubusercontent.com/unclehuzi/pic/master/img\" for file in FileList: alter(file, o_s, n_s) 同时，我也向Gitee提交了注销账号的申请…这么一搞普通老百姓本身也不是目标用户了… 关于图床的 PlanB 就是七牛云了，但需要有个域名 ","date":"2022-05-28","objectID":"/2022/05/blog-pictures_gitee2github/:0:0","tags":["blog"],"title":"将博客中的图片从Gitee迁移至Github","uri":"/2022/05/blog-pictures_gitee2github/"},{"categories":["读书笔记"],"content":"真希望在校期间就能了解卡片笔记法o.o 我相信，在中国，大部分本、硕毕业论文的题目都受命于导师或者说学院、学校层面的安排。依然记得刚转到商科的我，也不知道写什么论文，但又想写点什么。自己也做了些尝试，走马观花的看了些论文，大概能看明白一些。但如果问我写个啥，感觉还是丈二的和尚摸不着头脑。老师也建议我们多看些经典、顶刊的论文。那时候的我也没静下心来好好看。最后稍微有了几个不成熟的想法后就去找导师聊了，导师基于某个想法衍生出了另一个主题并拍板。主题定了后有种如释重负的感觉，就觉得有方向了。后续看的论文似乎也有针对性。但看过之后呢？ 那时我看过就看过了，大致知道咋个回事，也没内化什么的。其实以上背景有两个问题：（1）主题；（2）学术笔记 现在来看，我会建议通过卡片笔记的方法来完成论文的写作，通过卡片笔记找到主题、并做好学术笔记。即书中提到的“闪念笔记”、“文献笔记”和“永久笔记”。但我更喜欢用少楠提的 i.A.R.P：Inbox, Area, Resource, Project. 首先关于论文方向/主题，他是需要一定时间、知识沉淀的，硕士期间总是期望有一个领域的宏观架构，殊不知那是一步步自下而上积累起来的，学术工作是需要被训练的。我们也要接受前期一脸懵逼的自己，当然也不急于知道那个框架，文献依然是要看的，前期可以结合学校的课程扎进某篇学术论文里看，看文献的时候就开始结合卡片笔记法做笔记了。最主要的是用自己的话表达文章的观点，更详细的还包括作者用了什么方法来论证，用了什么统计方法分析什么类型的数据等等，所谓的精读。 久而久之会有一定的感觉，会有一些主题想法，这时候可以将其归为 Project下，针对性的看相关的文献；没有啥想法的依然可以作为素材归到 Resource下；有时候会有些突发奇想，可快速记在Inbox类别下，空闲的时候再来想想。我相信再加上学校老师、同学们的帮助下，Project会越来越越精进，同时也会不断的被修正。而Project下就对应着各种论文的 Idea。整体框架便是如此，剩下的就是交给时间了，不断的看文献、看文献、看文献，思考、思考、思考，观察、观察、观察，讨论、讨论、讨论 😂 感觉这一套真的是适合学术工作者。 但那时习惯了自上而下的我，面对这一套自下而上的操作或许一时半会儿也理解不了吧。 ","date":"2022-05-01","objectID":"/2022/05/notes-zettelkasten_method/:0:0","tags":["学术","知识管理"],"title":"对卡片笔记法的一些思考及应用","uri":"/2022/05/notes-zettelkasten_method/"},{"categories":["读书笔记"],"content":"工作中的 IARP 离开学术，成为打工人的我就将这一套 i.A.R.P 理念运用在工作中，试图搭建一套工作体系，基于Notion 建立企业工作中的 i.A.R.P ","date":"2022-05-01","objectID":"/2022/05/notes-zettelkasten_method/:1:0","tags":["学术","知识管理"],"title":"对卡片笔记法的一些思考及应用","uri":"/2022/05/notes-zettelkasten_method/"},{"categories":["读书笔记"],"content":"Inbox 这里放的是需要做的事儿，搭建工作空间。也是在霍师傅分享的模板上修改的 这里的标签类似 Project的概念，每个工作项目打上相应的标签，为日后的规整及思考提供相应的素材。经过时间的沉淀，我相信会丰富大框架下的Project 甚至工作中的Area。希望有朝一日能独当一面 ","date":"2022-05-01","objectID":"/2022/05/notes-zettelkasten_method/:1:1","tags":["学术","知识管理"],"title":"对卡片笔记法的一些思考及应用","uri":"/2022/05/notes-zettelkasten_method/"},{"categories":["读书笔记"],"content":"Resources 这里存放的是一些基本的事实，譬如产品的一些动作、术语的记录等等。我觉得一个团队是需要这个栏目的，如果以后我带团队了，应该是会好好经营这块儿的，这不仅对新人来说很友好，同时也方便团队内部信息的互通，一定程度上解决信息不对成的问题。 这里不禁吐槽下，工作后遇到了有这么个特点的一些人：把公司内部基本的事实当作是自己的护城河，以为自己是公司所谓的老人😂 有时候在会上还针对一些基本事实提问新人🤷‍♂️ so？我真的是大开眼界o.o ","date":"2022-05-01","objectID":"/2022/05/notes-zettelkasten_method/:1:2","tags":["学术","知识管理"],"title":"对卡片笔记法的一些思考及应用","uri":"/2022/05/notes-zettelkasten_method/"},{"categories":["读书笔记"],"content":"Project 这里存放的主要是工作中个人负责的一些模块，纵向拧好螺丝。也可以是跟进的各个项目 ","date":"2022-05-01","objectID":"/2022/05/notes-zettelkasten_method/:1:3","tags":["学术","知识管理"],"title":"对卡片笔记法的一些思考及应用","uri":"/2022/05/notes-zettelkasten_method/"},{"categories":["读书笔记"],"content":"Area 这就像是阿德勒说的 交友、工作、爱 三大“人生课题”，或者说是某个领域，需要我们长时间钻研、精进的。譬如工作中涉及的工作习惯、方法，编程等等 剩下的就是交给时间了，同样的道理，前期应该接受自己无知懵懂的样子，多学习、多干活，为思考、搭框架提供素材。 ","date":"2022-05-01","objectID":"/2022/05/notes-zettelkasten_method/:1:4","tags":["学术","知识管理"],"title":"对卡片笔记法的一些思考及应用","uri":"/2022/05/notes-zettelkasten_method/"},{"categories":["读书笔记"],"content":"再论读书笔记 之前也在想一个问题：到底怎么做读书笔记。在解决这个问题之前，首先是为啥要看书。可以引用经常出现在章惠南教授朋友圈的一句话：多一只眼看世界。私认为与查理·芒格所推出的广泛理论工具箱有异曲同工之处。多了解些看世界的模型、角度。如果一直坚守着一两个模型，则就像拿着锤子看啥都是钉子。这也只是其一。最重要的还是结合Area 形成并丰富自己的知识体系。 譬如这波上海疫情，“政府”的所作所为有很多被吐槽的点。以前的我对此无感，似乎政府说啥就是啥；看了些奥派相关的书籍和文章，似乎就走“愤青流”、所谓的批判性看问题；再到现在认为ZF牵扯到的利益太多、很难全局最优，更需要关注的是自己在当前环境下如何活命o.o 对于网上一些吐槽政府这个、那个的更多是吃瓜的心态，甚至都懒得看了 受到《卡片笔记写做法》的启发，这个读书笔记可分为俩阶段：一是作为小白出现在某领域时，需要以开放的心态来看待书中的观点，尝试用自己的话阐述，其实这个开放的心态往往就比较难o.o 二是随着阅读、思考的增加，逐步构建自己的框架，成为一名有经验的读者，带着问题去阅读文本，并试图结合其他可能有用的方法，并与现有知识构建链接。 但记录并非终点，实则是要思考及落地。记录确实是种输出，但更好的是能为生活、工作中的决策带来一些增益，而决策又是作为幸福感的手段，最终还是为了增加幸福感。当然，单纯的记录可能也能直接带来一定的幸福感，但更希望网状输出，能多方面影响。 ","date":"2022-05-01","objectID":"/2022/05/notes-zettelkasten_method/:2:0","tags":["学术","知识管理"],"title":"对卡片笔记法的一些思考及应用","uri":"/2022/05/notes-zettelkasten_method/"},{"categories":["FEM"],"content":"台大经济学原理 课程笔记之“International Trade” 国际贸易如何影响经济福利？在各国间的自由贸易中谁受益？谁受损？如何比较收益和损失？ 各国之间的额贸易最终要建立在比较优势的基础之上。贸易之所以是互惠的，是因为他使各国可以专门从事自己最擅长的活动。 世界价格（world price）：一种物品在世界市场上通行的价格。 ","date":"2022-04-30","objectID":"/2022/04/notes-principles-of-economics-ch9-international_trade/:0:0","tags":["经济学","课程笔记"],"title":"Ch9-国际贸易","uri":"/2022/04/notes-principles-of-economics-ch9-international_trade/"},{"categories":["FEM"],"content":"贸易的赢家和输家 假设X国在世界经济中是价格接受者（世界价格作为既定的）。即X国的贸易政策的任何变化都不会影响某商品的世界价格。 ","date":"2022-04-30","objectID":"/2022/04/notes-principles-of-economics-ch9-international_trade/:1:0","tags":["经济学","课程笔记"],"title":"Ch9-国际贸易","uri":"/2022/04/notes-principles-of-economics-ch9-international_trade/"},{"categories":["FEM"],"content":"出口国的得失 X国在某商品（纺织品）上比较优势较强，世界价格高于贸易前价格 （书上说一旦允许自由贸易，国内价格上升到世界价格。为啥国内价格就一定要上升到世界价格的水平呢？存在套利行为倒逼厂商抬价？） 价格上升，国内供给增加（生产者剩余由 C 变为 B+C+D），国内需求减少（贸易后消费者剩余由 A+B 变为 A），但多的那部分通过出口。整体来看，总剩余是增加了 D ","date":"2022-04-30","objectID":"/2022/04/notes-principles-of-economics-ch9-international_trade/:1:1","tags":["经济学","课程笔记"],"title":"Ch9-国际贸易","uri":"/2022/04/notes-principles-of-economics-ch9-international_trade/"},{"categories":["FEM"],"content":"进口国的得失 X国在某商品（纺织品）上比较优势较弱，世界价格低于国内贸易前价格 价格下降，国内供给减少（生产者剩余由 B+C 变为 C），国内需求增加（贸易后消费者剩余由 A 变为 A+B+D），国内供给不足的那部分通过进口。整体来看，总剩余是增加了 D 虽然整体来看，无论是作为出口还是进口，总剩余都是增加的。但也是存在“输家”的，即利益受损的一方。这时候就看输家“声音”大不大了😂 ","date":"2022-04-30","objectID":"/2022/04/notes-principles-of-economics-ch9-international_trade/:1:2","tags":["经济学","课程笔记"],"title":"Ch9-国际贸易","uri":"/2022/04/notes-principles-of-economics-ch9-international_trade/"},{"categories":["FEM"],"content":"关税的影响 关税（tariff）：对在国外生产而在国内销售的物品征收的一种税。影响进口的情况 增收关税之后，供给量由 $Q_1^S$ 增加为 $Q_2^S$，原本处于世界价格时的边际厂商要嗝屁的、现在苟活着。部分生产者受益，消费者受损。产生 D+F 的无谓损失 ","date":"2022-04-30","objectID":"/2022/04/notes-principles-of-economics-ch9-international_trade/:1:3","tags":["经济学","课程笔记"],"title":"Ch9-国际贸易","uri":"/2022/04/notes-principles-of-economics-ch9-international_trade/"},{"categories":["FEM"],"content":"国际贸易的其他好处 自由的国际贸易增加了可供消费者消费的物品的多样性；使企业可以利用规模经济；使市场更具竞争性；并有助技术扩散。 ","date":"2022-04-30","objectID":"/2022/04/notes-principles-of-economics-ch9-international_trade/:1:4","tags":["经济学","课程笔记"],"title":"Ch9-国际贸易","uri":"/2022/04/notes-principles-of-economics-ch9-international_trade/"},{"categories":["FEM"],"content":"各种限制贸易的观点 ","date":"2022-04-30","objectID":"/2022/04/notes-principles-of-economics-ch9-international_trade/:2:0","tags":["经济学","课程笔记"],"title":"Ch9-国际贸易","uri":"/2022/04/notes-principles-of-economics-ch9-international_trade/"},{"categories":["FEM"],"content":"工作岗位论 基本论调是不保护人们就会失业，就像特朗普之前说让制造业回归美国。自由贸易在消灭一些岗位的同时，也创造的一些岗位。关键是看国人是否愿意跟着转型了。国人是不是要摆烂，大家是不是一起选择躺平。有时候觉得有个资本念想还是好的，通俗的讲就是知道如果有钱了就能成也算是黑暗世界中的烛光了，至少能看到希望。怕就怕各种门槛卡你，卡到你窒息、卡到作为普通老百姓的你无能为力。那不开摆干嘛😂 ","date":"2022-04-30","objectID":"/2022/04/notes-principles-of-economics-ch9-international_trade/:2:1","tags":["经济学","课程笔记"],"title":"Ch9-国际贸易","uri":"/2022/04/notes-principles-of-economics-ch9-international_trade/"},{"categories":["FEM"],"content":"国家安全论 国家安全这一点是没毛病的，毛爷爷就曾说过，抢杠子里面出政权。两国交战不可能说，存在一个某组织出售各种“战斗力”，然后进行交易甚至整个价高者得。同时这也间接说明“国家”、“政府”才是最大的暴力 ","date":"2022-04-30","objectID":"/2022/04/notes-principles-of-economics-ch9-international_trade/:2:2","tags":["经济学","课程笔记"],"title":"Ch9-国际贸易","uri":"/2022/04/notes-principles-of-economics-ch9-international_trade/"},{"categories":["FEM"],"content":"幼稚产业论 20世纪末、21世纪初时期中国的汽车行业。试图通过保护国内汽车行业，让其发展起来。 其实还得依赖企业家精神，保护起来也是当时有能力从事汽车生产的企业爽到，赚的盆满钵满 ","date":"2022-04-30","objectID":"/2022/04/notes-principles-of-economics-ch9-international_trade/:2:3","tags":["经济学","课程笔记"],"title":"Ch9-国际贸易","uri":"/2022/04/notes-principles-of-economics-ch9-international_trade/"},{"categories":["FEM"],"content":"作为讨价还价筹码的保护论 你打我一拳，我踢你一脚。大国之间的政治等各种关系。A对B的X产品增收关税；B对A的Y产品增收关税。大家一起打太极。也出现在 “中美贸易战” 拜登重新豁免352项中国商品关税 美中贸易战是否迎来转折点 - BBC News 中文 ","date":"2022-04-30","objectID":"/2022/04/notes-principles-of-economics-ch9-international_trade/:2:4","tags":["经济学","课程笔记"],"title":"Ch9-国际贸易","uri":"/2022/04/notes-principles-of-economics-ch9-international_trade/"},{"categories":["FEM"],"content":"Reference 曼昆，《经济学原理·微观经济学分册》，第7版，北京大学出版社 ","date":"2022-04-30","objectID":"/2022/04/notes-principles-of-economics-ch9-international_trade/:3:0","tags":["经济学","课程笔记"],"title":"Ch9-国际贸易","uri":"/2022/04/notes-principles-of-economics-ch9-international_trade/"},{"categories":["FEM"],"content":"台大经济学原理 课程笔记之“The Costs of Taxation” 税收是我们为文明社会所付出的代价。——Oliver Wendell Holmes Jr. ","date":"2022-04-10","objectID":"/2022/04/notes-principles-of-economics-ch8-the_costs_of_taxation/:0:0","tags":["经济学","课程笔记"],"title":"Ch8-赋税的代价","uri":"/2022/04/notes-principles-of-economics-ch8-the_costs_of_taxation/"},{"categories":["FEM"],"content":"赋税的无谓损失 无谓损失（deadweight los）：当税收（或某种其他政策）扭曲了市场结果时所引起的总剩余减少。 简单理解，人们（尤其是边际买卖双方）对税收（或某种其他政策）会做出相应的反应，使得原本会发生的交易没发生（dT\u003c0） ![Untitled](/Users/huwei/self_improve/blog/unclehuzi.github.io.source/content/posts/notes-principles-of-economics-Ch8-The_Costs_of_Taxation/The Costs cb2a0/Untitled.png) ","date":"2022-04-10","objectID":"/2022/04/notes-principles-of-economics-ch8-the_costs_of_taxation/:1:0","tags":["经济学","课程笔记"],"title":"Ch8-赋税的代价","uri":"/2022/04/notes-principles-of-economics-ch8-the_costs_of_taxation/"},{"categories":["FEM"],"content":"弹性影响无谓损失 供给和需求的弹性越大，税收的无谓损失也越大 ![Untitled](/Users/huwei/self_improve/blog/unclehuzi.github.io.source/content/posts/notes-principles-of-economics-Ch8-The_Costs_of_Taxation/The Costs cb2a0/Untitled 1.png) ","date":"2022-04-10","objectID":"/2022/04/notes-principles-of-economics-ch8-the_costs_of_taxation/:2:0","tags":["经济学","课程笔记"],"title":"Ch8-赋税的代价","uri":"/2022/04/notes-principles-of-economics-ch8-the_costs_of_taxation/"},{"categories":["FEM"],"content":"税收变动时的无谓损失和税收收入 ![Untitled](/Users/huwei/self_improve/blog/unclehuzi.github.io.source/content/posts/notes-principles-of-economics-Ch8-The_Costs_of_Taxation/The Costs cb2a0/Untitled 2.png) 拉佛曲线却死很好的描述了税收规模和税收收入之间的倒U关系。过去我总局限这种倒U关系，但曲线的拐（顶）点在当下如何得知？尤其是在左侧的时候。正如“物极必反”，这个“极”在哪儿？ 私认为，很难甚至没法一蹴而就，难以基于此时直接预测及知道顶点在哪儿，更多的还是需要贝叶斯思维，基于响应的反馈来不断修正，从而得知拐（顶）点 ","date":"2022-04-10","objectID":"/2022/04/notes-principles-of-economics-ch8-the_costs_of_taxation/:3:0","tags":["经济学","课程笔记"],"title":"Ch8-赋税的代价","uri":"/2022/04/notes-principles-of-economics-ch8-the_costs_of_taxation/"},{"categories":["FEM"],"content":"Reference 曼昆，《经济学原理·微观经济学分册》，第7版，北京大学出版社 ","date":"2022-04-10","objectID":"/2022/04/notes-principles-of-economics-ch8-the_costs_of_taxation/:4:0","tags":["经济学","课程笔记"],"title":"Ch8-赋税的代价","uri":"/2022/04/notes-principles-of-economics-ch8-the_costs_of_taxation/"},{"categories":["生活"],"content":"2022年3月上海， 🦠新冠病毒迎来“奥密克戎”。我作为一个观察者记录客观结果/消息 2019年年底、2020年年初的时候正逢硕士三年级的寒假，一直待在老家，吃喝主要由爸妈掌管，再加上十八线小县城不严重，3、4月份的时候就能出门活动了，但进入超市等聚集性场所时需要出示“健康码”，整体可以说是恢复了正常。那时候的我似乎也并没有觉得咋样，和以往假期差不多，就是时间长了许多。 ","date":"2022-04-05","objectID":"/2022/04/life-covid_19-observation/:0:0","tags":["碎碎念"],"title":"2022年3月上海新冠疫情流水账","uri":"/2022/04/life-covid_19-observation/"},{"categories":["生活"],"content":"流水账 时间来到了2022年3月13日 周日，下午回到上海住处的时候看见楼下停着一辆MPV，有三个“大白”（对穿着防护服工作人员（主要是医务人员）的简称，类似下图）。我好奇问了问这栋楼是有什么事了么，其中一个工作人员告诉我，没什么事，例行检查。事后才知道楼道里有密接，居家隔离。到晚上7点的样子楼就被封了，只进不出，实行了“2+12”（2天封闭管理，期间两次核酸检测，若大家都是阴则放开，否则继续封）。这会儿上海浦东新区以及我住处周边还没大面积的封楼、封小区，外卖、快递还算是正常。 到了3月16日 周三，居委会的工作人员说解封了。我以为一切都将结束，准备收拾收拾第二天去公司上班了。哪知晚上公司发来消息说上海职场周四、周五居家办公。此时的我依然是乐观态度😂 也不知道哪来的信心。 紧接着3月18日 周五晚上7点街道居委又发来消息说明后天开展两次核酸检测，让准备物资。经历了上一次“2+12”的我想当然的以为，周末封两天、周一又正常上班了。8点一刻的样子，我准备出门买点吃的，以能度过周末。周四、周五那两天我依然沉迷于工作，没太在意这些事儿，本打算周五晚上去公司拿键盘等配件的也没去。哪知道这次是直接把小区封了😂 等到3月20日 周日的时候大家还是想着周一能正常去上班的，直到下午5点20分的时候，我司HRBP发来消息说，自3月21日起上海职场继续居家办公，具体复工时间待定。紧接着，7点40分的时候小区也通知明、后天继续核酸检测。这一波应该是响应政府的号召 这时候配送人力就略显紧张了，外卖商家也少了，叮咚、盒马、每日优鲜、美团买菜等APP也是各种爆单，大家都开启了囤货模式，同时价格也不让涨。3月25日当天，“上海发布”公众号发三篇关于「价格」的事儿，政府严控价格。 资源是有限的，政府禁止了「价格」，那就要选择别的分配手段。私营企业这边主要是盒马等电商平台，平台方的分配机制不得而知，但作为老百姓的我直观感受是需要付出时间成本的，譬如盒马从一开始的晚上12点开始抢、到早上7点下单、再到模棱两可的说早8点30开放运力。以及下单时点大家蜂拥而至，一直不断重复戳着手机屏幕的“结算”button。政府便给配送物资的车辆发“通行证”以保障民生。谁能拿到通行证？通行证给谁？ 这段时间一直就持续这样的状态：早上6点起来抢物资，大约到6.15基本大局已定；继续睡会，8点30分再来碰碰运气。之后再起来开启一天紧张的工作直到晚上10点。 2022年3月28日 周一，新一轮核酸检测，划江而“治”，期间经历了四次核酸检测：两次是医务人员检测，两次是抗原自检。这周好在跟上了一两个社区团购，买了些自热饭和面包。我分别在2022年3月31日和4月2日领到政府的物资，第一波是6根黄瓜、6根胡萝卜和2颗卷心菜；第二波是挂面、一袋火腿肠和一罐午餐肉 国务院副总理孙春兰来沪，于 2022年4月4日 全市再来一波核酸检测 2022年4月6日，要求全市范围再进行一波检测。简单理解为不咋严重的采用抗原检测 2022年4月7日，全市范围再再进行一波 2022年4月8日，再再再开展 2022年4月18日，收到公司大礼包 2022年4月20日，所住小区收到政府的物资 （其实感觉挺有意思的，政府、公司就知道我需要这些东西？ 哈哈，有时候只是借着这些东西传递一些相应的“意思”罢了，但不见得就是经济的，毕竟这些东西我也难以加工，最终还是扔掉。怕就怕在最后有些不明事理之人从道德层面美名其曰浪费） 2022年5月31日 2022年6月1日，似乎疫情在一夜之间都结束了😂 出门不再卡“出入证”了。 ","date":"2022-04-05","objectID":"/2022/04/life-covid_19-observation/:1:0","tags":["碎碎念"],"title":"2022年3月上海新冠疫情流水账","uri":"/2022/04/life-covid_19-observation/"},{"categories":["生活"],"content":"一些有意思的图 官媒 🆚 某地前线 2022-04-05 微博 #上海买菜 话题被封杀，2022-04-08 有点意思，小区封了一个月，突然有阳性，居委会说是已转运。2022-04-13 见识下，什么叫真正的 0⃣️ source: https://covid19.who.int/region/searo/country/kp 网上有个 “四月之声” 的视频，单纯的记录下 感觉现在的操作有点像， 现在搞出来的常态化核酸，城市里搭建了很多小亭子（“核酸亭”），试问这些开支谁来支付呢？到最后不还是依然转嫁在普通老板姓身上？目前给的政策是，6月份免费做核酸，7月1日开始单管 ¥25/次，要知道在疫情之前，¥25能让我吃一顿“陈香贵”兰州牛肉面 大规模、高频做核酸的意义在哪儿？包括被封在家里的这将近三个月的时间里。病原体 =\u003e 传染源 =\u003e 传播途径 =\u003e 宿主 这条链路里要说干预能做的事有很多。但大规模、高频的核酸带来的增益又是几何？封控管理期间，核酸结果阳性了被带去“方舱”又如何？去了之后也是自己自愈，在那儿又没有药。（因为如果有相应的药压根就不用去所谓的“方舱”）。我理解这仅是链路中的一条：尽可能的控制传染源嘛。但去了方舱也是自愈…而且身边也有朋友的家属感染了，但同在屋檐下的其他家属依然正常，到底是病毒太弱还是其他人抵抗力太强？🤷‍♂️ 形成傳染病的傳播四項主要因素有：病原體、傳染源、傳播途徑 及宿主，稱之為傳染鏈。 另外，还有个社会性的问题，在这严格的封控政策下，日后大家如何对待曾经感染过的人？假如你是面试官，你知道求职者感染过新冠，你还给面试机会么？还会录用么？假如作为老师的你，得知你的学生感染过新冠，你还会像往常一样对他么？假如你是还在上小学的小朋友，你的同学感染了新冠，你还会和他一起玩么？…… 这无疑是会带来社会层面的后遗症：“歧视”。想到了什么？“艾滋” 。事后再来宣传新冠健康平等么？ ","date":"2022-04-05","objectID":"/2022/04/life-covid_19-observation/:2:0","tags":["碎碎念"],"title":"2022年3月上海新冠疫情流水账","uri":"/2022/04/life-covid_19-observation/"},{"categories":["读书笔记"],"content":"其实，你是为了大发雷霆而生气😠 以一个简单且常见的例子展开说明 小明同学去餐馆用膳，结果紧张的服务员不小心把番茄酱洒在了小明新买的衣服。小明很生气，对服务员大发雷霆。 这波操作似乎还是符合剧情的，即 生气 $\\Rightarrow$ 大发雷霆 但阿德勒心理学的态度是，因为小明要大发雷霆所以才生气，是“目的论”。 （「插播」 阿德勒、荣格、弗洛伊德 仨人所谓是心理学“三巨头”） 我们结合 📦箱子模型来看：外界刺激（“衣服被弄脏”）$\\Rightarrow$ 小明这个整体 $\\Rightarrow$ 行为（大发雷霆）。最后这个行为是小明自己选择的。其实最后选择什么是小明的自由，但就是需要对选择负责 o.o 我是被开篇这个观点吸引了，觉得很有意思。但也有不同的观点：认为是生硬的套上这一层目的。（不排除是我说的不富有感染力 😂） 借助这个例子是要想表达 我们应该立足于目的论而不是弗洛伊德的原因论；不可以从过去中找原因；要否定精神创伤；人不是受过去原因支配的存在，人是为了达成某种目的而采取行动的。 过去已然无法改变，我们需要专注于当下，做好此时此刻该做的事儿。过去和未来根本不存在，所以才要谈现在。起决定作用的既不是昨天也不是明天，而是“此时此刻”。 话又说回来，有时候在当下受挫或者受到些打击之类的很难专注于当下。但我们需要的是接受普通而又平庸的自己o.o “自我接纳”，而不是自我肯定，诚实的对待自己。正所谓，知之为知之，不知为不知，是知也。 我一直尝试用一句话来抽象概括全书😂 似乎是想营造一种“我理解了”的氛围。我还是诚实的对待自己吧😂 凭着自己的理解，还是有这么一张图👇 作为一个独立自由个体的我生活在这个世界上总会遇着你和他，即人际关系。这也带来了人生三大课题：👬交友、💻工作和❤️爱。而面对这三大课题，我们总会有烦恼、不开心的时候。为此，我们需要做的是“课题”分离，通过 责任方（“某种选择所带来的结果最终要由谁来承担？”） 确定这是谁的课题。此外，通过“自我接纳”、“他者信赖”、“他者贡献”建立起“共同体感觉”，以更好的解决人际关系的问题。 人的目标是追求幸福，开心快乐最为重要。正所谓重点不是说什么，而是做什么。经过独立、自由的个体选择后所产生的行动，肯定是有“爽点”的。或许是当下、或许是以后、或许…阿德勒心理学提倡、坚守的这些也是为了能增加自身的幸福感。 书中提到， 甚至也有人说要想真正理解阿德勒心理学直至改变生活方式，需要“相当于自身岁数一半的时间”。也就是说，如果40岁开始学的话，需要20年也就是到60岁才能学会。20岁开始学的话，加上10年，得到30岁才能学会。 修生养性的路子还长着呢～但在路上就是好的 🌞 ","date":"2022-03-01","objectID":"/2022/03/notes-the_courage_to_be_disliked/:0:0","tags":["心理学"],"title":"《被讨厌的勇气》","uri":"/2022/03/notes-the_courage_to_be_disliked/"},{"categories":["FEM"],"content":"台大经济学原理 课程笔记之“Efficiency of Markets” 步入新的篇章：市场与福利。福利经济学 welfare economics，研究资源配置如何影响经济福利。 ","date":"2022-03-01","objectID":"/2022/03/notes-principles-of-economics-ch7-efficiency_of_markets/:0:0","tags":["经济学","课程笔记"],"title":"Ch7-市场效率","uri":"/2022/03/notes-principles-of-economics-ch7-efficiency_of_markets/"},{"categories":["FEM"],"content":"消费者剩余 支付意愿（willingness to pay）：买者愿意支付的最高价格。衡量买者对物品的评价 消费者剩余（consumer surplus）：买者愿意为一种物品支付的量 减去 其为此实际支付的量。衡量买者从参与市场中得到的利益。 （类比营销里的 满意度=实际-预期） 需求曲线以下和价格以上的面积衡量一个市场上的消费者剩余（结合积分、极限来理解） 价格降低消费者剩余增加。之前爽到的更爽，之前没爽到的现在爽到了。“现在”是指价格降低后的时点 ","date":"2022-03-01","objectID":"/2022/03/notes-principles-of-economics-ch7-efficiency_of_markets/:1:0","tags":["经济学","课程笔记"],"title":"Ch7-市场效率","uri":"/2022/03/notes-principles-of-economics-ch7-efficiency_of_markets/"},{"categories":["FEM"],"content":"生产者剩余 生产者剩余（producer surplus）：卖者得到的量减去其生产成本。衡量卖者从市场中得到的利益 买者愿意为一种物品支付的量 减去 其为此实际支付的量。衡量买者从参与市场中得到的利益。 价格之下和供给曲线以上的面积衡量一个市场上的生产者剩余 价格上升生产者剩余增加。同理，之前爽到的更爽，之前没爽到的现在爽到了。“现在”是指价格上升后的时点 $$ \\begin{equation} \\begin{split} 总剩余 \u0026= 消费者剩余+生产者剩余\\ \u0026=(买者的评价-买者支付的量)+(卖者得到的量-卖者成本)\\ \u0026=买者的评价-卖者的成本 \\end{split} \\end{equation} $$ ","date":"2022-03-01","objectID":"/2022/03/notes-principles-of-economics-ch7-efficiency_of_markets/:2:0","tags":["经济学","课程笔记"],"title":"Ch7-市场效率","uri":"/2022/03/notes-principles-of-economics-ch7-efficiency_of_markets/"},{"categories":["FEM"],"content":"结论：市场效率和市场失灵 书中指出，市场失灵是指一些不受管制的市场不能有效的配置资源。而“市场势力”和“外部性”是典型的 🌰例子。“市场势力”是指影响价格的能力：在一些市场，某个单个（或一小群）卖者或买者可以控制价格。“外部性“是指买者和卖者的决策会影响那些不参与市场的人，譬如农药的使用不仅影响生产商和农民，还影响呼吸、饮用被农药污染的空气、水的其他人。 但张维迎教授认为 传统经济学所谓的“完全竞争”，实际上是没有竞争；所谓的“垄断”，实际上是真实市场中的竞争手段；外部性本质上是个产权界定问题；信息不对称是以分工为基础的市场经济的基本特征，市场本身是解决信息不对称的有效机制。因此，所谓的市场失灵，实际上是传统市场理论的失灵，不是市场本身的失灵；所谓的垄断、外部性和信息不对称的存在，都不构成政府干预市场的正当理由。——《经济学原理》 ","date":"2022-03-01","objectID":"/2022/03/notes-principles-of-economics-ch7-efficiency_of_markets/:3:0","tags":["经济学","课程笔记"],"title":"Ch7-市场效率","uri":"/2022/03/notes-principles-of-economics-ch7-efficiency_of_markets/"},{"categories":["FEM"],"content":"Reference ","date":"2022-03-01","objectID":"/2022/03/notes-principles-of-economics-ch7-efficiency_of_markets/:4:0","tags":["经济学","课程笔记"],"title":"Ch7-市场效率","uri":"/2022/03/notes-principles-of-economics-ch7-efficiency_of_markets/"},{"categories":["FEM"],"content":"台大经济学原理 课程笔记之“Supply, Demand and Government Policies” 经济受两种规则体系支配：供需规律和政府制定的法规。本章主要是举例分析政府介入后的供需变化 ","date":"2022-02-27","objectID":"/2022/02/notes-principles-of-economics-ch6-supply_demand_and_government_policies/:0:0","tags":["经济学","课程笔记"],"title":"Ch6-供给、需求与政府政策","uri":"/2022/02/notes-principles-of-economics-ch6-supply_demand_and_government_policies/"},{"categories":["FEM"],"content":"价格控制 ","date":"2022-02-27","objectID":"/2022/02/notes-principles-of-economics-ch6-supply_demand_and_government_policies/:1:0","tags":["经济学","课程笔记"],"title":"Ch6-供给、需求与政府政策","uri":"/2022/02/notes-principles-of-economics-ch6-supply_demand_and_government_policies/"},{"categories":["FEM"],"content":"价格上限（Price Ceiling） 政府規定價格不能超過一定金額 non-binding 若把價格定在均衡之上，則此約束無效，但若有一個供給面的衝擊發生(s 移往 s’)時， binding 則有可能變成有效，造成短缺。 例： 1970s 的石油危機衝擊造成 non-binding（線段 bc）意外轉變為短缺(線段 ab) binding 發生效力時會造成供不應求 例一：房租上限，政府往往為了保障弱勢團體有房子可住，常規定一價 格上限，但卻造成房子短缺（如線段 ab），反而害了想幫助的人。 ","date":"2022-02-27","objectID":"/2022/02/notes-principles-of-economics-ch6-supply_demand_and_government_policies/:1:1","tags":["经济学","课程笔记"],"title":"Ch6-供给、需求与政府政策","uri":"/2022/02/notes-principles-of-economics-ch6-supply_demand_and_government_policies/"},{"categories":["FEM"],"content":"价格下限（Price floor） 政府規定價格不能低於一定金額 non-binding: 若把價格定於均衡價格之下，則此限制無效 binding 發生效力時會造成供過於求（线段 bc） 譬如，最低工资法。劳动力即为供给方。 (1) 工會的組成 雖然有可能造成大規模的分配，但更可能的情況是工會內的既得利益者把持權力，只爭取已經有工作者的權益，沒有工作的人仍然沒有工作 (2) 老闆寧缺不補 政府只能規定最低工資，卻無法規定僱主的僱用意願，此時失業者難以獲得工作，政府政策反而只保護到既有勞工而非潛在勞工 (3) 企業主找到替代品 例如機器人的使用，有可能造成勞動需求的下降，嚴重者可能更多人失業（造成交點在 b 點左邊），如麥當勞在日前在歐洲 7000 個地方買進 touch screen cashier 便有可能造成這個效果 关于最低工资法，最有意思的当属2021年的诺贝尔经济学奖获得者之一：戴维·卡德（David Card）。David Card 曾經在 AER (American Economic Journal, one of top 4 American Economic journals) 發過一篇文章，說明最低工資不會讓失業增加，發表之時立即引起軒然大波，不過曾獲麥克阿瑟天才獎的芝大經濟系莫菲（ Kevin Murphy）教授卻發現，「 當次的基本工資上升。 整體來說，使得新州的十五到二十四歲年輕人、非裔美人以及女性的就業率大幅下降，而這些正是構成邊際勞工的最重要族群！ 」 我想林明仁教授在讲授这门课程的时候怎么也不会想到他能拿诺奖吧😂 ","date":"2022-02-27","objectID":"/2022/02/notes-principles-of-economics-ch6-supply_demand_and_government_policies/:1:2","tags":["经济学","课程笔记"],"title":"Ch6-供给、需求与政府政策","uri":"/2022/02/notes-principles-of-economics-ch6-supply_demand_and_government_policies/"},{"categories":["FEM"],"content":"税收 除了价格管制，政府还会通过 税收 影響市場 无论是向生产者征税还是向需求者征税都会得到相同的结果：消费者负担紅色線段，生產者負擔綠色線段，政府獲得黑色線段的稅收。看似单方面征税，实则供给双方均贡献了税收 譬如冰激凌🍦 的例子，原本市场达到了 $P_0$ 的均衡 此时政府对生产者征税 $P_x$ 1⃣️ 生产曲线上移，达到新的均衡价格 $P_1$ ，也是消费者支付的价格 2⃣️ 此时生产者实际得到的是 $P_1-P_x$ 3⃣️ 相比于 $P_0$ 状态，消费者多支付了 $P_1-P_0$ 即红色线段；生产者少了 $P_0-(P_1-P_x)$ 即绿色线段 此时政府向消费者征税 $P_x$ 1⃣️ 生产曲线下移，达到新的均衡价格 $P_1$ ，也是生产者所得到的收益 2⃣️ 因为对消费者征税，所以消费者支付的价格为 $P_1+P_x$ 3⃣️ 相比于 $P_0$ 状态，消费者多支付了 $P_1+P_x-P_0$ 即红色线段；生产者少了 $P_0-P_1$ 即绿色线段 當政府想改善公平性的時候，可以藉由課稅達成這個目標，因為其會進行租稅轉嫁，依據 bargaining power 來決定，而 bargainging power 又可由彈性看出（彈性是圖中供給需求線的斜率改變）。即负担比例更多取决于弹性如何。 相比需求，供给更富有弹性 此时税收主要由消费者承担 相比供给，需求更富有弹性 此时税收主要由生产者承担 相比游艇制造商，富人需求更富有弹性，替代品多。 此时税收主要由生产者即游艇制造商承担 ","date":"2022-02-27","objectID":"/2022/02/notes-principles-of-economics-ch6-supply_demand_and_government_policies/:2:0","tags":["经济学","课程笔记"],"title":"Ch6-供给、需求与政府政策","uri":"/2022/02/notes-principles-of-economics-ch6-supply_demand_and_government_policies/"},{"categories":["FEM"],"content":"Reference ","date":"2022-02-27","objectID":"/2022/02/notes-principles-of-economics-ch6-supply_demand_and_government_policies/:3:0","tags":["经济学","课程笔记"],"title":"Ch6-供给、需求与政府政策","uri":"/2022/02/notes-principles-of-economics-ch6-supply_demand_and_government_policies/"},{"categories":["FEM"],"content":"台大经济学原理 课程笔记之“Elasticity and its Application” 彈性（Elasticity）是用來衡量某一被解釋變數（Y）對其解釋變數（X）變動是否敏感的指標。 A measurement of responsiveness of variable Y to one of its determinants, X. 中文里提到「 有彈性」往往指容易受外力影響，圓融；而「 沒彈性」 🈯️不知變通，正直。 ","date":"2022-02-23","objectID":"/2022/02/notes-principles-of-economics-ch5-elasticity_and_its_application/:0:0","tags":["经济学","课程笔记"],"title":"Ch5-弹性及其应用","uri":"/2022/02/notes-principles-of-economics-ch5-elasticity_and_its_application/"},{"categories":["FEM"],"content":"需求弹性 $$ 需求的价格弹性=\\frac{需求变化百分比}{价格变化百分比} $$ 备注：被解释变数（Y）为分子，解释变数（X）为分母 ⚠️ 同时也需要注意，参考点不同，弹性不同，如下图所示 而且不同点之间的弹性也不同 ","date":"2022-02-23","objectID":"/2022/02/notes-principles-of-economics-ch5-elasticity_and_its_application/:1:0","tags":["经济学","课程笔记"],"title":"Ch5-弹性及其应用","uri":"/2022/02/notes-principles-of-economics-ch5-elasticity_and_its_application/"},{"categories":["FEM"],"content":"需求曲线 结合弹性来看，对应有5类 Name_cn name_en |Elasticity| 完全无弹性 Perfectly Inelastic $=0$ 完全弹性 Perfectly Elasticity $\\infty$ 无弹性需求 Inelastic Demand $\u003c1$ 单位弹性 Unit Elastic $=1$ 弹性需求 Elastic Demand $\u003e1$ ","date":"2022-02-23","objectID":"/2022/02/notes-principles-of-economics-ch5-elasticity_and_its_application/:1:1","tags":["经济学","课程笔记"],"title":"Ch5-弹性及其应用","uri":"/2022/02/notes-principles-of-economics-ch5-elasticity_and_its_application/"},{"categories":["FEM"],"content":"决定因素 替代品的多寡與強弱： 替代品多、強→彈性大 Ex: 便利商店裡的飲料 時間長短： the longer the time period → The larger the elasticity ，事緩則圓 Ex: gas↑ 一開始大家沒辦法只好忍耐；時間一久，改搭公車， 叫政府蓋捷運，或換省油車→汽油需求量下降幅度變大 Ex: 野蠻女友或宅男男友， 短期雞肋效果 vs.長期汰換效果 市場的定義： 定義愈窄， 彈性愈大 Ex: 松阪牛肉 vs.牛肉 vs. 食物， Lexus 460 vs. car →替代品多寡 必需品 vs. 奢侈品 必需品佔所得比例小，彈性小，奢侈品則反之。 Ex: visiting doctor vs. buying a sailboat 支出佔所得的比例越高，彈性越大。 Ex: 房價 vs.菜價 ","date":"2022-02-23","objectID":"/2022/02/notes-principles-of-economics-ch5-elasticity_and_its_application/:1:2","tags":["经济学","课程笔记"],"title":"Ch5-弹性及其应用","uri":"/2022/02/notes-principles-of-economics-ch5-elasticity_and_its_application/"},{"categories":["FEM"],"content":"Case Analysis — 总收入 通过需求弹性的角度来分析 总收入 Total Revenue（TR） （这里又以坐标轴为准 $P=f(Q)$ ， $TR$ 是关于 $Q$ 的函数） $$ TR=P\\times Q=P(Q)\\times Q $$ 需求曲线上的点与坐标轴围成的矩形面积即为 TR ，其中，中点处 TR 最大 无弹性需求，价格⬆️ TR⬆️ 弹性需求，价格⬆️ TR⬇️ ","date":"2022-02-23","objectID":"/2022/02/notes-principles-of-economics-ch5-elasticity_and_its_application/:1:3","tags":["经济学","课程笔记"],"title":"Ch5-弹性及其应用","uri":"/2022/02/notes-principles-of-economics-ch5-elasticity_and_its_application/"},{"categories":["FEM"],"content":"其他的需求弹性 ","date":"2022-02-23","objectID":"/2022/02/notes-principles-of-economics-ch5-elasticity_and_its_application/:1:4","tags":["经济学","课程笔记"],"title":"Ch5-弹性及其应用","uri":"/2022/02/notes-principles-of-economics-ch5-elasticity_and_its_application/"},{"categories":["FEM"],"content":"供给弹性 $$ 供给的价格弹性=\\frac{供给变化百分比}{价格变化百分比} $$ ","date":"2022-02-23","objectID":"/2022/02/notes-principles-of-economics-ch5-elasticity_and_its_application/:2:0","tags":["经济学","课程笔记"],"title":"Ch5-弹性及其应用","uri":"/2022/02/notes-principles-of-economics-ch5-elasticity_and_its_application/"},{"categories":["FEM"],"content":"供给曲线 Name_cn name_en |Elasticity| 完全无弹性 Perfectly Inelastic $=0$ 完全弹性 Perfectly Elasticity $\\infty$ 无弹性供给 Inelastic Supply $\u003c1$ 单位弹性 Unit Elastic $=1$ 弹性供给 Elastic Supply $\u003e1$ ","date":"2022-02-23","objectID":"/2022/02/notes-principles-of-economics-ch5-elasticity_and_its_application/:2:1","tags":["经济学","课程笔记"],"title":"Ch5-弹性及其应用","uri":"/2022/02/notes-principles-of-economics-ch5-elasticity_and_its_application/"},{"categories":["FEM"],"content":"决定因素 生产投入是否具备多种用途 比亚迪生产口罩 时间长短，时间拉长较有弹性 ","date":"2022-02-23","objectID":"/2022/02/notes-principles-of-economics-ch5-elasticity_and_its_application/:2:2","tags":["经济学","课程笔记"],"title":"Ch5-弹性及其应用","uri":"/2022/02/notes-principles-of-economics-ch5-elasticity_and_its_application/"},{"categories":["FEM"],"content":"Case Analysis 旨在 结合弹性分析供、需 ","date":"2022-02-23","objectID":"/2022/02/notes-principles-of-economics-ch5-elasticity_and_its_application/:3:0","tags":["经济学","课程笔记"],"title":"Ch5-弹性及其应用","uri":"/2022/02/notes-principles-of-economics-ch5-elasticity_and_its_application/"},{"categories":["FEM"],"content":"谷贱伤农 谷物产量增加，供给曲线 👉右移，价格下降，但人们对谷物的需求无弹性，所以Total Revenue 减少 ","date":"2022-02-23","objectID":"/2022/02/notes-principles-of-economics-ch5-elasticity_and_its_application/:3:1","tags":["经济学","课程笔记"],"title":"Ch5-弹性及其应用","uri":"/2022/02/notes-principles-of-economics-ch5-elasticity_and_its_application/"},{"categories":["FEM"],"content":"OPEC无法维持高油价 备注：参考资料横坐标标注有误 OPEC 联合减少石油供给，早期且短期内替代品较少，无弹性需求 $\\Rightarrow$​ 短期内价格 $\\uparrow$​​ （左图） 随着时间的推移，相应替代品增加，转为弹性需求 $\\Rightarrow$​​ 价格回落（右图） ","date":"2022-02-23","objectID":"/2022/02/notes-principles-of-economics-ch5-elasticity_and_its_application/:3:2","tags":["经济学","课程笔记"],"title":"Ch5-弹性及其应用","uri":"/2022/02/notes-principles-of-economics-ch5-elasticity_and_its_application/"},{"categories":["FEM"],"content":"打击毒品 👊“扫毒” 的点在于很难甚至不可能做到把供应转为 0 作者认为，要对人们进行教育，减少人们的毒品需求。 ","date":"2022-02-23","objectID":"/2022/02/notes-principles-of-economics-ch5-elasticity_and_its_application/:3:3","tags":["经济学","课程笔记"],"title":"Ch5-弹性及其应用","uri":"/2022/02/notes-principles-of-economics-ch5-elasticity_and_its_application/"},{"categories":["FEM"],"content":"Reference ","date":"2022-02-23","objectID":"/2022/02/notes-principles-of-economics-ch5-elasticity_and_its_application/:4:0","tags":["经济学","课程笔记"],"title":"Ch5-弹性及其应用","uri":"/2022/02/notes-principles-of-economics-ch5-elasticity_and_its_application/"},{"categories":["数据分析"],"content":"客户终生价值-CLV ","date":"2022-02-18","objectID":"/2022/02/da-customer-lifetime-value/:0:0","tags":["Python","CRM","CLV"],"title":"Customer Lifetime Value","uri":"/2022/02/da-customer-lifetime-value/"},{"categories":["数据分析"],"content":"简介 企业要活下去，终究是要讲究盈利的，尽管现代营销理论中谈及的 customer-based，终点也是获利。 为此企业花钱获客、投广告、促销、让利等等。但总有些用户是不买账的，没啥付费意愿，拉低了盈利。就像有人会买电商等平台的会员，但也有人不会购买这个会员。从企业盈利的角度来看，企业需要识别这些行为模式，细分客户并采取相应的行动。like 本文将记录如何用 Lifetimes 测算客户终生价值（Customer Lifetime Value, CLV） 一顿扒，大胆推测 Lifetimes 这个包的作者 在 Data Science 的工作中有遇到相关的问题，一不做二不休基于相关论文、manual、R的包等等参考资料，整了个Python版本。（是我羡慕及崇拜的样子） 整体纵向来看，Lifetimes 分为两大部分：一是数据准备等基建工作；二是模型等应用层。前者“基建”工作主要包括 utils.py里的数据处理部分，将客户维度的明细数据，汇总为 Frequency, Recency, T, Monetary_value 维度；以及切分时间外样本等。后者应用层部分主要是各Model的实现，基于利益细分为两大部分：（1）能预测未来交易的Model（transaction_prediction_model），譬如 Pareto/NBD, BG/NBD Model；（2）测算CLV的模型gamma_gamma_filter.GammaGammaFilter 。 这里的“Model”是传统统计学的方法，假设 xxx 服从xxx分布，进行统计建模，完成未来交易次数、CLV的估计。 For all models, the following nomenclature is used: frequency represents the number of repeat purchases the customer has made. This means that it’s one less than the total number of purchases. This is actually slightly wrong. It’s the count of time periods the customer had a purchase in. So if using days as units, then it’s the count of days the customer had a purchase on. T 观测时点 - 第一次购买时间 represents the age of the customer in whatever time units chosen (weekly, in the above dataset). This is equal to the duration between a customer’s first purchase and the end of the period under study. recency 观测时点内，最近一次购买时间 - 第一次购买时间 represents the age of the customer when they made their most recent purchases. This is equal to the duration between a customer’s first purchase and their latest purchase. (Thus if they have made only 1 purchase, the recency is 0.) monetary_value ⚠️ 均值 ⚠️ 客户维度的 value，譬如利润、收益 represents the average value of a given customer’s purchases. This is equal to the sum of all a customer’s purchases divided by the total number of purchases. Note that the denominator here is different than the frequency described above. 以客户维度的明细数据为例完成 CLV 的测算 ","date":"2022-02-18","objectID":"/2022/02/da-customer-lifetime-value/:1:0","tags":["Python","CRM","CLV"],"title":"Customer Lifetime Value","uri":"/2022/02/da-customer-lifetime-value/"},{"categories":["数据分析"],"content":"CLV 假设有张表（transaction_data）记录着客户交易的明细数据，形如 cust_no date amt a1 2020-02-15 113.3 a2 2020-02-15 213 a1 2020-03-05 12 a3 2020-02-25 4.66 ","date":"2022-02-18","objectID":"/2022/02/da-customer-lifetime-value/:2:0","tags":["Python","CRM","CLV"],"title":"Customer Lifetime Value","uri":"/2022/02/da-customer-lifetime-value/"},{"categories":["数据分析"],"content":"变量衍生 from lifetimes.utils import summary_data_from_transaction_data summary_with_money_value = summary_data_from_transaction_data(transaction_data ,customer_id_col = 'cust_no' ,datetime_col = 'date' , monetary_value_col = 'amt' , observation_period_end='2022-02-15' ) returning_customers_summary = summary_with_money_value[summary_with_money_value['frequency']\u003e0] # returning_customers_summary.head() Paper 中是假设交易频次和金额是独立的 Monetary value is independent of the underlying transaction process. ","date":"2022-02-18","objectID":"/2022/02/da-customer-lifetime-value/:2:1","tags":["Python","CRM","CLV"],"title":"Customer Lifetime Value","uri":"/2022/02/da-customer-lifetime-value/"},{"categories":["数据分析"],"content":"计算 from lifetimes import GammaGammaFitter from lifetimes import BetaGeoFitter # \"\"\"Beta Geo Fitter, also known as BG/NBD model.\"\"\" # similar API to scikit-learn and lifelines. bgf = BetaGeoFitter(penalizer_coef=0.0) ## 数据量小的时候调整 penalizer_coef（0.001 to 0.1） bgf.fit(returning_customers_summary['frequency'], returning_customers_summary['recency'], returning_customers_summary['T']) #print(bgf) ggf = GammaGammaFitter(penalizer_coef = 0) ggf.fit(returning_customers_summary['frequency'], returning_customers_summary['monetary_value']) clv_df = pd.DataFrame(ggf.customer_lifetime_value( bgf, #the model to use to predict the number of future transactions returning_customers_summary['frequency'], returning_customers_summary['recency'], returning_customers_summary['T'], returning_customers_summary['monetary_value'], time=12, # months discount_rate=0.01 # monthly discount rate ~ 12.7% annually )).reset_index() 这个方法更多是针对存量户测算CLV，在观测时点内Frequency\u003e0，对于新户或者说没发生交易的用户来说就不适用了。不过，看着似乎可以参考 🔗这个 的思路。结合测算后的CLV join 些 X，训练个回归模型，实现CLV的预测 ","date":"2022-02-18","objectID":"/2022/02/da-customer-lifetime-value/:2:2","tags":["Python","CRM","CLV"],"title":"Customer Lifetime Value","uri":"/2022/02/da-customer-lifetime-value/"},{"categories":["数据分析"],"content":"Reference Principles of Marketing, 17th. https://github.com/CamDavidsonPilon/lifetimes Counting your customers: who are they and what will they do next? “Counting Your Customers” the Easy Way: An Alternative to the Pareto/NBD Model RFM and CLV: Using iso-value curves for customer base analysis ","date":"2022-02-18","objectID":"/2022/02/da-customer-lifetime-value/:3:0","tags":["Python","CRM","CLV"],"title":"Customer Lifetime Value","uri":"/2022/02/da-customer-lifetime-value/"},{"categories":["FEM"],"content":"台大经济学原理 课程笔记之“Supply and Demand” 四种市场结构 完全竞争 垄断 寡占 Oligopoly 独占性竞争 Monopolistic Competition ","date":"2022-02-15","objectID":"/2022/02/notes-principles-of-economics-ch4-supply_and_demand/:0:0","tags":["经济学","课程笔记"],"title":"Ch4-供给和需求","uri":"/2022/02/notes-principles-of-economics-ch4-supply_and_demand/"},{"categories":["FEM"],"content":"Demand 需求量 (Quantity of Demand) : The amount of a good that buyers are willing and able to purchase. 在某种价格下，买家愿意且能购买的量。 需求法则 (Law of demand) : Other things being equal, the quantity demanded of a good falls when the price of the good rises. 其他情况不变的情况下，通常来说价格与需求量为负向关系。但也有意外 (比例非常少) 👇 Conspicuous goods (炫耀性商品) Veblen good 价格越高可能需求量越高 The Theory of the Leisure Class: An Economic Study of Institutions (1899), by Thorstein Veblen (《有闲阶级论》) 也是研究奢侈品的理论基础。 Giffen’s good (季芬財) 愛爾蘭經濟學家發現，由於當時經濟不佳、馬鈴薯是最便宜的食物，因此在馬鈴薯歉收導致價格上升之際，反而會有人搶購，畢竟就算買更貴的馬鈴薯也比其它食物便宜。 「MARK」关于需求曲线中横纵坐标的问题 如下图所示，横轴（X）是 Quantity 、纵轴（Y）是 Price，习惯性理解是X影响Y，即$Y=f(X)$ 但需求曲线描述的是，给定价格P，需求量Q几何，即 $Q=f(P)$​。林老师给的解释是鼻祖 Alfred Marshall 搞错了 P.S. 市場中不太可能每個人決定不買的價格相同，在此情況下加總，會產生許多拗折 (kinked)，最後就會變成一個有弧度的曲線。 为啥是凸的呢？私认为，高价的时候价格稍微降低一些，买的人也不会增加多少；极端至免费，不要白不要了，需求量增加很多。 ","date":"2022-02-15","objectID":"/2022/02/notes-principles-of-economics-ch4-supply_and_demand/:1:0","tags":["经济学","课程笔记"],"title":"Ch4-供给和需求","uri":"/2022/02/notes-principles-of-economics-ch4-supply_and_demand/"},{"categories":["FEM"],"content":"需求量的改变 v.s. 需求曲线的移动 Change in demand quantity 🆚 Shift in demand curve 前者是沿着需求曲线移动；后者是需求曲线发生移动 ","date":"2022-02-15","objectID":"/2022/02/notes-principles-of-economics-ch4-supply_and_demand/:1:1","tags":["经济学","课程笔记"],"title":"Ch4-供给和需求","uri":"/2022/02/notes-principles-of-economics-ch4-supply_and_demand/"},{"categories":["FEM"],"content":"影响需求曲线移动的因素 所得 Incomes normal good（income 增加，需求增加） 🆚 inferior good（income 增加， 需求减少） 但也取决于定义方式 相关物品价格 Prices of related goods 替代品 想要得到某種體驗收穫時，可以用A也可以用B，則A與B就是消費上的替代。 When a fall in the price of one good reduces the demand for another good, the two goods are called substitutes. A商品的需求量增加、B商品的需求量就會減少。 互补品 消費A商品時必須要和B商品一起消費。A商品的需求量增加、B商品的需求量也就會增加。 如，買鞋子不能只買左腳； 買爆米花配電影 偏好 Tastes 这个比较难以衡量。 买家人数 Number of buyers 市場需求是個人需求的平行加總，買家數量越多就會增加市場需求量。 对未来的预期 Expectations 如果可以做跨期替代時，像是知道之後購買會比較便宜就會減少當下的需求量，或是知道颱風來價格會上漲於是就先大量購買。 ","date":"2022-02-15","objectID":"/2022/02/notes-principles-of-economics-ch4-supply_and_demand/:1:2","tags":["经济学","课程笔记"],"title":"Ch4-供给和需求","uri":"/2022/02/notes-principles-of-economics-ch4-supply_and_demand/"},{"categories":["FEM"],"content":"Supply 供给量：在给定的价格，生产者愿意且能生产的数量。 其他情况不变的情况下，通常来说价格与需求量为正向关系。 很多情况类比 #需求 ","date":"2022-02-15","objectID":"/2022/02/notes-principles-of-economics-ch4-supply_and_demand/:2:0","tags":["经济学","课程笔记"],"title":"Ch4-供给和需求","uri":"/2022/02/notes-principles-of-economics-ch4-supply_and_demand/"},{"categories":["FEM"],"content":"影响供给曲线移动的因素 相关物品价格：替代、互补（生产者角度） 替代：整车厂生产轿车、SUV 互补举例：猪脑、猪排骨🥩、五花肉 生产要素价格（input price） 生产技术 预期：囤积居奇 卖方人数 ","date":"2022-02-15","objectID":"/2022/02/notes-principles-of-economics-ch4-supply_and_demand/:2:1","tags":["经济学","课程笔记"],"title":"Ch4-供给和需求","uri":"/2022/02/notes-principles-of-economics-ch4-supply_and_demand/"},{"categories":["FEM"],"content":"Equilibrium 供给均衡 当价格到达某个水平，供给量=需求量 ","date":"2022-02-15","objectID":"/2022/02/notes-principles-of-economics-ch4-supply_and_demand/:3:0","tags":["经济学","课程笔记"],"title":"Ch4-供给和需求","uri":"/2022/02/notes-principles-of-economics-ch4-supply_and_demand/"},{"categories":["FEM"],"content":"价格 \u003e 均衡价格： 剩余 Surplus 超额供给 ","date":"2022-02-15","objectID":"/2022/02/notes-principles-of-economics-ch4-supply_and_demand/:3:1","tags":["经济学","课程笔记"],"title":"Ch4-供给和需求","uri":"/2022/02/notes-principles-of-economics-ch4-supply_and_demand/"},{"categories":["FEM"],"content":"价格 \u003c 均衡价格：短缺 Shortage 超额需求 「MARK」 均衡分析不一定是实际的交易点。在一个范围内波动，但相差不大 供给 和 需求 是独立的 买卖不成，供需在 供需价格为负的情况 譬如视频中提到 某老师（supply）为了让学生（demand）听课赠送咖啡 ","date":"2022-02-15","objectID":"/2022/02/notes-principles-of-economics-ch4-supply_and_demand/:3:2","tags":["经济学","课程笔记"],"title":"Ch4-供给和需求","uri":"/2022/02/notes-principles-of-economics-ch4-supply_and_demand/"},{"categories":["FEM"],"content":"分析均衡变化 Decide whether the event shifts the supply or demand curve (or perhaps both). 确定供给、需求曲线是否移动 Decide in which direction the curve shifts. 确定移动方向 Use the supply-and-demand diagram to see how the shift changes the equilibrium price and quality. 看图说话，新的平衡点情况 改变需求 天气热 =》 冰激凌需求增加 改变供给 冰激凌的原材料——糖的价格增加 ","date":"2022-02-15","objectID":"/2022/02/notes-principles-of-economics-ch4-supply_and_demand/:3:3","tags":["经济学","课程笔记"],"title":"Ch4-供给和需求","uri":"/2022/02/notes-principles-of-economics-ch4-supply_and_demand/"},{"categories":["FEM"],"content":"供给九宫格 ","date":"2022-02-15","objectID":"/2022/02/notes-principles-of-economics-ch4-supply_and_demand/:3:4","tags":["经济学","课程笔记"],"title":"Ch4-供给和需求","uri":"/2022/02/notes-principles-of-economics-ch4-supply_and_demand/"},{"categories":["FEM"],"content":"Reference ","date":"2022-02-15","objectID":"/2022/02/notes-principles-of-economics-ch4-supply_and_demand/:4:0","tags":["经济学","课程笔记"],"title":"Ch4-供给和需求","uri":"/2022/02/notes-principles-of-economics-ch4-supply_and_demand/"},{"categories":["读书笔记"],"content":"对于“心理咨询”，现在我觉得是被污名化了，人们也有些误解 过去总觉得是心理有问题了才搞些“心理咨询”什么的，就像是只有生病了才去找医生👨‍⚕️ 基于《中国文化的深层结构》我更加认为“心理学”、“心理咨询”等等皆为舶来品（⚠️未考证）。或许是历史原因，中国自古以来对于“身心”健康更加重视的“身”，而对于自我“心”方面的关心较少；甚至认为“攻心为上”的捷径为“身”。所以，我大胆揣测心理学方面的研究较少。 对于《蛤蟆去看心理医生》这本书也会结合自身的心理咨询经历，其中也有些产生共鸣的地方。譬如书中有提到“老师用讲解模式，咨询师用倾听模式”，我在校咨询的时候早期还真的不习惯“倾听模式”，毕竟从小到大接触的都是灌输式的“讲解模式”，随着咨询次数的增加，后续慢慢的很享受这种交流方式。 之前和某同学聊天的时候得知，该同学在校期间心情不好或有啥想不通的时候就会预约学校的心理咨询 在此我不得不说华师的心理咨询很是认真、负责且专业了。正所谓没有对比就没有伤害 《蛤蟆去看心理医生》是以蛤蟆陷入抑郁为背景，以此进行心理咨询。（在此我还是想说并不是抑郁或心理疾病了才想着找心理咨询，尤其是在学校的时候。社会上的心理咨询成本确实较高） 书中反复提到蛤蟆现在的状态更多是和儿童时期的经历有关（有时候我不得不想以后怎么教育自己的孩子😂） 诚然过去已无法改变，我们现在、当下能做的是改变对过去的看法以此修身养性、强大自己，将自我从过去中解放出来。 我认为没有人能‘让’我们产生什么感受，除非他们用蛮力胁迫你。说到底，是我们‘选择’了自己的感受。我们‘选择’了愤怒，我们‘选择’了悲伤。” 这和“箱子模型”不谋而合了。外界的刺激 =\u003e 我 =\u003e 反应，“我”便是那个箱子。 书中通过“我是怎么看自己的”以及 “我是怎么看别人的”得到二维矩阵，即 我认为： 我好，你好 正所谓“大家好，才是真的好” 我好，你不好 “挑剔型家长” 我不好，你好 我不好，你不好 这些理念只是用来理解行为的方法，尤其是理解我们自己的行为。 记得在校咨询时，最后有个经验是在理性时（即“成人状态”）针对过去苦恼或自己讨厌的事情多想想解决方案，以备不时之需，虽然存在一定的“转化”（即未必能100%执行），但比过去进步了、心态好了就是进步呐。我想这也是自我成长的一个过程吧 ","date":"2022-02-08","objectID":"/2022/02/notes-counselling-for-toads/:0:0","tags":["心理学"],"title":"其实可以试试心理咨询","uri":"/2022/02/notes-counselling-for-toads/"},{"categories":["生活"],"content":"试图记录📝一些感悟，有些东西记着记着就成「原则」了吧 「MARK」如何解决“剧场效应”（以教育为例）的问题？（2022-02-05） “环境”越动荡的时候越要沉住气、保持学习，以备反弹的时候有机会顺势而为（2022-01-29） 当犹豫不决、拿不准的想法时，不要急于实施，多和朋友们（尤其是过来人）推心置腹的好好聊聊，多听听不同的声音。（2022-01-01） ","date":"2022-01-29","objectID":"/2022/01/life-thoughts/:0:0","tags":["鸡汤"],"title":"感悟？=\u003e原则？","uri":"/2022/01/life-thoughts/"},{"categories":["读书笔记"],"content":"读后感？可还行？ 从腾讯视角初窥中国互联网。之所以这么说是因为各大巨头的发展与壮大离不开当时的环境以及“企业家精神”，而本书也是在中国互联网的背景下记录下腾讯的一些里程碑事件。 《腾讯传》这本书于2016年出版，作者吴晓波将腾讯的发展分为三大时间段： 创业：1998—2004 出击：2005—2009 巨头：2010—2016 撸完之后让我产生了一些想法吧，难以说中国互联网的发展史，更多是其他书籍甚至学科之间的碰撞与融合。 ","date":"2022-01-22","objectID":"/2022/01/notes-bio-of-tencent/:0:0","tags":["传记"],"title":"《腾讯传》","uri":"/2022/01/notes-bio-of-tencent/"},{"categories":["读书笔记"],"content":"领先者的跟随策略 在校期间，浪迹图书馆时，翻看了一本博弈论方面的科普类书籍，大致记得有个理论的应用是说，领先者可通过模仿跟随者的策略维持其领先地位。 书中有句话是这么说的， 紧盯市场动态，以最快的方式复制成功者模式，利用QQ用户优势进行后发超越 而且书中也提到，业界对腾讯的评价大多是“抄袭”。其实这也是一种竞争策略啊😂 看到这我又想到了现在（2022年1月）的字节跳动，截止目前，字节依托抖音的用户优势陆陆续续差不多把目前各大互联网公司干的事儿都实现了：电商、本地生活、汽车媒体、长视频、房产中介、支付、借贷等等等 其实这种，从1到N快速孵化的模式，中台的优势是体现的淋漓尽致了。 书中的那句话就变成，【字节】 紧盯市场动态，以最快的方式复制成功者模式，利用抖音用户优势进行后发超越 是不是可以这么总结，互联网时代需要掌握流量，“流量”通过（新工具）解决满足中国特色的需求而获得 “领先者的跟随策略”可以说是通用性的“经验”，但是放在个案中是不是又是另外一回事儿呐，因为撸完后也有了第二个困惑 ","date":"2022-01-22","objectID":"/2022/01/notes-bio-of-tencent/:1:0","tags":["传记"],"title":"《腾讯传》","uri":"/2022/01/notes-bio-of-tencent/"},{"categories":["读书笔记"],"content":"为什么是新浪微博？ 对啊，有QQ用户的基础及导流，为什么不是腾讯微博呐？ 关于微博之间的战争书中笔墨并没“3Q大战”（360 v.s. QQ）多。作者似乎更多是归因于时间上的问题 腾讯微博上线于2010年5月，比新浪微博迟了整整8个月，这对于一个战略性产品来说，几乎是难以追赶的时间距离。——《腾讯传》 或许是我对微博无感，也或许是因为我懒，依然想不通为什么是新浪微博 🤔 至少在内因方面难以得到一手信息 o.o 对市场快速作出反应并“跑马圈地”的重要性确实无需多言，但腾讯的“模仿”大法为什么在“微博”这块儿失效了呢？🤔 几乎所有的观察家都意识到，在白热化的微博一战中，腾讯对新浪的取胜概率十分渺茫，“能够战胜微博的，一定不是另外一个微博”，如果没有新的战略级产品诞生——正如迈克尔·波特所提示的，“挑战者必须找到不同于领先者的新竞争方式以取得成功”，腾讯在移动互联网时代的未来无疑是黯淡的。——《腾讯传》 但我觉得这段话更像是引出下一章《微信：移动互联时代的“站台票”》的内容。 ","date":"2022-01-22","objectID":"/2022/01/notes-bio-of-tencent/:2:0","tags":["传记"],"title":"《腾讯传》","uri":"/2022/01/notes-bio-of-tencent/"},{"categories":["读书笔记"],"content":"下一个终端？ 2011年1月21日推出“微信”，腾讯张小龙谦虚的说通过微信拿到了移动互联时代的“站台票”。 基于我目前的认知，我一直按照终端的变革来切分互联网发展的时间点，即 PC =\u003e 手机。近十年来手机带来的便利性、普及性可谓是有目共睹。各大互联网公司依托于手机终端开展各自的业务，借助于手机终端打破对于人、产品和信息的时空限制。 那么，这就引发出了下一代终端是啥？未来依托什么呐？ 留意观察身边生活、活跃在数字时代的亲朋好友，放眼望去，大家鼻梁上都架着一副眼镜。可见，眼镜有天然的优势，那么眼镜有没有可能成为下一代终端呐？🤔 根据“智猪博弈”，我们可以等待大厂的结果~毕竟谷歌、苹果、华为等已经有推出各自的眼镜产品了。 本文可谓是以“大”见“小” / 管中窥豹 了，从《腾讯传》长文中 zhái 出某些点简单展开 o.o 更多是了解性质的范畴 ","date":"2022-01-22","objectID":"/2022/01/notes-bio-of-tencent/:3:0","tags":["传记"],"title":"《腾讯传》","uri":"/2022/01/notes-bio-of-tencent/"},{"categories":["生活"],"content":"巴菲特：不纠结过去的事，纠结也没用。人生只能向前看。 🔗 原文链接 1998年巴菲特在佛罗里达大学商学院做了一场演讲，段永平曾力荐这场演讲，并坦言自己看了不下10次。这场演讲也被人们称为：“这是巴菲特最经典的演讲，没有之一。” ","date":"2022-01-15","objectID":"/2022/01/life-forward/:0:0","tags":["鸡汤"],"title":"【转载】不纠结过去的事，人生只能向前看","uri":"/2022/01/life-forward/"},{"categories":["生活"],"content":"一、成功不只取决于智商和勤奋 我先简单说几句，把大部分时间留下来回答大家的问题。我想聊聊大家关心的话题。 请各位提问的时候一定要刁钻。你们问的问题越难，才越好玩。什么都可以问，就是不能问上个月我交了多少税，这个问题我无可奉告。 各位同学，你们毕业之后未来会怎样？ 我简单说说我的想法。各位在这所大学能学到大量关于投资的知识，你们将拥有成功所需的知识。 既然各位能坐在这里，你们也拥有成功所需的智商，你们还有成功所需的拼劲。你们大多数人都会成功地实现自己的理想。 但是最后你到底能否成功，不只取决于你的头脑和勤奋。 我简单讲一下这个道理。 奥马哈有个叫彼得•基威特的人，他说他招人的时候看三点：品行、头脑和勤奋。 他说一个人要是头脑聪明、勤奋努力，但品行不好，肯定是个祸害。品行不端的人，最好又懒又蠢。 我知道各位都头脑聪明、勤奋努力，所以我今天只讲品行。为了更好地思考这个问题，我们不妨一起做个游戏。 各位都MBA二年级的学生，应该很了解自己周围的同学了。假设现在你可以选一个同学，买入他今后一生之内10%的收入。 你不能选富二代，只能选靠自己奋斗的人。请各位仔细想一下，你会选班里的哪位同学，买入他今后一生之内10%的收入。 你会给所有同学做个智商测试，选智商最高的吗？未必。你会选考试成绩最高的吗？未必。 你会选最有拼劲的吗？不一定。因为大家都很聪明，也都很努力，我觉得你会主要考虑定性方面的因素。 好好想想，你会把赌注压在谁的身上？也许你会选你最有认同感的那个人，那个拥有领导能力，能把别人组织起来的人。 这样的人应该是慷慨大方的、诚实正直的，他们自己做了贡献，却说是别人的功劳。我觉得让你做出决定的应该是这样的品质。 找到了你最钦佩的这位同学之后，想一想他身上有哪些优秀品质，拿一张纸，把这些品质写在纸的左边。 下面我要加大难度了。为了拥有这位同学今后一生10%的收入，你还要同时做空另一位同学今后一生10%的收入，这个更好玩。 想想你会做空谁？你不会选智商最低的。你会想到那些招人烦的人，他们可能学习成绩优秀，但你就是不想和他们打交道，不但你烦他们，别人也烦他们。 为什么有人会招人烦？原因很多，这样的人可能自私自利、贪得无厌、投机取巧或者弄虚作假。类似这样的品质，你想想还有什么，请把它们写在刚才那张纸的右边。 看看左右两边分别列出来的品质，你发现了吗？这些品质不是把橄榄球扔出60米，不是10秒钟跑完100米，不是相貌在全班最出众。 左边的这些品质，你真想拥有的话，你可以有。这些是关于行为、脾气和性格的品质，是能培养出来的。在座的各位，只要你想要获得这些品质，没一个是你得不到的。 再看一下右边的那些品质，那些令人生厌的品质，没一个是你非有不可的，你身上要是有，想改的话，可以改掉。 大多数行为都是习惯成自然。我已经老了，但你们还年轻，想摆脱恶习，你们年轻人做起来更容易。 常言道，习惯的枷锁，开始的时候轻的难以察觉，到后来却重的无法摆脱。这话特别在理。 我在生活中见过一些人，他们有的和我年纪差不多，有的比我年轻十几二十几岁，但是他们染上了一些坏习性，把自己毁了，改也改不掉，走到哪都招人烦。他们原来不是这样的，但是习惯成自然，积累到一定程度，根本改不了了。 你们还年轻，想养成什么习惯、想形成什么品格，都可以，就看你自己怎么想了。 本•格雷厄姆，还有他之前的本•富兰克林，他们都这么做过。 本•格雷厄姆十几岁的时候就观察自己周围那些令人敬佩的人，他对自己说：“我也想成为一个被别人敬佩的人，我要向他们学习。”格雷厄姆发现学习他敬佩的人，像他们一样为人处世，是完全做得到的。 他同样观察周围遭人厌恶的人，摆脱他们身上的缺点。我建议大家把这些品质写下来，好好想想，把好品质养成习惯，最后你想买谁 10% 的收入，就会变成他。 你已经确定拥有自己100%的收入，再有别人的10%，这多好。你选择了谁，你都可以学得像他一样。 ","date":"2022-01-15","objectID":"/2022/01/life-forward/:1:0","tags":["鸡汤"],"title":"【转载】不纠结过去的事，人生只能向前看","uri":"/2022/01/life-forward/"},{"categories":["生活"],"content":"二、救赎长期资本管理公司的启示 这件事非常耐人寻味。长期资本管理公司的由来，相信在座的大多人都知道，实在太令人感慨了。 约翰•梅里韦瑟、艾瑞克•罗森菲尔德、拉里•希利布兰德、格雷格•霍金斯、维克多•哈格哈尼，还有两位诺贝尔奖桂冠得主罗伯特•默顿和迈伦•舒尔兹。 把他们这16个人加起来，他们的智商该多高，随便从哪家公司挑16个人出来，包括微软，都没法和他们比。 第一，他们的智商高得不得了。 第二，他们这 16 个人都是投资领域的老手。他们不是倒卖服装发的家，然后来搞证券的。他们这16个人加起来，有三四百年的经验了，一直都在投资这行摸爬滚打。 第三，他们大多数人都几乎把自己的整个身家财产都投入到了长期资本管理公司，他们把自己的钱也投进去了。他们自己投了几亿的钱，而且智商高超，经验老道，结果却破产了。真是让人感慨。 要让我写一本书的话，书名我都想好了，就叫《聪明人怎么做蠢事》，我的合伙人说我的自传可以叫这个名字。 但是，我们从长期资本这件事能得到很多启发：长期资本的人都是好人。我尊重他们。当我在所罗门焦头烂额的时候，他们帮过我。他们根本不是坏人。 但是他们为了赚更多的钱，为了赚自己不需要的钱，把自己手里的钱，把自己需要的钱都搭进去了。这不是傻是什么？绝对是傻，不管智商多高，都是傻。 为了得到对自己不重要的东西，甘愿拿对自己重要的东西去冒险，哪能这么干？ 我不管成功的概率是100比1，还是1000比1，我都不做这样的事。 假设你递给我一把枪，里面有1000个弹仓、100万个弹仓，其中只有一个弹仓里有一颗子弹，你说：“把枪对准你的太阳穴，扣一下扳机，你要多少钱？” 我不干。你给我多少钱，我都不干。 要是我赢了，我不需要那些钱；要是我输了，结果不用说了。这样的事，我一点都不想做，但是在金融领域，人们经常做这样的事，都不经过大脑。 有一本很好的书，不是书好，是书名好。这是一本烂书，但是书名起得很好，是沃尔特•古特曼写的，书名是《一生只需富一次》。这个道理难道不是很简单吗？ 假设年初你有1亿美元，如果不上杠杆，能赚10%，上杠杆的成功率是99%，能赚20%，年末时你有1.1亿美元，还是1.2亿美元，有区别吗？没一点区别。 要是年末你死了，写讣告的人可能有个笔误，虽然你有1.2亿，但他写成了1.1亿。 多赚的钱有什么用？一点用没有。对你、对你的家人，对别人，都没用。 要是亏钱了的话，特别是给别人管钱，亏的不但是钱，而且颜面扫地、无地自容，把朋友的钱都亏了，没脸见人。 我真理解不了，怎么有人会像这16个人一样，智商很高、人品也好，却做这样的事，一定是疯了。他们吃到了苦果，因为他们太依赖外物了。 我临时掌管所罗门的时候，他们和我说，六西格玛的事件、七西格玛的事件伤不着他们。他们错了。只看过去的情况，无法确定未来金融事件发生的概率。 他们太依赖数学了，以为知道了一只股票的贝塔系数，就知道了这只股票的风险。要我说，贝塔系数和股票的风险根本是八竿子打不着。 会计算西格玛，不代表你就知道破产的风险。我是这么想的，不知道现在他们是不是也这么想了。 说真的，我都不愿意以长期资本为例。我们都有一定的概率会摊上类似的事，我们都有盲点，或许是因为我们了解了太多的细枝末节，把最关键的地方忽略了。 亨利•考夫曼说过一句话：“破产的有两种人，一种是什么都不知道的，一种是什么都知道的。”说起来，真是令人扼腕叹息。 同学们，引以为戒。我们基本上没借过钱，当然我们的保险公司里有浮存金。但是我压根没借过钱。 我只有1万块钱的时候都不借钱，不借钱不一样吗？我钱少的时候做投资也很开心。 我根本不在乎我到底是有1万、10万，还是100万。除非遇上了急事，比如生了大病急需用钱。 当年我钱很少，但我也没盼着以后钱多了要过不一样的生活。从衣食住行来看，你我之间有什么差别吗？ 我们穿一样的衣服，我们都能喝天赐的可口可乐，我们都能吃上麦当劳，还有更美味的DQ冰淇淋，我们都住在冬暖夏凉的房子里，我们都在大屏幕上看橄榄球赛。你在大电视上看，我也在大电视上看。我们的生活完全一样，没多大差别。 要是你生了大病，会得到良好的治疗。如果我得了大病，也会得到良好的治疗。我们唯一不一样的地方是我们出行的方式不同。 我有一架小飞机，可以飞来飞去，我特别喜欢这架飞机，这是要花钱的。除了我们出行的方式不同，你说有什么是我能做，但你做不了的吗？ 我有一份我热爱的工作，但我一直都在做我喜欢的工作。当年我觉得赚1000 美元是一大笔钱的时候，我就喜欢我的工作。 同学们，做你们喜欢的工作。要是你总做那些自己不喜欢的工作，只是为了让简历上的工作经历更漂亮，那你真是糊涂了。 有一次，我去做一个演讲，来接我的是一个 28 岁的哈佛大学的学生。我听他讲完了他的工作经历，觉得他很了不起。 我问他：“以后你有什么打算？”他说：“等我MBA毕业后，可能先进一家咨询公司，这样能给简历增加一些分量。” 我说：“你才28岁，已经有这么漂亮的工作经历了，你的简历比一般人的漂亮10倍。你还接着做自己不喜欢的工作，不觉得有点像年轻的时候把性生活省下来，留到岁数大的时候再用吗？ 或早或晚，你们都应该开始做自己真心想做的事。 我觉得我说的话，大家都听明白了。各位毕业之后，挑一个自己真心喜欢的工作，别为了让自己的简历更漂亮而工作，要做自己真心喜欢的。 时间久了，你的喜好可能会变，但在做自己喜欢的事的时候，早晨你会从床上跳起来。 我刚从哥伦比亚大学商学院毕业，就迫不及待地希望立刻为格雷厄姆工作。我说我不要工资，格雷厄姆说我要的薪水太高了，我一直骚扰他。 回到奥马哈后，我做了三年股票经纪人，一直给格雷厄姆写信，告诉他我发现的投资机会。 最后，我终于得到了机会，在他手下工作了一两年。那是一段宝贵的经历。总之，我做的工作始终都是我喜欢的。 你财富自由之后想做什么工作，现在就该做什么工作，这样的工作才是理想的工作。做这样的工作，你会很开心，能学到东西，能充满激情。每天会从床上跳起来，一天不工作都不行。 或许以后你喜欢的东西会变，但是现在做你喜欢的工作，你会收获很多。我根本不在乎工资是多少。不知怎么，扯得有点远了。 总之，如果你现在有1块钱，以为将来有2块钱的时候，自己能比现在过得更幸福，你可能想错了。你应该找到自己真心喜欢做的事情，投入地去做。 别以为赚10倍或20倍能解决生活中的所有问题，这样的想法很容易把你带到沟里去。 在不该借钱的时候借钱，或者急功近利、投机取巧，做自己不该做的事，将来都没地方买后悔药。 ","date":"2022-01-15","objectID":"/2022/01/life-forward/:2:0","tags":["鸡汤"],"title":"【转载】不纠结过去的事，人生只能向前看","uri":"/2022/01/life-forward/"},{"categories":["生活"],"content":"三、喜欢什么样的公司？ 我喜欢我能看懂的生意。先从能不能看懂开始，我用这一条筛选，90%的公司都被过滤掉了。 我不懂的东西很多，好在我懂的东西足够用了。世界如此之大，几乎所有公司都是公众持股的。所有的美国公司，随便挑。 首先，有些东西明知道自己不懂的，不能做。 有些东西是你能看懂的。可口可乐，是我们都能看懂的，谁都能看懂。可口可乐这个产品从1886年起基本没变过。可口可乐的生意很简单，但是不容易。 我不喜欢很容易的生意，生意很容易，会招来竞争对手。我喜欢有护城河的生意。我希望拥有一座价值连城的城堡，守护城堡的公爵德才兼备。 有的生意，我看不出来十年后会怎样，我不买。一只股票，假设从明天起纽约股票交易所关门五年，我就不愿意持有了，这样的股票，我不买。 我买一家农场，五年里没人给我的农场报价，只要农场的生意好，我就开心。我买一个房子，五年里没人给我的房子报价，只要房子的回报率达到了我的预期，我就开心。 人们买完股票后，第二天一早就盯着股价，看股价决定自己的投资做得好不好。糊涂到家了。买股票就是买公司，这是格雷厄姆教给我的最基本的道理。 买的不是股票，是公司的一部分所有权。 只要公司生意好，而且你买的价格不是高得离谱，你的收益也差不了。投资股票就这么简单。 要买你能看懂的公司，就像买农场，你肯定买自己觉得合适的。没什么复杂的。这个思想不是我发明的，都是格雷厄姆提出来的。 我特别走运。19岁的时候，我有幸读到了《聪明的投资者》。我六七岁的时候就对股票感兴趣，11岁时第一次买股票。我一直都在自己摸索，看走势图、看成交量，做各种技术分析的计算，什么路子都试过。 后来，我读到了《聪明的投资者》，书里说，买股票，买的不是代码，不是上蹿下跳的报价，买股票就是买公司。我转变到这种思维方式以后，一切都理顺了。道理很简单。所以说，我们买我们能看懂的公司。 在座的各位，没有看不懂可口可乐公司的，但是某些新兴的互联网公司呢，我敢说，在座的各位，没一个能看懂的。 今年在伯克希尔的股东大会上，我说要是我在商学院教课，期末考试时，我会出这样的题目，告诉学生一家互联网公司的信息，让他们给这家公司估值。哪个学生给出了估值，我就给他不及格。 无论什么时候，都要知道自己在做什么，这样才能做好投资。 必须把生意看懂了，有的生意是我们能看懂的，但不是所有生意我们都能看懂。 ","date":"2022-01-15","objectID":"/2022/01/life-forward/:3:0","tags":["鸡汤"],"title":"【转载】不纠结过去的事，人生只能向前看","uri":"/2022/01/life-forward/"},{"categories":["生活"],"content":"四、在商业中所犯的错误 对于我和我的合伙人查理•芒格来说，我们犯过的最大的错误不是做错了什么，而是该做的没做。 在这些错误中，我们对生意很了解，本来应该行动，但不知道怎么了，我们就在那犹豫来犹豫去，什么都没做。 有些东西我们不明白就算了，但有些东西是我们能看明白的，本来可以赚几十亿、几百亿的，却眼睁睁看着机会溜走了。 我本来可以买微软赚几十亿，但这不算数，因为我一直搞不懂微软。但是医药股，我本来是可以赚到几十亿的，这些钱是我该赚到的，我却没赚到。 当克林顿当局提出医疗改革方案后，所有的医药股都崩盘了。我们本来可以买入医药股大赚特赚的，因为我能看懂医药股，我却没做这笔投资。 至于各位能看到的错误，几年前我买入美国航空优先股是个错误。当时我手里闲钱很多。手里一有闲钱，我就容易犯错。 查理让我去酒吧喝酒去，别在办公室里待着。但我还是留在办公室，兜里有钱，就做了傻事。每次都这样。当时我买了美国航空的优先股。没人逼我，是我自己要买的。 现在我有一个800热线电话，每次我一想买航空股，就打这个电话。电话那边的人会安抚我。 我说：“我是沃伦，又犯了想买航空公司的老毛病。” 他们说：“继续讲，别停下，别挂电话，别冲动。”最后那股劲就过去了。 我买了美国航空以后，差点把所有钱都亏进去，真是差一点全亏了。我活该亏钱。 我买入美国航空，是因为它是一只很合适的证券，但它的生意不好。对所罗门的投资也一样。我根本不想买它的生意，只是觉得它的证券便宜。这也算是一种错误。 本来不太喜欢公司的生意，却因为喜欢证券的条款而买了。这样的错误我过去犯过，将来可能还会犯。最大的错误还是该做的没做。 我想告诉大家，人们总说通过错误学习，我觉得最好是尽量从别人的错误里学习。不过，在伯克希尔，我们的处事原则是，过去的事就让它过去。 我有个合伙人，查理•芒格，我们一起合作40年了，我们从来没红过脸。我们对很多东西看法不一样，但是我们不争不吵。 我们从来不想已经过去的事。我们觉得未来有那么多值得期待的，何必对过去耿耿于怀。 不纠结过去的事，纠结也没用。人生只能向前看。 你们从错误里或许能学到东西，但最重要的是只投资自己能看懂的生意。如果你像很多人一样，跳出了自己的能力圈，听别人的消息买了自己毫不了解的股票，犯了这样的错，你需要反省，要记得只投资自己能看懂的。 你做投资决策的时候，就应该对着镜子，自言自语：“我要用每股55美元的价格买入100股通用汽车，理由是……” 自己要买什么，得对自己负责。一定要有个理由，说不出来理由，别买。 是因为别人在和你闲聊时告诉你这只股票能涨吗？这个理由不行。是因为成交量异动或者走势图发出了信号吗？ 这样的理由不行。你的理由，一定是你为什么要买这个生意。我们恪守这个原则，这是本•格雷厄姆教我的。 ","date":"2022-01-15","objectID":"/2022/01/life-forward/:4:0","tags":["鸡汤"],"title":"【转载】不纠结过去的事，人生只能向前看","uri":"/2022/01/life-forward/"},{"categories":["生活"],"content":"五、对分散投资的看法 如果不是职业投资者，不追求通过管理资金实现超额收益率的目标，我觉得应该高度分散。 我认为98%到99%的投资者应该高度分散，但不能频繁交易，他们的投资应该和成本极低的指数型基金差不多。 只要持有美国的一部分就可以了，这样投资，是相信持有美国的一部分会得到很好的回报，我对这样的做法毫无异议。对于普通投资者来说，这么投资是正路。 如果想积极参与投资活动，研究公司并主动做投资决策，那就不一样了。 既然你走上研究公司这条路，既然你决定投入时间和精力把投资做好，我觉得分散投资是大错特错的。 那天我在SunTrust的时候，说到过这个问题。要是你真能看懂生意，你拥有的生意不应该超过六个。 要是你能找到六个好生意，就已经足够分散了，用不着再分散了，而且你能赚很多钱。 我敢保证，你不把钱投到你最看好的那个生意，而是再去做第七个生意，肯定会掉到沟里。靠第七个最好的主意发家的人很少，靠最好的生意发家的人很多。 所以，我说任何人，在资金量一般的情况下，要是对自己要投资的生意确实了解，六个就很多了，换了是我的话，我可能就选三个我最看好的。 我本人不搞分散。我认识的投资比较成功的人，都不搞分散，沃尔特•施洛斯是个例外，沃尔特的投资非常分散，他什么东西都买一点。 ","date":"2022-01-15","objectID":"/2022/01/life-forward/:5:0","tags":["鸡汤"],"title":"【转载】不纠结过去的事，人生只能向前看","uri":"/2022/01/life-forward/"},{"categories":["生活"],"content":"六、如果能重新活一次，为了让生活更幸福，会怎么做？ 要是我重新活一次的话，我只想做一件事，选能活到120岁的基因。 我其实是非常幸运的。我经常举一个例子，觉得可能会对各位有启发，所以花两分钟时间讲讲。 假设现在是你出生前24小时，一个神仙出现了，他说：“孩子，我看你前途无量，我现在手里有个难题，我得设计你出生后生活的世界，我觉得太难了，你来设计吧。 你有24小时的时间，社会规则、经济规则、政府规则，这些都给你设计，你还有你的子孙后代都在这些规则的约束下生活。” 你问了：“我什么都能设计？” 神仙说：“对，什么都能设计。” 你说：“没什么附加条件？” 神仙说：“有一个附加条件。你不知道自己出生后是黑人还是白人，是富有还是贫穷，是男人还是女人，是身体健壮还是体弱多病，是聪明过人还是头脑迟钝。你知道的就一点，你要从一个装着58亿个球的桶里选一个球。” 我把这个叫娘胎彩票。你要从这58亿个球里选一个，这是你一生之中最重大的决定，它会决定你是出生在美国还是阿富汗，智商是130还是70。选出来之后，很多东西都注定了。你会设计一个怎样的世界？ 我觉得用这种思维方式可以很好地看待社会问题。 因为你不知道自己会选到哪个球，所以在设计世界的时候，你会希望这个世界能提供大量产品和服务，你希望所有人都能过上好日子。你会希望这个世界的产品越来越丰富，将来你的子孙后代能越过越好。 在希望世界能提供大量产品和服务的同时，还要考虑到有的人手气太差，拿到的球不好，天生不适合这个世界的体系，你希望他们不会被这个世界抛弃。 我天生非常适合我们现在的这个世界。我一生下来就具备了分配资金的天赋。这其实没什么了不起的。 如果我们都被困在荒岛上，永远回不来，我们所有人里，谁最会种地，谁最有本事。我再怎么说我多擅长分配资金，你们也不会理我。 我赶上了好时候。盖茨说，要是我生在几百万年前，早成了动物的盘中餐。他说：“你跑不快，也不会爬树，什么都不行，刚生下来就得被吃了。你生在今天是走运。” 既然我运气这么好，我就要把自己的天分发挥出来，一辈子都做自己喜欢的事，与自己喜欢的人交往，只和自己喜欢的人共事。 要是有个人让我倒胃口，但是和他走到一起，我能赚1亿美元，我会断然拒绝，要不和为了钱结婚有什么两样？ 无论什么时候，都不能为了钱结婚，要是已经很有钱了，更不能这样了，你们说是不是？ 我不为了钱结婚。我还是会一如既往地生活，只是不想再买美国航空了（2021年巴菲特股东大会又强调了这件事）！ 谢谢。 ","date":"2022-01-15","objectID":"/2022/01/life-forward/:6:0","tags":["鸡汤"],"title":"【转载】不纠结过去的事，人生只能向前看","uri":"/2022/01/life-forward/"},{"categories":["数据分析"],"content":"最近接触了曲线拟合（curve fitting），在此简单整理一波Python的实现方式 依稀记得高中数学课本有提到这个，$x$​​、$y$​​​​ 二维坐标。大致是两种方式：一种是看着像啥样或基于先验知识给出常见函数的关系式，通过数据拟合得到相应的系数；第二种是直接从数据出发，采用“基函数”拟合，和泰勒展开、级数有关系，函数越复杂拟合的越完美，但泛化能力就有待考究了，即复杂度越高越容易出现过拟合 「插播」这两种又让我想起了统计里的“参数估计”和“非参数估计” 备注：以下分类名称仅从个人理解出发 ","date":"2022-01-13","objectID":"/2022/01/da-curve-fitting-python/:0:0","tags":["曲线拟合","Python"],"title":"Python曲线拟合","uri":"/2022/01/da-curve-fitting-python/"},{"categories":["数据分析"],"content":"自定义函数拟合 “自定义函数拟合”即我们可以自行编写定义各种函数（如幂函数、指数函数等）关系，基于此对现有数据进行拟合。往往需要一些领域内的知识🤔 具体实现可参考 scipy.optimize.curve_fit ","date":"2022-01-13","objectID":"/2022/01/da-curve-fitting-python/:1:0","tags":["曲线拟合","Python"],"title":"Python曲线拟合","uri":"/2022/01/da-curve-fitting-python/"},{"categories":["数据分析"],"content":"官方示例 import matplotlib.pyplot as plt import numpy as np from scipy.optimize import curve_fit # 自定义函数 def func(x, a, b, c): return a * np.exp(-b * x) + c # 构造数据 xdata = np.linspace(0, 4, 50) y = func(xdata, 2.5, 1.3, 0.5) rng = np.random.default_rng() y_noise = 0.2 * rng.normal(size=xdata.size) ydata = y + y_noise # 拟合 popt, pcov = curve_fit(func, xdata, ydata) ## 设置参数取值范围 popt1, pcov1 = curve_fit(func, xdata, ydata, bounds=(0, [3., 1., 0.5])) # 可视化 plt.plot(xdata, ydata, 'b-', label='data') plt.plot(xdata, func(xdata, *popt), 'r-', label='fit: a=%5.3f, b=%5.3f, c=%5.3f' % tuple(popt)) plt.plot(xdata, func(xdata, *popt1), 'g--', label='fit: a=%5.3f, b=%5.3f, c=%5.3f' % tuple(popt1)) plt.legend() plt.show() curve_fit() 的参数方面： p0 系数初始值 bounds 各系数的取值范围 method 最优化算法，’lm’, ’trf’, ‘dogbox’ ","date":"2022-01-13","objectID":"/2022/01/da-curve-fitting-python/:1:1","tags":["曲线拟合","Python"],"title":"Python曲线拟合","uri":"/2022/01/da-curve-fitting-python/"},{"categories":["数据分析"],"content":"MARK-log 此外还要 MARK 的一点是关于 $log$​ 的问题，Python中 numpy 和 math 都可以计算对数（$log$） 首先 math.log 和 numpy.log 都是以自然常数 $e$​​​ 为底的自然对数，针对底数不同各自都有以2、10为底的函数，分别为log2(), log10() 。其中，math.log2(x), math.log10(x)计算的准确性高于 math.log(x,2), math.log(x,10) 但是 math.log() 支持自选底数，比如计算 $log_{12}{10}$​​ ：math.log(10,12) 其实结合“换底公式”， 这个就等价于 math.log(10)/math.log(12) $$ log_ab=\\frac{log_ca}{log_cb} $$ 但但但但是，numpy.log 是支持数组、列表等形式的，享受 broadcasting带来的快感；而 math.log 只支持单个数字的计算，若传入数组等 array_like 则会报错：TypeError: only size-1 arrays can be converted to Python scalars 若一定要用 math.log 也是可以的： [math.log(i) for i in [1,2,3,4,5]] ","date":"2022-01-13","objectID":"/2022/01/da-curve-fitting-python/:1:2","tags":["曲线拟合","Python"],"title":"Python曲线拟合","uri":"/2022/01/da-curve-fitting-python/"},{"categories":["数据分析"],"content":"基函数拟合 关于这部分，目前记录的 “基函数” 更多是多项式（polynomials）形式，numpy提供了 sub-package： numpy.polynomial （NumPy 1.4 版本，2009-12-28，引入的） Name Provides Polynomial Power series Chebyshev Chebyshev series Legendre Legendre series Laguerre Laguerre series Hermite Hermite series HermiteE HermiteE series Power series（Polynomial）就是我们常见的 $y=1+2x+3x^2$​ 这种 import numpy as np import matplotlib.pyplot as plt from numpy import polynomial as P x = np.array([10,20,30,40,50,60,70,80]) y = np.array([174,236,305,334,349,351,342,323]) # 3 表示想要拟合的最高次项是多少。 p = P.polynomial.Polynomial.fit(x,y,deg=3) # 表达式 # print(p) # 343.18750000000006 + 59.98042929292918·x¹ - 96.68750000000027·x² + 15.80744949494958·x³ yvals = p(x) #拟合y值 plt.plot(x, y, 's',label='original values') plt.plot(x, yvals, 'r',label='Power series') plt.legend() plt.show() ","date":"2022-01-13","objectID":"/2022/01/da-curve-fitting-python/:2:0","tags":["曲线拟合","Python"],"title":"Python曲线拟合","uri":"/2022/01/da-curve-fitting-python/"},{"categories":["数据分析"],"content":"MARK 在官方文档会看到 Polynomial 这个类前面套了好几层numpy.polynomial.polynomial.Polynomial 实则关系是 numpy.polynomial 下面有个 polynomial.py 文件，文件里有个类是 Polynomial。同理，剩下五种多项式也是如此，chebyshev.py 有个 Chebyshev类 在实际使用的时候可以严格遵守这种关系 from numpy import polynomial as P ## 使用 Power series 拟合 p = P.polynomial.Polynomial.fit(x,y,deg=3) ## 使用 Chebyshev series 拟合 c = P.chebyshev.Chebyshev.fit(x,y,deg=2) ## 其他几种多项式类似 plt.plot(x, y, 's',label='original values') plt.plot(x, p(x), 'r',label='Power series') plt.plot(x, c(x), 'g--',label='Chebyshev series') plt.legend() plt.show() ","date":"2022-01-13","objectID":"/2022/01/da-curve-fitting-python/:2:1","tags":["曲线拟合","Python"],"title":"Python曲线拟合","uri":"/2022/01/da-curve-fitting-python/"},{"categories":["数据分析"],"content":"Reference https://numpy.org/doc/stable/reference/generated/numpy.log.html https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html https://docs.python.org/3.7/library/math.html https://numpy.org/doc/stable/reference/routines.polynomials.html https://numpy.org/doc/stable/reference/routines.polynomials.package.html#module-numpy.polynomial https://numpy.org/doc/stable/reference/generated/numpy.polynomial.polynomial.polyfit.html#numpy.polynomial.polynomial.polyfit https://numpy.org/doc/stable/reference/routines.polynomials.html https://www.jianshu.com/p/44baeed131df ","date":"2022-01-13","objectID":"/2022/01/da-curve-fitting-python/:3:0","tags":["曲线拟合","Python"],"title":"Python曲线拟合","uri":"/2022/01/da-curve-fitting-python/"},{"categories":["FEM"],"content":"经徐惟能教授许可，转载其知乎的回答 原文链接 恰逢2020年毕业季，学院邀请了徐教授作讲座，当时也咨询过徐教授关于量化的一些事儿，老师也推荐了相关金融、经济方面的书籍，在此也做个同步，防走丢 = = = = = = 分割线 = = = = = = 在金融学领域教学科研多年，在这里我系统化地只推荐高质量的优秀教材。金融学和其他学科一样，是需要沉下心来认真领悟其中逻辑的一门学科。市面上充斥着大量所谓可以赚快钱的金融学快餐文化，本人并不推荐。只知其一、不知其二，试图多快好省地实现财务自由对于很多人来讲是不切实际的——韭菜就是这么来的。 我按照金融学学习的总体架构分，推荐以下一些书籍： ","date":"2022-01-08","objectID":"/2022/01/fem-resources/:0:0","tags":["金融","经济学"],"title":"系统学习金融经济方面知识的书籍推荐","uri":"/2022/01/fem-resources/"},{"categories":["FEM"],"content":"1. 经济学常识 第一大类：经济学常识。经济学是金融学的基础和基石。金融学的很多逻辑和原理和经济学是相通的。一般高校在专业课程安排上会在大一大二安排《微观经济学》和《宏观经济学》两门课程，道理也是如此。这里建议学习曼昆的经济学原理，分微观经济学和宏观经济学两部分。先学习微观经济学、再学习宏观经济学：这两本书也是我十多年前初入金融经济学大门的启蒙书，高度推荐。 ","date":"2022-01-08","objectID":"/2022/01/fem-resources/:1:0","tags":["金融","经济学"],"title":"系统学习金融经济方面知识的书籍推荐","uri":"/2022/01/fem-resources/"},{"categories":["FEM"],"content":"2. 财务会计入门 第二大类：财务会计入门。财务会计的基础知识是理解公司财务所必备的先修内容。会计学为企业财务决策提供了数据支持和依据。一般高校会在大一大二安排《财务会计》课程。当然在这里，取决于读者的需求——对于大部分不太想花太多时间深究会计分录及做账的读者来说，可能了解企业的三张报表（资产负债、利润表、现金流量表）及其互相之间的联系可能就够了，对于这样的读者，请跳到第三部分。否则，如果想对财务会计有一定深入了解的读者，请参考以下这个问题中的答案。我的专业背景不是会计学，因此不想在这里随意推荐，误导各位。 ","date":"2022-01-08","objectID":"/2022/01/fem-resources/:2:0","tags":["金融","经济学"],"title":"系统学习金融经济方面知识的书籍推荐","uri":"/2022/01/fem-resources/"},{"categories":["FEM"],"content":"3. 金融学原理及公司金融 第三大类：金融学原理及公司金融。有些答主可能会推荐先专门读一本有关于金融市场学方面的教材，再进入公司金融的学习。但我认为先后次序并无所谓。一般高校的金融学专业会在大二大三安排一门类似《金融学原理》的课程，这门课程的教材一般运用的就是公司金融的教材。在上一段，我建议想粗略了解三大报表的读者跳到这一段，因为我推荐的这本教材囊括了最基本的、公司金融所必要的财务会计知识，又涉及资本市场运作的一些扫盲，同时也涵盖了公司金融的全部内容： 这本教材是《公司金融》的经典之作，也是我从教8年来一直在课上使用的教材。前几章铺垫了金融学的基本框架、货币时间价值、基本的财务分析基础，然后循序渐进地引出公司金融这个金融学大分支的各个方面。如果读者能够认真读完，必将对企业的价值创造、财务管理、财务分析有一个系统化的全新认识，又对金融市场有一个初步的认知。 我在知乎上开过一个有关于一个公司金融入门的 Live，差不多相当于我在学校授课《公司金融》的第一堂课，希望给刚刚入门金融学，准备学习《公司金融》的同学一些指导和启发： ","date":"2022-01-08","objectID":"/2022/01/fem-resources/:3:0","tags":["金融","经济学"],"title":"系统学习金融经济方面知识的书籍推荐","uri":"/2022/01/fem-resources/"},{"categories":["FEM"],"content":"4. 投资学 第四大类：投资学。读完公司金融以后，读者可能会有跃跃欲试的冲动，那么这个时侯学习《投资学》将是水到渠成的事情。投资学是资产定价的一部分，也是金融学领域另一个重大分支，它涉及各种金融资产的特点性质、投资组合的要领、金融资产的交易等等内容。在这里我推荐博迪的《投资学》： 好，如果读者能够坚持读到这里，读完上述几本书籍，其实已经对于金融学有了一个很完整的概览了。 ","date":"2022-01-08","objectID":"/2022/01/fem-resources/:4:0","tags":["金融","经济学"],"title":"系统学习金融经济方面知识的书籍推荐","uri":"/2022/01/fem-resources/"},{"categories":["FEM"],"content":"5. 进阶 如果读者还有兴趣，或者想更进阶一些，我再推荐几本延伸的方向： 想更多了解金融衍生品的：以下这本教材是个经典著作（原版+中文译版） 想更多了解行为金融学的：诺奖获得者、耶鲁大学教授席勒的著作： 想往数理金融方向拓展、入门计量经济学的： 能把这些教材读懂吃透，对于金融学来讲已经不仅仅是入门了。 = = = = = = 分割线 = = = = = = 毕业后也有看老师推荐的经济学、财务报表方面的书籍、资料，但遗憾的是一直没坚持，无论是曼昆的经济学原理还是财务报表分析皆中断 希望2022年能都好好补上～ ","date":"2022-01-08","objectID":"/2022/01/fem-resources/:5:0","tags":["金融","经济学"],"title":"系统学习金融经济方面知识的书籍推荐","uri":"/2022/01/fem-resources/"},{"categories":["生活"],"content":"限制 pday 分区时，开头要写 2022 了 ","date":"2022-01-01","objectID":"/2022/01/life-new-year-2022/:0:0","tags":["碎碎念","总结与展望"],"title":"回顾2021，展望2022","uri":"/2022/01/life-new-year-2022/"},{"categories":["生活"],"content":"向后看 2021 2021年是毕业后完整的第一个自然年。这一年在很多事我都没处理好，也很糟糕。 若展开细说，故事真的太长、太长，或许也是我不愿再回忆及梳理。但理性的时候想想还是得到之前的结论：这些都是人生中的素材。 正如杨绛先生所说， 如果事与愿违 请相信一定另有安排。 工作、情感等方面遇到磕磕绊绊很多也是自己造成的，万事皆有因，万般皆是果。 而我们要做的便是从素材中总结出经验教训，避免再犯 叨叨了这么多，也不符合向后看的主题 hhhhh （非记叙文） 就让我们放下往事，管它过去有多美。 ","date":"2022-01-01","objectID":"/2022/01/life-new-year-2022/:1:0","tags":["碎碎念","总结与展望"],"title":"回顾2021，展望2022","uri":"/2022/01/life-new-year-2022/"},{"categories":["生活"],"content":"向前看 2022 既然放下，则应向前看。 所有的失去，都将以另一种方式归来。 因果循环，都是命数～ 济姐与我说， 世界不是围着你转的，不是所有的事情都要跟着你的进程来的 是的，我记得有人总结过类似人生阶段的东西，其中一个便是 以自我为中心，总认为世界是围着自己转的。 说白了就还是心智还不够成熟，总要经历些什么让自己成长，而所付出的代价便是因人而异了。 若想降低相应的代价，我认为“向前看”便是 当你有犹豫不决、拿不准的想法时，不要急于实施，多和朋友们（尤其是过来人）推心置腹的好好聊聊，多听听不同的声音。以此降低犯错成本。 过去，我总会寄希望于“新年新气象”，即真的单纯的认为什么都不用做，事情放那儿就能解决。其实只是忘却了罢了；其实只是要去做另一件事罢了，可能还是影响下一件事。然而之前困扰我的事情始终没有得到很好的解决。历史总会重演，再见面时还是会不知所措。 所以，向前看，不仅光看着外部环境中 2021 的 1 变成了 2；更多还是要自己主动的去解决问题，正所谓幸福掌握在自己手中～ 等待并期待新气象的同时，也要解决问题～ ","date":"2022-01-01","objectID":"/2022/01/life-new-year-2022/:2:0","tags":["碎碎念","总结与展望"],"title":"回顾2021，展望2022","uri":"/2022/01/life-new-year-2022/"},{"categories":["数据分析"],"content":"当下处理大规模数据集比较流行的两大产品：Hive和Spark。本文从历史等维度对两者进行比较 🔗原文链接 ","date":"2021-12-27","objectID":"/2021/12/da-hive-vs-spark/:0:0","tags":["Hive","Spark"],"title":"Hive和Spark的区别","uri":"/2021/12/da-hive-vs-spark/"},{"categories":["数据分析"],"content":"Hive Hive 是一个运行在 Hadoop 分布式文件系统上的开源分布式数据仓库。Hive为查询和分析大规模（以表格形式存储的）结构化数据集而生。人们可以通过Hive内置的SQL引擎——HiveQL操作数据。将HiveSQL解析为Map-Reduce的操作。 ","date":"2021-12-27","objectID":"/2021/12/da-hive-vs-spark/:1:0","tags":["Hive","Spark"],"title":"Hive和Spark的区别","uri":"/2021/12/da-hive-vs-spark/"},{"categories":["数据分析"],"content":"简短的历史 Hive最初是由 Facebook 开发的，当时Facebook的开发人员发现他们的数据在几天内从 GB级别 呈指数增长到 TB级别。当时，Facebook 使用 Python 将他们的数据加载到关系型数据库。性能和可扩展性很快成为棘手的问题，因为关系型数据库只能纵向扩展。他们需要一个可以横向扩展并处理大量数据的数据库。那时Hadoop已经很流行了；不久之后，构建在 Hadoop 之上的 Hive 便出现了。Hive和关系型数据库很类似，但又不完全是。 ","date":"2021-12-27","objectID":"/2021/12/da-hive-vs-spark/:1:1","tags":["Hive","Spark"],"title":"Hive和Spark的区别","uri":"/2021/12/da-hive-vs-spark/"},{"categories":["数据分析"],"content":"为什么选择Hive 选择 Hive 的核心原因是因为它是一个运行在 Hadoop 上的 SQL 接口，降低了MapReduce框架的复杂性。Hive 帮助企业在 HDFS 上执行大规模数据分析，使其成为一个可横向扩展的数据库。它的 SQL 接口——HiveQL，使具有关系型数据库背景的开发人员可以更轻松地构建和开发性能更快、可扩展的数据仓库。（简单来说是上手快，方便原有DBA完成数据建模） ","date":"2021-12-27","objectID":"/2021/12/da-hive-vs-spark/:1:2","tags":["Hive","Spark"],"title":"Hive和Spark的区别","uri":"/2021/12/da-hive-vs-spark/"},{"categories":["数据分析"],"content":"Hive的特性和功能 Hive 具有企业级特性和功能，可帮助组织构建高效、高端的数据仓库解决方案。具备以下特性： Hive 使用 Hadoop 作为其存储引擎，并且仅在 HDFS 上运行 它专为数据仓库操作而构建，但不适用于 OLTP HiveQL 是 SQL 引擎，可为数据仓库层级的操作构建复杂的 SQL 查询。Hive 可以与其他分布式数据库（如 HBase）和 NoSQL 数据库（如 Cassandra）集成。 Hive的架构 有一个 Hive 接口，并使用 HDFS 跨多个服务器存储数据以进行分布式数据处理。 Hive在数仓中的应用 Hive 是专门为操作数据仓库而构建的数据库，尤其是那些处理TB、PB级数据的数据库。正如上文所说，Hive支持横向扩展，并结合 Hadoop 的功能，使其成为一个快速、高效及高维扩展的数据库。它可以在数千个节点上运行，充分体现硬件的性能。这使得 Hive 成为具有高性能和可扩展性的高性价比产品。 Hive 的集成功能 因为 HiveQL 符合 ANSI SQL标准，所以 HBase 和 Cassandra 等数据库也可以集成Hive。这些数据库对 SQL 的支持有限，但可以帮助应用程序对更大的数据集进行分析。Spark, Kafka和Flume等工具也可以集成Hive。 ","date":"2021-12-27","objectID":"/2021/12/da-hive-vs-spark/:1:3","tags":["Hive","Spark"],"title":"Hive和Spark的区别","uri":"/2021/12/da-hive-vs-spark/"},{"categories":["数据分析"],"content":"Hive的不足 Hive 是一个以表格形式存储数据的数据仓库，所以他只能处理使用 SQL 查询读取和写入的结构化数据。并不适用于存储非结构化数据，也不适用于OLTP。 ","date":"2021-12-27","objectID":"/2021/12/da-hive-vs-spark/:1:4","tags":["Hive","Spark"],"title":"Hive和Spark的区别","uri":"/2021/12/da-hive-vs-spark/"},{"categories":["数据分析"],"content":"Spark Spark 是一个分布式大数据框架，可处理并分析 RDD 格式的大规模数据集。简而言之，Spark 不是数据库，而是一个框架，可以将Hive和HBase等数据库中的数据加载至Spark的RDD，以享受分布式带来的快感。 ","date":"2021-12-27","objectID":"/2021/12/da-hive-vs-spark/:2:0","tags":["Hive","Spark"],"title":"Hive和Spark的区别","uri":"/2021/12/da-hive-vs-spark/"},{"categories":["数据分析"],"content":"Spark Streaming Spark Streaming是Spark 的一个扩展，它可以从 Web 源流式传输实时数据以进行各种分析。尽管还有其他工具（例如 Kafka 和 Flume）可以执行此操作，但 Spark 在复杂的数据分析方面更胜一筹。Spark 有自己特有的 SQL 引擎，并且在与 Kafka 和 Flume 集成时也能很好的兼容。 ","date":"2021-12-27","objectID":"/2021/12/da-hive-vs-spark/:2:1","tags":["Hive","Spark"],"title":"Hive和Spark的区别","uri":"/2021/12/da-hive-vs-spark/"},{"categories":["数据分析"],"content":"简短的历史 Spark 是 MapReduce 的替代方案。Spark通过“in-memory”的形式完成大数据分析，不依赖磁盘空间及网络带宽。 ","date":"2021-12-27","objectID":"/2021/12/da-hive-vs-spark/:2:2","tags":["Hive","Spark"],"title":"Hive和Spark的区别","uri":"/2021/12/da-hive-vs-spark/"},{"categories":["数据分析"],"content":"为什么选择Spark Spark 的核心优势在于它能够执行复杂的“in-memory”分析和 PB 级的流数据，效能优于MapReduce。Spark 可以从运行在 Hadoop 上的任何数据存储中提取数据，并在内存中并行执行复杂的分析。此功能减少了磁盘 I/O 和网络争用，使其速度提高了十倍甚至一百倍。此外，Spark 中的数据分析框架可以使用 Java、Scala、Python、R 甚至 SQL 构建。 ","date":"2021-12-27","objectID":"/2021/12/da-hive-vs-spark/:2:3","tags":["Hive","Spark"],"title":"Hive和Spark的区别","uri":"/2021/12/da-hive-vs-spark/"},{"categories":["数据分析"],"content":"Hive的特性和功能 Spark的架构 四大主要部分： Spark SQL Spark Streaming MLlib (machine learning) GraphX (graph 高效分析 Spark 从 Hadoop 中提取数据并在内存中执行分析。数据以并行方式分块进入内存，然后将生成的数据集推送到目的地。数据集也可以驻留在内存中，直到它们被消耗。 Spark Streaming Spark Streaming 是 Spark 的扩展，它可以实时流式传输来自高频使用的 Web 源的大量数据。由于其执行高级分析的能力，与其他数据流工具（如 Kafka 和 Flume）相比，Spark 便脱颖而出。 多个API Spark 支持不同的编程语言，如 Java、Python 和 Scala，这些语言在大数据和数据分析领域非常流行。人们可以使用这些语言中的任何一种编写数据分析框架。 处理大规模数据集 Spark也是为了分析、处理大数据的，就像上文提到的MapReduce。也是为了更加高效的大数据分析工作 ","date":"2021-12-27","objectID":"/2021/12/da-hive-vs-spark/:2:4","tags":["Hive","Spark"],"title":"Hive和Spark的区别","uri":"/2021/12/da-hive-vs-spark/"},{"categories":["数据分析"],"content":"Hive v.s. Spark Hive 和 Spark 是在大数据领域为不同目的而构建的不同产品。 Hive 是分布式数据库，Spark 是数据分析框架。 Hive Spark 类似关系型数据库，存储表格形式的数据 数据分析框架，不是数据库 通过HiveQL 取数 支持 SQL、Python、Java、R和scala 基于Hadoop 本身不存储数据，可以将数据加载至Spark RDDs 简单来说，Hive是数据仓库，而Spark是个让取数更快的框架。 ","date":"2021-12-27","objectID":"/2021/12/da-hive-vs-spark/:3:0","tags":["Hive","Spark"],"title":"Hive和Spark的区别","uri":"/2021/12/da-hive-vs-spark/"},{"categories":["数据分析"],"content":"最近用 pandas.qcut 分箱遇到了个很奇怪的bug，先Mark一波 在此之前也顺便记录下 pandas.qcut, pandas.Series.value_counts 和 pandas.Series.value_counts 的用法 ","date":"2021-12-16","objectID":"/2021/12/da-pandas-qcut/:0:0","tags":["Python","pandas"],"title":"pandas.qcut及一个很奇怪的bug","uri":"/2021/12/da-pandas-qcut/"},{"categories":["数据分析"],"content":"相关函数 ","date":"2021-12-16","objectID":"/2021/12/da-pandas-qcut/:1:0","tags":["Python","pandas"],"title":"pandas.qcut及一个很奇怪的bug","uri":"/2021/12/da-pandas-qcut/"},{"categories":["数据分析"],"content":"pandas.qcut 基于样本数据排序或分位数分箱 pandas.qcut(x, q, labels=None, retbins=False, precision=3, duplicates='raise') Parameter type comment x 一维 ndarray 或 Series q int or list-like of float 如4，或 [0,0.2,0.8,1] labels array or False, default None 对分箱后的区间重命名，要求和bins等数量 retbins bool, optional 是否返回边界值 precision int, optional 用于调整精度，一般默认 duplicates ‘raise’ or ‘drop’ ‘raise’: 若边界值重复则报错 ‘drop’: 删除重复的 import pandas as pd pd.qcut(range(5), 4) #[(-0.001, 1.0], (-0.001, 1.0], (1.0, 2.0], (2.0, 3.0], (3.0, 4.0]] #Categories (4, interval[float64, right]): [(-0.001, 1.0] \u003c (1.0, 2.0] ... pd.qcut(range(5), 3, labels=[\"good\", \"medium\", \"bad\"]) #[good, good, medium, bad, bad] #Categories (3, object): [good \u003c medium \u003c bad] ","date":"2021-12-16","objectID":"/2021/12/da-pandas-qcut/:1:1","tags":["Python","pandas"],"title":"pandas.qcut及一个很奇怪的bug","uri":"/2021/12/da-pandas-qcut/"},{"categories":["数据分析"],"content":"pandas.Series.value_counts Return a Series containing counts of unique values. 返回的结果默认是根据频数降序排序，且排除 NaN Series.value_counts(normalize=False, sort=True, ascending=False, bins=None, dropna=True) Parameter type comment normalize bool, default False If Ture 则返回频率 sort bool, default True 按照频数排序 ascending bool, default False If True，从小到大排序 bins int, optional 仅适用于数值型数据，分箱计数 dropna bool, default True If False， 包含 NaN \u003e\u003e\u003e pd.Series(range(1,101)).value_counts(bins=4) (75.25, 100.0] 25 (50.5, 75.25] 25 (25.75, 50.5] 25 (0.9, 25.75] 25 dtype: int64 ############################################### \u003e\u003e\u003e pd.Series(range(100)).value_counts(normalize=True,bins=4) (74.25, 99.0] 0.25 (49.5, 74.25] 0.25 (24.75, 49.5] 0.25 (-0.1, 24.75] 0.25 dtype: float64 ","date":"2021-12-16","objectID":"/2021/12/da-pandas-qcut/:1:2","tags":["Python","pandas"],"title":"pandas.qcut及一个很奇怪的bug","uri":"/2021/12/da-pandas-qcut/"},{"categories":["数据分析"],"content":"pandas.Series.unique Return unique values of Series object. Series.unique() \u003e\u003e\u003e pd.Series([3, 1, 2, 3, 4, np.nan]).unique() array([ 3., 1., 2., 4., nan]) ","date":"2021-12-16","objectID":"/2021/12/da-pandas-qcut/:1:3","tags":["Python","pandas"],"title":"pandas.qcut及一个很奇怪的bug","uri":"/2021/12/da-pandas-qcut/"},{"categories":["数据分析"],"content":"那个奇怪的bug Python: 3.6.4|Anaconda, Inc. pandas: 1.1.5 背景是对数据进行等频分箱 pdf['qcut'] = pd.qcut(pdf['prob'],20,duplicates='drop') 之后通过value_counts计数发现有个区间频数为0，且为17个区间 此时，再通过 unique 去重，就只有16个区间，上图中的 (22.0,22.2] 那个区间就没了 根本原因还是数据分布的问题，因为本来是要分20个bin，存在较多边界值重复的情况 ","date":"2021-12-16","objectID":"/2021/12/da-pandas-qcut/:2:0","tags":["Python","pandas"],"title":"pandas.qcut及一个很奇怪的bug","uri":"/2021/12/da-pandas-qcut/"},{"categories":["数据分析"],"content":"解决方案 源码方面的原因暂时不得而知 分箱后得到的数据类型是 Categorical将其转换为 String后再进行后续的分组统计计算 pdf['qcut'] = pdf['qcut'].astype(str) ","date":"2021-12-16","objectID":"/2021/12/da-pandas-qcut/:3:0","tags":["Python","pandas"],"title":"pandas.qcut及一个很奇怪的bug","uri":"/2021/12/da-pandas-qcut/"},{"categories":["数据分析"],"content":"Reference https://pandas.pydata.org/docs/reference/api/pandas.qcut.html https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html https://pandas.pydata.org/docs/reference/api/pandas.Series.unique.html ","date":"2021-12-16","objectID":"/2021/12/da-pandas-qcut/:4:0","tags":["Python","pandas"],"title":"pandas.qcut及一个很奇怪的bug","uri":"/2021/12/da-pandas-qcut/"},{"categories":["生活"],"content":"最近在撸 X战警系列的电影，从故事的时间线维度出发，整理现有影片的观影顺序 ","date":"2021-11-19","objectID":"/2021/11/life-movie-x-men/:0:0","tags":["电影"],"title":"X战警系列观影顺序","uri":"/2021/11/life-movie-x-men/"},{"categories":["生活"],"content":"X-Men: First Class(2011) 时间：1944年 地点：奥斯维辛集中营 人物：万磁王小时候 万磁王（Erik）小时候在奥斯维辛集中营因愤怒等情绪展现出了控制铁制品的超能力，被纳粹Klaus Schmidt盯上了，一顿蹂躏，甚至还当着Erik面枪杀他的母亲 时间到了1962年，也是故事的大背景——古巴导弹危机。之前的纳粹Klaus Schmidt，因为具备吸收能量的超能力，老的没那么快，之后叫 Shaw（Sebastian Shaw） Erik也各种展开复仇。 同时这部X战警也介绍了后续变种人中两大理念的领导者，Professor X（Charles） 和 Erik（“万磁王”）早期的爱恨情仇。以及“魔形女” Raven，Hank 四人之间的你侬我侬。 期间也闪现了Professor X（Charles） 和 Erik（“万磁王”）两人拉 James Howlett（即之后的“金刚狼”）入伙的镜头 Mark 这时候（1962年）越南战争还没结束。 第一战 即是变种人和普通人类之间的第一战，也是Professor X（Charles） 和 Erik（“万磁王”）之间的第一战 ","date":"2021-11-19","objectID":"/2021/11/life-movie-x-men/:1:0","tags":["电影"],"title":"X战警系列观影顺序","uri":"/2021/11/life-movie-x-men/"},{"categories":["生活"],"content":"X-Men Origins: Wolverine (2009) / 金刚狼1 时间：1854年 地点：加拿大 人物：金刚狼小时候 金刚狼（James Howlett）小时候一个不小心干掉了生父（Thomas Logan），之后和他的大兄弟（Victor Creed）狂奔，共同经历了美国内战，第一、二次世界大战，越南战争。 越南战争结束已是 1975 年，这期间已经过了121年，变种人的故事多多少少也会夹杂着同步发生 之后他俩加入了 Stryker 的变种人团队 X 时间来到了 6 年后，那么至少是1981年之后了 感觉后面的矛盾基本都由 Stryker 挑起，金刚狼那钢铁般的爪子也是他给整出来的 这部最后还有些体现时间点的东西： Professor X（Charles） 已经坐上轮椅且头发没了 眼睛喷火的大哥（Scott）还小 Deadpool 没完全GG ","date":"2021-11-19","objectID":"/2021/11/life-movie-x-men/:2:0","tags":["电影"],"title":"X战警系列观影顺序","uri":"/2021/11/life-movie-x-men/"},{"categories":["生活"],"content":"X-Men: Apocalypse | 天启（2016） 时间：1983年 地点：美国俄亥俄州（OHIO） 人物：Scott Scott 的课堂上，老师讲授着，变种人大规模出现在公众视野是在1973年的巴黎和平协约上 balabala 这集主要是讲如何干掉 传说中第一个变种人：En Sabah Nur 在此期间出现的人物，包括但不限于 风暴女（Ororo Moonroe，还没好好跟着 X-Professor） Caliban，收集情报 夜行者 Kurt Wagner Jean Grey 这里最牛逼的当属 Jean（琴），最后干掉那个伪神（En Sabah Nur）时并没有太多笔墨，感觉完全就是两个世界的人，直接降 n 维打击，了结了所谓的Boss。可谓是 Jean 才是大大大Boss啊。 这里有两个点🉑️ 先 「Mark」 Jean 第一次与 金刚狼相遇，并帮他找到了名字 Logan。名字嘛，和“我是谁” 这种哲学性十足的问题简直不是个数量级的 X-Professor 的头发没了。挺难的：“第一站”之后难以直立行走，现在又头秃了，不是以前随意撩妹的帅教授了 最后关于时间点上来看还是有些瑕疵的，比如在“X-Men Origins: Wolverine” 的时候，Scott还是个孩子，那时至少是1981年之后，但这里已经是1983年了 不过本文并不是聚焦于此～ ","date":"2021-11-19","objectID":"/2021/11/life-movie-x-men/:3:0","tags":["电影"],"title":"X战警系列观影顺序","uri":"/2021/11/life-movie-x-men/"},{"categories":["生活"],"content":"X-Men (2000) 电影中似乎未提及具体时间，故事发生在1944年之后，not-too-distant future，但看着人物状态估计离X-Professor头秃的时候也有20年了，即2000年左右 Professor-X 和 万磁王（Erik）都老了，且之前X教授收的几个小弟（琴、暴风女、Scott）都具备一定的单兵作战能力 关于时间线方面，此时金刚狼还没找到当年实验基地的（An abandoned military installation in Canada）的记忆，即 X-Men Origins: Wolverine (2009) 讲述的故事。 ","date":"2021-11-19","objectID":"/2021/11/life-movie-x-men/:4:0","tags":["电影"],"title":"X战警系列观影顺序","uri":"/2021/11/life-movie-x-men/"},{"categories":["生活"],"content":"X-Men 2 (2003) 承接 X-Men(2000) 之后的故事，似乎也没有啥时间点 这里出现了 Stryker，那个给予金刚狼xxx合金爪子的Stryker Stryker想干掉变种人，而 万磁王（Erik） 想干掉人类 😂 不过最后也是互相妥协了吧，也说明白了是有人想挑起战争，搞得两败俱伤。应当求同存异、互利共赢、共创美好未来～ 关于 Stryker 儿子——Jason 的事儿一直也没整明白，和 Professor X 之间的交集也不得而知，不知道是不是哪里漏了 🤷‍♂️ ","date":"2021-11-19","objectID":"/2021/11/life-movie-x-men/:5:0","tags":["电影"],"title":"X战警系列观影顺序","uri":"/2021/11/life-movie-x-men/"},{"categories":["生活"],"content":"X-Men: The Last Stand(2006) 承接 X-Men2 之后的故事，依然没有啥时间点 强大且产生威胁时就要被干掉o.o 人们总是对自己不了解的东西小心翼翼 ","date":"2021-11-19","objectID":"/2021/11/life-movie-x-men/:6:0","tags":["电影"],"title":"X战警系列观影顺序","uri":"/2021/11/life-movie-x-men/"},{"categories":["生活"],"content":"The Wolverine(2013) 1945年8月9日，美国投掷原子弹轰炸日本长崎。金刚狼不仅扛过来了，还救了军官 Ichirō Yashida（未执行尊贵的切腹） 后面的故事就是这个幸存的军官 Ichirō Yashida 想永生而引发的各种故事。 剧中提到 Do not let the lights fool you. These are dark days in Japan. 不知道说的是不是20世纪90年代经济泡沫之后的日本 P.S. 片尾有彩蛋：看样子似乎 Professor-X 和 万磁王（Erik）统一战线了，“一致对外” ","date":"2021-11-19","objectID":"/2021/11/life-movie-x-men/:7:0","tags":["电影"],"title":"X战警系列观影顺序","uri":"/2021/11/life-movie-x-men/"},{"categories":["生活"],"content":"X-Men: Days of Future Past ｜ 逆转未来（2014） RT，逆转未来呐么，回到过去改写历史，玩起了穿越，回到了1973年 剧中时间点是2023年，（本文写作时间点是2021年12月25日），改写历史的任务交给了拥有自愈能力的金刚狼 片尾也出现了琴、Scott～回到了最初的美好 ","date":"2021-11-19","objectID":"/2021/11/life-movie-x-men/:8:0","tags":["电影"],"title":"X战警系列观影顺序","uri":"/2021/11/life-movie-x-men/"},{"categories":["生活"],"content":"Reference https://rddiy.com/chuangyisheji/shijue/ygqje.html ↩︎ ","date":"2021-11-19","objectID":"/2021/11/life-movie-x-men/:9:0","tags":["电影"],"title":"X战警系列观影顺序","uri":"/2021/11/life-movie-x-men/"},{"categories":["数据分析"],"content":"Hi PySpark，初次见面，别来无恙 PySpark is an interface for Apache Spark in Python. It not only allows you to write Spark applications using Python APIs, but also provides the PySpark shell for interactively analyzing your data in a distributed environment. 首先，我是这么来看PySpark的：有一波人会Python但不会Java，那就搞个接口让会Python的小伙伴享受Spark分布式环境带来的快感，更好的分析大数据。 那么对于“面向问题编程”的从业人员来说PySpark的作用就很明显了。当觉得现有的分析工具很慢时可以考虑下PySpark，当然这里是基于Spark环境。换句话说，“快”是分布式环境带来的快感之一。 引入 PySpark 后，分析工作大致流程就变成了这样 👇 其实，整体还是“箱子模型” 📦 ，“喂”数据 =\u003e 处理、计算模块 =\u003e 结果 所以，应用层角度来看 PySpark 也就简单了： 如何读取数据？ 如何处理、计算得到自己想要的结果，即“面向问题编程” 如何处理结果？要保存到哪儿？ ","date":"2021-11-10","objectID":"/2021/11/da-pyspark-beginning/:0:0","tags":["PySpark"],"title":"PySpark之应用层小白视角","uri":"/2021/11/da-pyspark-beginning/"},{"categories":["数据分析"],"content":"如何读取数据 这个往往取决于数据在哪儿，譬如有些数据是以csv格式保存，有些是在数据库… 总之都是为了 Loading data onto Spark RDDs，享受分布式的快感 实际操作可以基于具体情况在网上检索相应的解决方案，如 pyspark read hive table # A example from https://spark.apache.org/docs/latest/sql-data-sources-hive-tables.html from os.path import abspath from pyspark.sql import SparkSession from pyspark.sql import Row # warehouse_location points to the default location for managed databases and tables warehouse_location = abspath('spark-warehouse') spark = SparkSession \\ .builder \\ .appName(\"Python Spark SQL Hive integration example\") \\ .config(\"spark.sql.warehouse.dir\", warehouse_location) \\ .enableHiveSupport() \\ .getOrCreate() # spark is an existing SparkSession spark.sql(\"CREATE TABLE IF NOT EXISTS src (key INT, value STRING) USING hive\") spark.sql(\"LOAD DATA LOCAL INPATH 'examples/src/main/resources/kv1.txt' INTO TABLE src\") # The results of SQL queries are themselves DataFrames and support all normal functions. sqlDF = spark.sql(\"SELECT key, value FROM src WHERE key \u003c 10 ORDER BY key\") # # Licensed to the Apache Software Foundation (ASF) under one or more # contributor license agreements. See the NOTICE file distributed with # this work for additional information regarding copyright ownership. # The ASF licenses this file to You under the Apache License, Version 2.0 # (the \"License\"); you may not use this file except in compliance with # the License. You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # \"\"\" An interactive shell. This file is designed to be launched as a PYTHONSTARTUP script. \"\"\" import atexit import os import platform import warnings import py4j from pyspark import SparkConf from pyspark.context import SparkContext from pyspark.sql import SparkSession, SQLContext if os.environ.get(\"SPARK_EXECUTOR_URI\"): SparkContext.setSystemProperty(\"spark.executor.uri\", os.environ[\"SPARK_EXECUTOR_URI\"]) SparkContext._ensure_initialized() try: # Try to access HiveConf, it will raise exception if Hive is not added conf = SparkConf() if conf.get('spark.sql.catalogImplementation', 'hive').lower() == 'hive': SparkContext._jvm.org.apache.hadoop.hive.conf.HiveConf() spark = SparkSession.builder\\ .enableHiveSupport()\\ .getOrCreate() else: spark = SparkSession.builder.getOrCreate() except py4j.protocol.Py4JError: if conf.get('spark.sql.catalogImplementation', '').lower() == 'hive': warnings.warn(\"Fall back to non-hive support because failing to access HiveConf, \" \"please make sure you build spark with hive\") spark = SparkSession.builder.getOrCreate() except TypeError: if conf.get('spark.sql.catalogImplementation', '').lower() == 'hive': warnings.warn(\"Fall back to non-hive support because failing to access HiveConf, \" \"please make sure you build spark with hive\") spark = SparkSession.builder.getOrCreate() sc = spark.sparkContext sql = spark.sql atexit.register(lambda: sc.stop()) # for compatibility sqlContext = spark._wrapped sqlCtx = sqlContext print(\"\"\"Welcome to ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /__ / .__/\\_,_/_/ /_/\\_\\ version %s /_/ \"\"\" % sc.version) print(\"Using Python version %s (%s, %s)\" % ( platform.python_version(), platform.python_build()[0], platform.python_build()[1])) print(\"SparkSession available as 'spark'.\") # The ./bin/pyspark script stores the old PYTHONSTARTUP value in OLD_PYTHONSTARTUP, # which allows us to execute the user's PYTHONSTARTUP file: _pythonstartup = os.environ.get('OLD_PYTHONSTARTUP') if _pythonstartup and os.path.isfile(_pythonstartup): with open(_pythonstartup) as f: code = compile(f.read(), _pythonstartup, 'exec') exec(code) ","date":"2021-11-10","objectID":"/2021/11/da-pyspark-beginning/:1:0","tags":["PySpark"],"title":"PySpark之应用层小白视角","uri":"/2021/11/da-pyspark-beginning/"},{"categories":["数据分析"],"content":"数据处理、计算 读取数据得到 Spark DataFrame 后，可以直接对此进行操作，除了常见的业务分析还有机器学习模块（MLlib） raw_data = sc.textFile(\"./kddcup.data.gz\") ## Comma-Separated Value csv = raw_data.map(lambda x: x.split(\",\")) metrics = csv.map(lambda x: [x[0], x[4], x[5]]) from pyspark.mllib.stat import Statistics Statistics.corr(metrics, method=\"spearman\") Statistics.corr(metrics, method=\"pearson\") 值得一提的是，Spark DataFrame to pandas DataFrame 可以用 toPandas() 方法，同时参数方面设置 spark.sql.execution.arrow.enabled=true 能提高效率 # A example from https://docs.microsoft.com/en-us/azure/databricks/spark/latest/spark-sql/spark-pandas import numpy as np import pandas as pd # Enable Arrow-based columnar data transfers spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\") # Generate a pandas DataFrame pdf = pd.DataFrame(np.random.rand(100, 3)) # Create a Spark DataFrame from a pandas DataFrame using Arrow df = spark.createDataFrame(pdf) # Convert the Spark DataFrame back to a pandas DataFrame using Arrow result_pdf = df.select(\"*\").toPandas() 这部分再Mark一个关于 collect() 的小点，总之数据量比较大的时候就不要用这个方法。 The collect() function returns a list that contains all the elements in this RDD, and should only be used if the resulting array is expected to be ==small==, as all the data is loaded in a driver’s memory, in which case we lose the benefits of distributing the data around a cluster of Spark instances. ","date":"2021-11-10","objectID":"/2021/11/da-pyspark-beginning/:2:0","tags":["PySpark"],"title":"PySpark之应用层小白视角","uri":"/2021/11/da-pyspark-beginning/"},{"categories":["数据分析"],"content":"如何处理结果 处理、计算后的结果往往会再一次的落库，这个时候同 “数据读取” 的部分，🉑️ 根据具体情况进行检索。 以落到 hive 表为例，截止到目前整理的，大致有两种方法。 首先确保数据为 Spark DataFrame 状态（可以通过 spark.createDataFrame(df) 的方法将 pandas DataFrame 转为 Spark DataFrame） spark_df.write.mode(\"overwrite\").format(\"hive\").saveAsTable(\"dbName.tableName\") # 注意是 overwrite 或者 spark_df.createOrReplaceTempView(\"myTempTableName\") spark.sql(\"drop table if exists dbName.tableName\") spark.sql(\"create table dbName.tableName as select * from myTempTableName\") ","date":"2021-11-10","objectID":"/2021/11/da-pyspark-beginning/:3:0","tags":["PySpark"],"title":"PySpark之应用层小白视角","uri":"/2021/11/da-pyspark-beginning/"},{"categories":["数据分析"],"content":"总结 最近工作中遇到了 PySpark 的使用，在此从应用层小白视角通过 📦 “箱子模型”（Input =\u003e Box =\u003e Output） 简单记录大致的使用流程，方便于新手～ ","date":"2021-11-10","objectID":"/2021/11/da-pyspark-beginning/:4:0","tags":["PySpark"],"title":"PySpark之应用层小白视角","uri":"/2021/11/da-pyspark-beginning/"},{"categories":["数据分析"],"content":"Reference 360数科深圳数据组 Rudy Lai and Bartłomiej Potaczek.《Hands On Big Data Analytics With PySpark》 https://docs.microsoft.com/en-us/azure/databricks/spark/latest/spark-sql/spark-pandas http://spark.apache.org/docs/latest/api/python/index.html https://spark.apache.org/docs/latest/sql-data-sources-hive-tables.html https://stackoverflow.com/questions/30664008/how-to-save-dataframe-directly-to-hive https://bitbucket.org/cli14020/spark-cache/src/master/python/pyspark/shell.py ","date":"2021-11-10","objectID":"/2021/11/da-pyspark-beginning/:5:0","tags":["PySpark"],"title":"PySpark之应用层小白视角","uri":"/2021/11/da-pyspark-beginning/"},{"categories":["数据分析"],"content":"汇总一些【因果推断】方面的学习资料 最近看了下《原因与结果的经济学》并且结合硕士期间关于相关性与因果的思考，感觉这个 因果推断（causal inference）似乎挺有意思的。 基于数据分析的特性，我把目前因果推断方面的研究分为四大类 -- 聚焦某领域 未聚焦 理论 基于某领域的理论研究（如心理学因果关系的研究方法） 纯理论研究（这种常见于“扛把子”引领一个方向） 应用 基于某领域的应用研究（如业界的一些策略评估） 类似咨询 常见（或高产）的应该是“基于某领域的理论研究” 和 “基于某领域的应用研究”，至于第四种（“未聚焦领域的应用型研究”）因为商业性的问题应该较难找到公开案例。 后续也打算站在小白/门外汉的角度深入了解下，记录下遇到的学习资料。（持续更新…） ","date":"2021-10-09","objectID":"/2021/10/causal-resources/:0:0","tags":["因果推断"],"title":"因果推断补给站","uri":"/2021/10/causal-resources/"},{"categories":["数据分析"],"content":"网文 ","date":"2021-10-09","objectID":"/2021/10/causal-resources/:1:0","tags":["因果推断"],"title":"因果推断补给站","uri":"/2021/10/causal-resources/"},{"categories":["数据分析"],"content":"博客 Emre Kiciman @Microsoft Amit Sharma @Microsoft 二位似乎一起搞了个网站：Getting Started with Causal Inference，里面有正在写的书：Causal Reasoning: Fundamentals and Machine Learning Applications 以及一些课程之类的 Yishi Li @Tencent 统计之都 Brady Neal，有篇从需求出发选择读物的文章 ","date":"2021-10-09","objectID":"/2021/10/causal-resources/:1:1","tags":["因果推断"],"title":"因果推断补给站","uri":"/2021/10/causal-resources/"},{"categories":["数据分析"],"content":"知乎 因果推断会是下一个AI热潮吗？ ","date":"2021-10-09","objectID":"/2021/10/causal-resources/:1:2","tags":["因果推断"],"title":"因果推断补给站","uri":"/2021/10/causal-resources/"},{"categories":["数据分析"],"content":"Github amit-sharma / causal-inference-tutorial Paper_CausalInference_abtest ","date":"2021-10-09","objectID":"/2021/10/causal-resources/:1:3","tags":["因果推断"],"title":"因果推断补给站","uri":"/2021/10/causal-resources/"},{"categories":["数据分析"],"content":"书籍 《原因与结果的经济学》 《别拿相关当因果！因果关系简易入门》（Why: A Guide to Finding and Using Causes） JUDEA PEARL. 《为什么》（THE BOOK OF WHY: THE NEW SCIENCE OF CAUSE AND EFFECT） JUDEA PEARL. Causality: Models, Reasoning, and Inference JUDEA PEARL. Causal Inference in Statistics: A Primer Donald B. Rubin. Causal Inference for Statistics, Social, and Biomedical Sciences: An Introduction Brady Neal. Introduction to Causal Inference Hernán MA, Robins JM. Causal Inference: What If，以及书中对应的Python-code ","date":"2021-10-09","objectID":"/2021/10/causal-resources/:2:0","tags":["因果推断"],"title":"因果推断补给站","uri":"/2021/10/causal-resources/"},{"categories":["数据分析"],"content":"工具包 Uber-Causal ML: A Python package that provides a suite of uplift modeling and causal inference methods using machine learning. Microsoft-EconML: A Python package for estimating heterogeneous treatment effects from observational data via machine learning. Microsoft-DoWhy: A Python library that aims to spark causal thinking and analysis. CausalDiscoveryToolbox: A package for causal inference in graphs and in the pairwise settings ","date":"2021-10-09","objectID":"/2021/10/causal-resources/:3:0","tags":["因果推断"],"title":"因果推断补给站","uri":"/2021/10/causal-resources/"},{"categories":["FEM","读书笔记"],"content":"为什么要讲究因果？因为只有因果才能决定未来 可能在相关性盛行的大数据时代，因果关系也成为了一种稀缺 但科学研究一直提倡的是因果🤔 可以从数据中的规律出发，找寻因果关系（相关性 $\\Rightarrow$ 因果） 与此同时，经济学中还有个流派——从公理出发，经过一顿操作（逻辑推演），得到相应的结论。 或许这是“研究范式”的不同吧。按照邓小平爷爷的“猫论”，研究成果能造福人类就好。 本文是《原因与结果的经济学》的读书笔记，全书主要分为两大部分：1是提出因果推理并强调“反事实”是其必经之路；2是例举一些构建“反事实”的方式方法 ","date":"2021-10-05","objectID":"/2021/10/notes-%E5%8E%9F%E5%9B%A0%E4%B8%8E%E7%BB%93%E6%9E%9C%E7%9A%84%E7%BB%8F%E6%B5%8E%E5%AD%A6/:0:0","tags":["因果推断"],"title":"相关性能预测未来，但只有因果能决定未来","uri":"/2021/10/notes-%E5%8E%9F%E5%9B%A0%E4%B8%8E%E7%BB%93%E6%9E%9C%E7%9A%84%E7%BB%8F%E6%B5%8E%E5%AD%A6/"},{"categories":["FEM","读书笔记"],"content":"因果推理 两个变量的关系是否真的是因果关系？解答这个问题所需的思维方法便是“因果推理”。 而判断因果关系有三个要点： 是否“纯属巧合”； 是否存在“第三变量” 是否存在“逆向因果关系” 两个变量之间为因果关系时才能画如上图中的实线指向箭头，原因指向结果 而推翻以上三点的方法便是 对现实和“反事实”进行对比 反事实是指对过去未曾发生的事实所做的假设，例如“如果当时没有……，那么……”。我们将现实中实际发生的事称为“事实”，所以将设想的与现实完全相反的情况称为“反事实”。 这方面比较好操作的便是自然科学领域的各种实验了，比如这根试管加 xxx，另一根试管不加 xxx，观察两者之间的差异，验证假设之类的 但到了人文社科领域，要想像自然科学领域做实验，可谓是 “噫！吁嚱…” 所以作为因果科普文的《原因与结果的经济学》所介绍的方法也是有很多被challenge的地方。 后面的章节便是按照“证据等级”排序介绍了相应构建“反事实”的方法，与事实进行对比，进而判断因果关系 ","date":"2021-10-05","objectID":"/2021/10/notes-%E5%8E%9F%E5%9B%A0%E4%B8%8E%E7%BB%93%E6%9E%9C%E7%9A%84%E7%BB%8F%E6%B5%8E%E5%AD%A6/:1:0","tags":["因果推断"],"title":"相关性能预测未来，但只有因果能决定未来","uri":"/2021/10/notes-%E5%8E%9F%E5%9B%A0%E4%B8%8E%E7%BB%93%E6%9E%9C%E7%9A%84%E7%BB%8F%E6%B5%8E%E5%AD%A6/"},{"categories":["FEM","读书笔记"],"content":"如何构建“反事实” 说到这个不禁想起硕士导师和我说过的话，只有实验才能得因果关系 至于构造“反事实”的方式方法，书中也简单罗列了几点 但不得不说，人文社科领域要想完全的像自然科学的实验那样严谨是比较难的，毕竟有时候个体之间也很难保持独立，即互相之间是会有影响的。 所以呢，CB（consumer behavior）以及心理学相关领域在评判学术文章时，除了idea 之外，还会看实验设计的是否巧妙。 此时针对此次实验研究（问卷形式）收集的数据便是“一手数据”，而非此次实验研究目的收集的那种便是“二手数据”。比如研究涉及电商评论，现有电商平台的评论数据对于我们的研究而言便是二手数据。 后续采取相应的分析方法常见有两种：一种是基于线性回归的 Conditional Process Analysis；另一种就是结构方程。可根据数据形式灵活采取相应的方法。 ","date":"2021-10-05","objectID":"/2021/10/notes-%E5%8E%9F%E5%9B%A0%E4%B8%8E%E7%BB%93%E6%9E%9C%E7%9A%84%E7%BB%8F%E6%B5%8E%E5%AD%A6/:2:0","tags":["因果推断"],"title":"相关性能预测未来，但只有因果能决定未来","uri":"/2021/10/notes-%E5%8E%9F%E5%9B%A0%E4%B8%8E%E7%BB%93%E6%9E%9C%E7%9A%84%E7%BB%8F%E6%B5%8E%E5%AD%A6/"},{"categories":["FEM","读书笔记"],"content":"业界的增益 20世纪末美国陆陆续续将统计模型引入信贷领域风控业务1，贯彻“数据驱动”的理念，一直沿袭至今。从早些年基于 logistics回归的评分卡到现在的“GBDT”树类模型，但均未涉及因果。 在目前中国政府进一步压缩借贷利率上限的背景下，对风控业务而言便需要更加精细化的管理，在基于相关性搜寻风控策略的基础上进一步探究产生信用风险的因果关系，在总用户被压缩的情况下，在风险可承受范围内，进一步提高“进水口处”的“进水量”（/批核率/通过率）。 所以，在工具方面，是不是可以尝试或探究下“因果推断” 🤔 ","date":"2021-10-05","objectID":"/2021/10/notes-%E5%8E%9F%E5%9B%A0%E4%B8%8E%E7%BB%93%E6%9E%9C%E7%9A%84%E7%BB%8F%E6%B5%8E%E5%AD%A6/:3:0","tags":["因果推断"],"title":"相关性能预测未来，但只有因果能决定未来","uri":"/2021/10/notes-%E5%8E%9F%E5%9B%A0%E4%B8%8E%E7%BB%93%E6%9E%9C%E7%9A%84%E7%BB%8F%E6%B5%8E%E5%AD%A6/"},{"categories":["FEM","读书笔记"],"content":"Reference http://www.sinotf.com/GB/consumerfinance/2018-01-16/0MMDAwMDI5OTc0Mw.html ↩︎ ","date":"2021-10-05","objectID":"/2021/10/notes-%E5%8E%9F%E5%9B%A0%E4%B8%8E%E7%BB%93%E6%9E%9C%E7%9A%84%E7%BB%8F%E6%B5%8E%E5%AD%A6/:4:0","tags":["因果推断"],"title":"相关性能预测未来，但只有因果能决定未来","uri":"/2021/10/notes-%E5%8E%9F%E5%9B%A0%E4%B8%8E%E7%BB%93%E6%9E%9C%E7%9A%84%E7%BB%8F%E6%B5%8E%E5%AD%A6/"},{"categories":["FEM"],"content":"一些观念被人们相信，是因为它们本身就是可被明证的事实；而另一些观念被人们相信，只是因为人们被这些观念反复的“洗脑”了而已。 最终，洗脑代替了证据，让人们普遍接受了这些“事实”。 当许多广为认知的观念接受事实与逻辑的检验，你会发现有的观念像纸牌屋一样不堪一击；有的观念看似真理，却只是一些思维谬误的产物。 经济政策中的谬误层出不穷，而且影响着社会的方方面面。小到住房，大到国际贸易，都是如此。 这些政策造成的灾难性后果往往要在好几年后才显现，但很少有人会对这些灾难的起因追根朔源。 即便一个政策出台后马上引发不良反应，很多人也不会去追究政策本身的缺陷，政策的倡导者还常常把这些不良后果嫁祸出去。他们甚至会辩解说如果没有他们推行的这套好政策，情况会更糟。（批注：因果反事实真的很难） 即使事实摆在眼前，谬误还是大行其道，其中的缘由各不相同。比如，政客为了避免影响自己的政治生涯，学者为了避免声望受损，扶贫活动的公益领袖为了避免内心的痛苦失落…… 没有人乐于承认自己的错误。 但在很多情况下，掩盖错误的代价是高昂的。这些代价让人们向现实低头，不管他们多么不愿意或多么痛苦。如果一个学生这次数学考试错了一道题，那下次考试之前他就必须把这道题解对；一家企业不会因为贯彻错误方针而任由企业不断亏损却不纠正。 简而言之，无论是出于实际需求还是理智，我们都有必要对谬误追根究底。 政府出台好的和错的经济政策都会影响无数人的生活，都会直接导致人们生活的更好或更差。这就是经济学研究为什么那么重要，而对谬误的研究不仅是单纯的学术行为。 经济谬误实在太多，无法一一列出。但我们可以概括出五大类常见的经济谬误进行分析： ","date":"2021-09-30","objectID":"/2021/09/fem-%E5%B8%B8%E8%A7%81%E7%9A%84%E4%BA%94%E5%A4%A7%E7%BB%8F%E6%B5%8E%E8%B0%AC%E8%AF%AF/:0:0","tags":["经济学","奥派"],"title":"索维尔：最常见的五大经济谬误","uri":"/2021/09/fem-%E5%B8%B8%E8%A7%81%E7%9A%84%E4%BA%94%E5%A4%A7%E7%BB%8F%E6%B5%8E%E8%B0%AC%E8%AF%AF/"},{"categories":["FEM"],"content":"1.零和式谬误 许多经济谬误都建立在一个错误的假设上，即交易是零和博弈，一方所得意味着另一方所失。 但是，如果不能让双方获利，交易就不会发生。这样浅显的道理，对于许多政策倡导者来说，不一定真的明白。 比如说，房租管制、最低工资，都是试图通过外部力量增加交易一方获得的收益。但是，当另一方无利可图或利益微薄时，交易就不再发生。 地产商不再建房，房东不再精心修缮房屋，导致更多的人租不到房子；老板不再雇佣新人，或者干脆将工厂搬到国外，导致本国人更多失业。 当你把交易误解成零和博弈，试图通过暴力强制交易一方减少收益，结果只会是交易量的减少。 零和博弈这种思维谬误造成的最坏的结果是：贫穷国家以为外来资本在剥削他们，为了避免被剥削，他们排斥和抵制外来资本。这种观念曾经被全世界广泛接受，造成的结果就是数千万人数代间都深陷贫困的泥沼。 许多国家后来纷纷抛弃了这种谬误，积极的拥抱资本和开展国际贸易。但在抛弃这种谬误之前的岁月里，无数人只能做无谓的牺牲，为一个没有事实根据的假设付出了巨大的代价。 可见，思维谬误造成的影响是极大的。 ","date":"2021-09-30","objectID":"/2021/09/fem-%E5%B8%B8%E8%A7%81%E7%9A%84%E4%BA%94%E5%A4%A7%E7%BB%8F%E6%B5%8E%E8%B0%AC%E8%AF%AF/:1:0","tags":["经济学","奥派"],"title":"索维尔：最常见的五大经济谬误","uri":"/2021/09/fem-%E5%B8%B8%E8%A7%81%E7%9A%84%E4%BA%94%E5%A4%A7%E7%BB%8F%E6%B5%8E%E8%B0%AC%E8%AF%AF/"},{"categories":["FEM"],"content":"2.组合式谬误 逻辑学家所说的“组合式”谬误是指部分正确即整体正确的观念。 一个棒球球迷在观众席上站起来看球场上的比赛可以看得清清楚楚，但如果所有球迷都站起来看，那最后的结果就是大家都看不好。许多经济政策都涉及组合式谬误。比如政治家们为某些特定群体、行业、利益集团代言，他们采取的政策看似造富全社会，其实不过是拆东墙补西墙的把戏。 例如，很多地方政府为了消灭贫民窟，“振兴社区”，大搞拆毁和重建，把贫民窟变成高档住宅和购物中心。人们总认为这些政府支出创造了就业、繁荣了经济，其实，不过是把纳税人的钱转移到了政府那里，导致纳税人无法用这些钱来消费和投资。政府宣称他们用繁荣社区取代了贫民窟，其实，那些贫民只不过是迁徙到了其他地方，去了其他的贫民窟。 ","date":"2021-09-30","objectID":"/2021/09/fem-%E5%B8%B8%E8%A7%81%E7%9A%84%E4%BA%94%E5%A4%A7%E7%BB%8F%E6%B5%8E%E8%B0%AC%E8%AF%AF/:2:0","tags":["经济学","奥派"],"title":"索维尔：最常见的五大经济谬误","uri":"/2021/09/fem-%E5%B8%B8%E8%A7%81%E7%9A%84%E4%BA%94%E5%A4%A7%E7%BB%8F%E6%B5%8E%E8%B0%AC%E8%AF%AF/"},{"categories":["FEM"],"content":"3.事后归因式谬误 事后归因式谬误不但最普遍，历史也最悠久。即对于两件相继发生的重大事件，人们会把第一件事当成第二件事的起因。 例如 1929 年股市崩盘之后，紧接着爆发了大萧条。所以一直以来人们都认为是股票市场的崩溃导致了整个经济的崩溃。然而，1987 年的股市崩盘，却迎来了持续 20 年的经济增长。 再例如世界上许多地方都开展过禁用 DDT 的运动。DDT 可以消灭传播疟疾的蚊虫，杀虫效果显著。但是使用 DDT 越多的地方，癌症发病率越高。以至于人们控诉 DDT 引发癌症，但这并非事实。禁止 DDT 让疟疾死灰复燃，夺走了全球上百万人的生命。 事后归因式谬误不仅仅是一个智力问题。人们总想着为好事邀功，把坏事归罪于人，这就是为什么会有那么多事后归因式谬误了。 ","date":"2021-09-30","objectID":"/2021/09/fem-%E5%B8%B8%E8%A7%81%E7%9A%84%E4%BA%94%E5%A4%A7%E7%BB%8F%E6%B5%8E%E8%B0%AC%E8%AF%AF/:3:0","tags":["经济学","奥派"],"title":"索维尔：最常见的五大经济谬误","uri":"/2021/09/fem-%E5%B8%B8%E8%A7%81%E7%9A%84%E4%BA%94%E5%A4%A7%E7%BB%8F%E6%B5%8E%E8%B0%AC%E8%AF%AF/"},{"categories":["FEM"],"content":"4.棋式谬误 在亚当·斯密的笔下，“教条理论家”是指自视甚高，认为“可以像摆弄棋盘上的棋子那样轻松驾驭一个国家”的一类人。这样的理论家仍然普遍存在，而且他们还影响着法律和政策的制定。 人类与棋子不同。他们有自己的喜好、价值观、计划和意愿。所有这些都可能会与“社会实验”的宏伟目标发生冲突。因为人不是棋子，不是任由摆布。 任何试图让人去机械的扮演某个宏伟计划的一部分的尝试都注定会失败，就像历史已经反复证明的那样。 很多教条理论家们并不死心，他们那种“如果一开始没有成功，那就多试几次”的想法是酿成更多灾祸的一味配方。 ","date":"2021-09-30","objectID":"/2021/09/fem-%E5%B8%B8%E8%A7%81%E7%9A%84%E4%BA%94%E5%A4%A7%E7%BB%8F%E6%B5%8E%E8%B0%AC%E8%AF%AF/:4:0","tags":["经济学","奥派"],"title":"索维尔：最常见的五大经济谬误","uri":"/2021/09/fem-%E5%B8%B8%E8%A7%81%E7%9A%84%E4%BA%94%E5%A4%A7%E7%BB%8F%E6%B5%8E%E8%B0%AC%E8%AF%AF/"},{"categories":["FEM"],"content":"5.开放式谬误 许多理想都忽略了一个最基本的经济事实：资源是稀缺的，而且有多种用途。 谁会反对安全、健康、保护环境呢？但是人们对这些的追求是无限的，政策的推动者也会促使人们进行无限制的追求。 大多人会乐意政府投资亿万美元用于癌症研究，但是同样的钱也可以用于许多其他疾病的研究。在倡导预防犯罪、更好的健康、更清洁的空气和水等理念时，人们确实遗漏了权衡取舍的概念，在政治正确下，我们的要求变得没有节制。 开放式没有上限的要求增加了财政预算，为权力扩张提供了便利，也助长了庞大的政府官僚机构。 法官在执行反垄断法时也经常陷入“开放式谬误”，即担忧某个企业正处于垄断“初期”。美国最高法院对布朗鞋业公司并购案的判决就是一个里程碑事件。法院禁止布朗鞋业收购肯尼连锁鞋店，因为后者占美国 1% 的鞋类市场，如果被收购，布朗鞋业有可能逐渐形成行业垄断，所以必须将这种垄断风险扼杀在摇篮中。 假设无限制的推断理论是正确的，那按照这种推理逻辑，如果黎明开始温度上升了 10 度，就意味着月底之前我们都会被高温烤成脆脆酥。 ","date":"2021-09-30","objectID":"/2021/09/fem-%E5%B8%B8%E8%A7%81%E7%9A%84%E4%BA%94%E5%A4%A7%E7%BB%8F%E6%B5%8E%E8%B0%AC%E8%AF%AF/:5:0","tags":["经济学","奥派"],"title":"索维尔：最常见的五大经济谬误","uri":"/2021/09/fem-%E5%B8%B8%E8%A7%81%E7%9A%84%E4%BA%94%E5%A4%A7%E7%BB%8F%E6%B5%8E%E8%B0%AC%E8%AF%AF/"},{"categories":["FEM"],"content":"总结：经济学的正确思考 许多信条其实经不起推敲，但是如果没有人真正去审视它们，它们就会一直延续下去，尤其是当精明的倡导者通过利用人们的情感诉求来规避理性检验的时候。 一些普遍的谬误已经有上百年的历史了，它们在几个世纪前就已经被驳斥过，但是到了今天却能新瓶装旧酒，重新粉饰以新的形式适应当下的时代潮流。 基于这些谬误制定的经济政策常常会危害世界各国千百万人民的福祉，甚至一再造成毁灭性的后果。洞察这些谬误远不止磨砺心智这么简单，更清晰的去理解经济学，还可以为提升世界人民的生活水平，带来许多意想不到的机会。 从这儿转载 ","date":"2021-09-30","objectID":"/2021/09/fem-%E5%B8%B8%E8%A7%81%E7%9A%84%E4%BA%94%E5%A4%A7%E7%BB%8F%E6%B5%8E%E8%B0%AC%E8%AF%AF/:6:0","tags":["经济学","奥派"],"title":"索维尔：最常见的五大经济谬误","uri":"/2021/09/fem-%E5%B8%B8%E8%A7%81%E7%9A%84%E4%BA%94%E5%A4%A7%E7%BB%8F%E6%B5%8E%E8%B0%AC%E8%AF%AF/"},{"categories":["FEM"],"content":"常见的还款方式：等额本息、等额本金、等本等息 一个一个来盘 ","date":"2021-09-13","objectID":"/2021/09/fem-%E8%BF%98%E6%AC%BE%E6%96%B9%E5%BC%8F/:0:0","tags":["金融"],"title":"还款方式：等额本息-等额本金-等本等息","uri":"/2021/09/fem-%E8%BF%98%E6%AC%BE%E6%96%B9%E5%BC%8F/"},{"categories":["FEM"],"content":"等额本息 ","date":"2021-09-13","objectID":"/2021/09/fem-%E8%BF%98%E6%AC%BE%E6%96%B9%E5%BC%8F/:1:0","tags":["金融"],"title":"还款方式：等额本息-等额本金-等本等息","uri":"/2021/09/fem-%E8%BF%98%E6%AC%BE%E6%96%B9%E5%BC%8F/"},{"categories":["FEM"],"content":"基本信息 等额本息还款法，也称定期付息。借款人每月按相等的金额偿还贷款本息，其中每月贷款利息按月初剩余贷款本金计算并逐月结清。（MBA智库百科） 每期还的钱是固定的，即每期 本金+利息 总额是固定的。但每期还的钱中 本金、利息 的占比是动态的 👇 上图中基本信息，假设 借款总额：300w 借款年限：30 年利率：5% ","date":"2021-09-13","objectID":"/2021/09/fem-%E8%BF%98%E6%AC%BE%E6%96%B9%E5%BC%8F/:1:1","tags":["金融"],"title":"还款方式：等额本息-等额本金-等本等息","uri":"/2021/09/fem-%E8%BF%98%E6%AC%BE%E6%96%B9%E5%BC%8F/"},{"categories":["FEM"],"content":"具体公式 假设借款总额 $p$ 元，分了 $n$ 期，每期的利率是 $r$，那么 每期应还款 $$ 每期应还款=\\frac{p \\times r \\times (1+r)^n}{(1+r)^n-1} $$ 第 i 期还款中本金部分 $$ 第i期还款中本金部分=p \\times r \\times \\frac{(1+r)^{(i-1)}}{(1+r)^n-1} $$ 第 i 期还款中利息部分 $$ 第i期还款中利息部分=\\frac{p \\times r}{(1+r)^n-1} \\times ((1+r)^n-(1+r)^{(i-1)}) $$ import pandas as pd class MRPI: ''' 等额本息 - 多种翻译 Matching the Repayment of Principal and interest / Fixed installment method / average capital plus interest method 计算 - 每月还款 - 本金、利息部分 - generate DataFrame ''' def __init__(self, p,R,N): ''' p: 贷款总额 R: 年化利率 N: 贷款年限 ''' self.p = p self.R = R self.N = N self.n = N * 12 self.r = R / 12 def pay_amt(self): ''' 每期总额（月供） ''' term_total = ( self.p * self.r * (1 + self.r)**self.n ) \\ / ( (1 + self.r)**self.n - 1 ) return round(term_total,2) def pay_part(self): ''' 月供中 利息，本金 部分 ''' interest,principal = [],[] for i in range(self.n): # 利息 term_interest = self.p * self.r * ( (1+self.r)**self.n - (1+self.r)**i ) \\ / ((1+self.r)**self.n-1) term_interest = round(term_interest,2) interest.append(term_interest) # 本金 term_principal = ( self.p * self.r * ( 1 + self.r )**i ) \\ / ( (1 + self.r)**self.n - 1 ) term_principal = round(term_principal,2) principal.append(term_principal) return interest,principal def get_detail(self): ''' convert to DataFrame ''' df_detail = pd.DataFrame({\"term\":[i for i in range(1,self.n + 1)] ,\"月还款\":[self.pay_amt()]*self.n ,\"本金部分\":self.pay_part()[1] ,\"利息部分\":self.pay_part()[0] }) df_total = pd.DataFrame({\"term\":[\"总计\"] ,\"月还款\":[self.pay_amt()*self.n] ,\"本金部分\":[self.p] ,\"利息部分\":[self.pay_amt()*self.n - self.p] }) df = df_detail.append(df_total) return df_detail,df.reset_index(drop=True) ","date":"2021-09-13","objectID":"/2021/09/fem-%E8%BF%98%E6%AC%BE%E6%96%B9%E5%BC%8F/:1:2","tags":["金融"],"title":"还款方式：等额本息-等额本金-等本等息","uri":"/2021/09/fem-%E8%BF%98%E6%AC%BE%E6%96%B9%E5%BC%8F/"},{"categories":["FEM"],"content":"等额本金 等额本金还款法，也称利随本清、等本不等息还款法。借款人将本金分摊到每期，同时付清上一个交易日至本次还款日之间的利息。（MBA智库百科） 每期还的本金是固定的，随着剩余本金的减少，利息便也动态减少 👇 但前期还款总额较多 上图中基本信息，假设 借款总额：300w 借款年限：30 年利率：5% ","date":"2021-09-13","objectID":"/2021/09/fem-%E8%BF%98%E6%AC%BE%E6%96%B9%E5%BC%8F/:2:0","tags":["金融"],"title":"还款方式：等额本息-等额本金-等本等息","uri":"/2021/09/fem-%E8%BF%98%E6%AC%BE%E6%96%B9%E5%BC%8F/"},{"categories":["FEM"],"content":"具体公式 第 i 期应还款 $$ 第i期应还款=\\frac{p}{n} + (1- \\frac{i-1}{n}) \\times p \\times r $$ 第 i 期还款中本金部分 $$ 第i期还款中本金部分=\\frac{p}{n} $$ 第 i 期还款中利息部分 $$ 第i期还款中利息部分=(1- \\frac{i-1}{n}) \\times p \\times r $$ import pandas as pd class MPR: ''' 等额本金 - 多种翻译 Matching the Principal Repayment / Reducing installment method (Fixed Principal) / average capital method 计算 - 每月还款 - 本金、利息部分 - generate DataFrame ''' def __init__(self, p,R,N): ''' p: 贷款总额 R: 年化利率 N: 贷款年限 ''' self.p = p self.R = R self.N = N self.n = N * 12 self.r = R / 12 def pay_part(self): ''' 本金，每期总额（月供） 以及 利息部分 ''' # 本金 term_principal = self.p / self.n amt,interest = [],[] for i in range(self.n): # 每期利息 term_interest = ( 1 - i/self.n ) * self.p * self.r # 每期还款 term_amt = term_principal + term_interest term_amt = round(term_amt,2) amt.append(term_amt) term_interest = round(term_interest,2) interest.append(term_interest) return round(term_principal,2),amt,interest def get_detail(self): ''' convert to DataFrame ''' df_detail = pd.DataFrame({\"term\":[i for i in range(1,self.n + 1)] ,\"月还款\":self.pay_part()[1] ,\"本金部分\":[self.pay_part()[0]]* self.n ,\"利息部分\":self.pay_part()[2] }) df_total = pd.DataFrame({\"term\":[\"总计\"] ,\"月还款\":[self.p + (self.n+1)*self.p*(self.r/2)] ,\"本金部分\":[self.p] ,\"利息部分\":[self.p*(self.n+1)*(self.r/2)] }) df = df_detail.append(df_total) return df_detail,df.reset_index(drop=True) 俩还款方式每期还款金额如下图所示 ","date":"2021-09-13","objectID":"/2021/09/fem-%E8%BF%98%E6%AC%BE%E6%96%B9%E5%BC%8F/:2:1","tags":["金融"],"title":"还款方式：等额本息-等额本金-等本等息","uri":"/2021/09/fem-%E8%BF%98%E6%AC%BE%E6%96%B9%E5%BC%8F/"},{"categories":["FEM"],"content":"等本等息 关于这个“等本等息”，常见于互金的现金贷业务、信用卡分期等 上面的等额本息、等额本金还款方式在计算每一期的利息时，也有按照占用借款时间的概念来计算，即还了的部分就不计算利息了 但 “等本等息”还款方式一开始就计算的死死的，每期还款中本金、利息都是固定的 比如，小明借了12w元，年利率是12%，分12期还。那么每期应还$11200=(\\frac{120000*(1+0.12)}{12})$ 还是基于 12w，年利率12%，分12期的情况，不同还款方式的情况如下所示 等额本金 等额本息 等本等息 1 11200 10661.85 11200 2 11100 10661.85 11200 3 11000 10661.85 11200 4 10900 10661.85 11200 5 10800 10661.85 11200 6 10700 10661.85 11200 7 10600 10661.85 11200 8 10500 10661.85 11200 9 10400 10661.85 11200 10 10300 10661.85 11200 11 10200 10661.85 11200 12 10100 10661.85 11200 总计 127800 127942.2 134400 ","date":"2021-09-13","objectID":"/2021/09/fem-%E8%BF%98%E6%AC%BE%E6%96%B9%E5%BC%8F/:3:0","tags":["金融"],"title":"还款方式：等额本息-等额本金-等本等息","uri":"/2021/09/fem-%E8%BF%98%E6%AC%BE%E6%96%B9%E5%BC%8F/"},{"categories":["FEM"],"content":"总结 本文罗列了等额本息、等额本金和等本等息三种还款方式的基本信息。但产品设计的角度思考较少 虽然表面上看起来等本等息还款方式很暴力，但我觉得每种还款方式背后都有金融产品设计者的考虑吧 银行不会雪中送炭，只会锦上添花。小额贷款等机构 、平台都是一样的，在风险可承受的情况下给予放款，毕竟这是门生意 但政府的监管，限制利率上限等政策，带来的结果便是，更多的人借不到钱 🤷‍♂️ 原本的毛细血管更加的“细”。 从奥派的角度来看“高利贷”等问题，可参考陈志武教授的这篇文章 ","date":"2021-09-13","objectID":"/2021/09/fem-%E8%BF%98%E6%AC%BE%E6%96%B9%E5%BC%8F/:4:0","tags":["金融"],"title":"还款方式：等额本息-等额本金-等本等息","uri":"/2021/09/fem-%E8%BF%98%E6%AC%BE%E6%96%B9%E5%BC%8F/"},{"categories":["生活"],"content":"在疫情的情况下毕业了🎓，时隔一年2个月，我们终于是和导师成功约饭了 时间：2021-09-06 晚 地点：上海-新世界城-陶陶居 这次“会师”似乎没有在学校时候的拘谨了，和导师之间可谓是亦师亦友了 总体而言，感觉多聊聊还是挺好的，聊的几个点也挺有意思，在此做个记录好了。 可能是之前受章慧南教授的影响 每个人都有自己的兴趣点或是说研究方向，可以通过大白话的形式分享自己关注的部分，同时也能加深自己对该领域知识的理解 从个人而言，就可以通过这种方式 “多一只眼看世界”。就像TED，在那儿有各种各样的角度，分享着各种各样有趣的东西 ","date":"2021-09-07","objectID":"/2021/09/life-%E4%B8%8E%E5%AF%BC%E5%B8%88%E7%9A%84%E6%99%9A%E9%A4%90/:0:0","tags":["碎碎念","学术"],"title":"记毕业后第一次与导师的晚餐","uri":"/2021/09/life-%E4%B8%8E%E5%AF%BC%E5%B8%88%E7%9A%84%E6%99%9A%E9%A4%90/"},{"categories":["生活"],"content":"回归人性 话虽如此，但我并未实际领悟到这四个字的深层含义，但也提供了一个思考的方向，很多时候有啥困惑的试着从人性的角度先去思考“为什么” 或许就能豁然开朗，但可能也不排除会以小人之心度君子之腹？🤔 hhhhh，没有什么十全十美的事儿，自己开心最重要，解释通了、开行了就好 工作之后，直接、间接学习到的一点也是 先思考为什么，再想其他的 比较典型的是之前我接手某件事儿时，总会吐槽这儿、吐槽那儿，但后来想想，这个方案放在当时的情景可能是个局部最优的方案了 比如会受到产品着急上线的压力；比如没有现在的新工具等等 总之，多一份为什么，少一份自以为是。 因为我发现自己在和上下游一起处理问题时，也会先着手解决当前的问题，达到局部最优，算是较为经济的一个方案吧🌞 ","date":"2021-09-07","objectID":"/2021/09/life-%E4%B8%8E%E5%AF%BC%E5%B8%88%E7%9A%84%E6%99%9A%E9%A4%90/:1:0","tags":["碎碎念","学术"],"title":"记毕业后第一次与导师的晚餐","uri":"/2021/09/life-%E4%B8%8E%E5%AF%BC%E5%B8%88%E7%9A%84%E6%99%9A%E9%A4%90/"},{"categories":["生活"],"content":"先有蛋 倒不是指传统的 先有鸡、后有蛋的问题。而是指先能生蛋，在此基础上，得到更好的环境，以便产出更多的鸡蛋 可能这个比喻不恰当 但表达的意思主要是在某个圈子里得先有实力能崭露头角，方能升级进入到高阶水平，不断的打怪升级 回想硕士期间，我也是先写了篇小论文出来，才找各位老师们提意见，看看能不能带我一起玩～ 所以，还是得在某个领域提升自己 吃饭时也提出了“加点”方向和圈子内对不上怎么办，就像是你待在一个研究机器学习的圈子，而你在研究数据库 导师的第一反应也是换到“加点”方向的那个圈子呀～ 这个也是让我豁然开朗，对啊，是这个道理啊，我为什么要鸡同鸭讲，需要的是“琴箫合奏”、沧海一声笑 m 所以，先有蛋的那个蛋得是在鸡圈里呀，在猪、羊等胎生动物的圈里，除非遇上“伯乐”，知道且需要蛋。 ","date":"2021-09-07","objectID":"/2021/09/life-%E4%B8%8E%E5%AF%BC%E5%B8%88%E7%9A%84%E6%99%9A%E9%A4%90/:2:0","tags":["碎碎念","学术"],"title":"记毕业后第一次与导师的晚餐","uri":"/2021/09/life-%E4%B8%8E%E5%AF%BC%E5%B8%88%E7%9A%84%E6%99%9A%E9%A4%90/"},{"categories":["生活"],"content":"身心健康 这一点虽然之前也有感悟，但一直未贯彻落实 身心健康是两个维度：身体和心理 《中国文化的深层结构》一书中也曾提及，国内传统文化及教育很少涉及“心理”，典型的是长辈说的最多的是注意身体之类的；常年在外回到家后往往会准备好吃的好喝的。 不过这也是，安身方可安心～ 只是说需要注意的是，“身”、“心”应齐头并进、双管齐下 这一点虽是老生常谈，但我个人并未很好的落实呀～ 🤦‍♂️ 外界是很难甚至没法改变的，我们能改变的或容易改变的是自己，所以 “修身，齐家，治国，平天下”，修身乃第一☝️位 ","date":"2021-09-07","objectID":"/2021/09/life-%E4%B8%8E%E5%AF%BC%E5%B8%88%E7%9A%84%E6%99%9A%E9%A4%90/:3:0","tags":["碎碎念","学术"],"title":"记毕业后第一次与导师的晚餐","uri":"/2021/09/life-%E4%B8%8E%E5%AF%BC%E5%B8%88%E7%9A%84%E6%99%9A%E9%A4%90/"},{"categories":["生活"],"content":"最后 最后，恭喜我导今年在营销领域顶刊 Journal of Marketing Research 发表相关学术论文～ 希望大家一切顺利～🌞 ","date":"2021-09-07","objectID":"/2021/09/life-%E4%B8%8E%E5%AF%BC%E5%B8%88%E7%9A%84%E6%99%9A%E9%A4%90/:4:0","tags":["碎碎念","学术"],"title":"记毕业后第一次与导师的晚餐","uri":"/2021/09/life-%E4%B8%8E%E5%AF%BC%E5%B8%88%E7%9A%84%E6%99%9A%E9%A4%90/"},{"categories":["生活"],"content":"不知不觉，离开学校已经有1年2个月了。。。 ","date":"2021-09-05","objectID":"/2021/09/life-%E8%83%A1%E8%A8%80%E4%B9%B1%E8%AF%AD/:0:0","tags":["碎碎念"],"title":"如果真的什么都不用想","uri":"/2021/09/life-%E8%83%A1%E8%A8%80%E4%B9%B1%E8%AF%AD/"},{"categories":["生活"],"content":"目标 这一年以来真的是经历了许多乌龙事件。最大的干扰点有二：一是户口；二是工作岗位。 心态差的时候，只想说，或许我的运气在实习期间都用完了吧 😂 实习期间遇到的人太棒、太赞了，以至于现在一塌糊涂… 心态好的时候，时常告诉自己说，这些都是经历、是“入道”的素材。 有时候想想，确实也是这样啊。毕业论文的致谢中，我依然会由衷的感谢导师给予我的自由度，也曾感叹着自己“摸黑”的日子 但尽管如此，在学校的时候隐隐约约似乎能感受到有些大方向依然还是在那儿的，真的就像黑暗中的烛光，忽闪忽闪的 然而，现在的状态大方向处于飘忽不定的状态，甚至是太大、太遥远了，使得自己有时候丧失了一切动力，只想躺尸 就希望能什么都不用想、不用顾虑“面包”🍞，每天尽享时间的流逝，就像电视剧里的样子 小时候我爸打趣的和我说，你看电视剧里都不讲赚钱的问题呐 真的觉得“系统1” 能轻而易举的战胜“系统2”。 没有错，保持理性是很累的一件事儿，是会消耗大量能量以及脑细胞的。 所以推出要将某事成为一种习惯、形成chunk，让一切都显得那么的自然与丝滑 就像每天在站点等交通工具 或是倒车入库 至于怎样才能将某事成为一种习惯呐，暂时认为就需要和时间做朋友了吧～以及自身的兴趣或动力 这是不是又回到了“先有鸡，还是先有蛋”的问题呐。本想着让一切是那么的自然，而习惯又需要动力来促成 也有可能是我想错了。但似乎也不需要走极端吧。即一定程度上的习惯降低动力的依赖或损耗，两者相辅相成呀☯️ 基于我目前对“奥派”的理解，以上便是属于目标的问题。目前的小目标都是下一个目标的过程：既是终点也是起点。 目标有了又如何？不做不都是白瞎么 ","date":"2021-09-05","objectID":"/2021/09/life-%E8%83%A1%E8%A8%80%E4%B9%B1%E8%AF%AD/:1:0","tags":["碎碎念"],"title":"如果真的什么都不用想","uri":"/2021/09/life-%E8%83%A1%E8%A8%80%E4%B9%B1%E8%AF%AD/"},{"categories":["生活"],"content":"落地 首先，我认为做什么都是每个人的自由，每个人都有自己的偏好，基于偏好、机会成本做决策。 早之前在旭辉实习的时候遇到位大佬，在短暂的接触中，真的是由衷的钦佩他～也曾就类似的事儿向其请教过 初窥地产研究岗，也关注了些公众号，看到相应的文章会收藏（比如现在的“浮窗”），但在收藏中躺了x天，都没打开过了 他说，因为你不认为这件事儿此刻对你而言是重要的，或者可能你压根就没这个需求。我会看是因为我的工作和这些相关，需要去了解这些讯息，了解…。 是的，我目前认为就是这样。这里面除了重要性之外，还有紧迫性的维度 这件事儿、这个目标当下对我是否重要？ 紧迫感、重要性的加持，我想大概率就能落地了吧。想想憋毕业论文的那段时间… 除非真的是无力回天…直接弃疗… 我们都知道身体的重要性，但并没有那种紧迫感。再极端点说，可能没和死神擦肩而过，对于重要性的感触也没那么的深刻。有些事儿真的很难感同身受… 所以对于这些，重要不紧急的目标，我该怎么办？或许这类事儿、目标真的不需要太多，让“系统2”和习惯共同加持吧，同时也需要一些“助推（Nudge）”的方式。真的需要踏出那一步o.o “助推”解释为那种轻轻用手肘碰下你，就能实现目标 ","date":"2021-09-05","objectID":"/2021/09/life-%E8%83%A1%E8%A8%80%E4%B9%B1%E8%AF%AD/:2:0","tags":["碎碎念"],"title":"如果真的什么都不用想","uri":"/2021/09/life-%E8%83%A1%E8%A8%80%E4%B9%B1%E8%AF%AD/"},{"categories":["生活"],"content":"WLB 感觉实际参加工作之后就没顺过，，，也是因为自己的决策问题吧，这也算是让自己直接学习了一波之前间接学习的经验：比较重大的事情要积极启用“系统2”来理性分析各种依赖关系！ 切片数据来看，我觉得可以将企业工作者分为能力、资源2个维度来看。 资源多 资源少 能力强 资源多-能力强 资源少-能力强 能力弱 资源多-能力弱 资源少-能力弱 某种程度上其实是不太合理，因为两个维度并非完全独立，也可能会存在互为因果的情况。比如直观理解，因为能力弱（强），所以资源少（多）。 但很多时候并非如此，资源是有限的 实际做决策的是个人，很多时候是由上而下的，分配资源的是各个节点上的人，各个节点上的人具体怎么分配的谁都不知道🤷‍♂️ 现实情况一样存在能力弱的人所拥有的资源多于能力强的。但这是不是也很难界定？因为溜须拍马、机遇也是种能力啊🤷‍♂️ 跟人扯上关系的都很复杂，所以我觉得人文社科领域是不存在类似物理世界的漂亮公式的 而且，实际工作中也并不需要多强的能力，企业越大，分工越明确、“通用件”越多、互换性越强。 工科应该都会提及“互换性技术”，带来的好处就是哪个零部件坏了，拆下来换个新的又能正常运转了，而且这个新的零部件也很容易获得，大大提高了生产效率。 最近刚好在欧神的文章中看到这么一段话👇 得想想办法怎么深度挖掘潜能🤔 ","date":"2021-09-05","objectID":"/2021/09/life-%E8%83%A1%E8%A8%80%E4%B9%B1%E8%AF%AD/:3:0","tags":["碎碎念"],"title":"如果真的什么都不用想","uri":"/2021/09/life-%E8%83%A1%E8%A8%80%E4%B9%B1%E8%AF%AD/"},{"categories":["生活"],"content":"愿望🙏 希望未来一切都好～ 目标能落地 找到深度挖掘潜能的路子 修身养性、由艺入道 ","date":"2021-09-05","objectID":"/2021/09/life-%E8%83%A1%E8%A8%80%E4%B9%B1%E8%AF%AD/:4:0","tags":["碎碎念"],"title":"如果真的什么都不用想","uri":"/2021/09/life-%E8%83%A1%E8%A8%80%E4%B9%B1%E8%AF%AD/"},{"categories":["机器学习"],"content":"RT，可视化决策树结果，直观感受决策流程 早之前可视化领域专家、学者提出之后要结合各种机器学习算法，制作相应可视化的图标以及工具。比如 TensorFlow 的可视化工具包—TensorBoard 针对结构化数据建模的算法中，树模型是较为常见的，之前 一直用sklearn自带的tree_plot()函数或Graphviz tree_plot 最近发现了一个可视化树模型结果的package1，画出来的图长这样👇 iris-TD-3-X 各个节点的分布情况也比较清楚，直观感受决策树的逻辑 更多代码示例可参考 这个 或 这个 但目前图片格式只支持 svg 这里主要记录下安装说明 ","date":"2021-08-19","objectID":"/2021/08/ml-%E5%8F%AF%E8%A7%86%E5%8C%96%E5%86%B3%E7%AD%96%E6%A0%91/:0:0","tags":["可视化"],"title":"可视化决策树结果","uri":"/2021/08/ml-%E5%8F%AF%E8%A7%86%E5%8C%96%E5%86%B3%E7%AD%96%E6%A0%91/"},{"categories":["机器学习"],"content":"安装2 原文 Python 版本 \u003e= 3.6 ","date":"2021-08-19","objectID":"/2021/08/ml-%E5%8F%AF%E8%A7%86%E5%8C%96%E5%86%B3%E7%AD%96%E6%A0%91/:1:0","tags":["可视化"],"title":"可视化决策树结果","uri":"/2021/08/ml-%E5%8F%AF%E8%A7%86%E5%8C%96%E5%86%B3%E7%AD%96%E6%A0%91/"},{"categories":["机器学习"],"content":"安装 graphviz 确保 graphviz 是 通过 pip 的方式安装的。 如果有装 Anaconda，又不确定是不是通过 pip 安装的，就走遍流程👇 conda uninstall python-graphviz conda uninstall graphviz pip install graphviz 接下来以 Windows 为例， 下载 graphviz.msi 并更新Path环境变量 假设保存路径为 C:\\Program Files (x86)\\Graphviz2.38，则将 C:\\Program Files (x86)\\Graphviz2.38\\bin 添加至用户变量（Path） C:\\Program Files (x86)\\Graphviz2.38\\bin\\dot.exe 添加至系统变量（PATH） 可以通过 where dot 验证是否安装成功 (base) C:\\Users\\Terence Parr\u003ewhere dot C:\\Program Files (x86)\\Graphviz2.38\\bin\\dot.exe ","date":"2021-08-19","objectID":"/2021/08/ml-%E5%8F%AF%E8%A7%86%E5%8C%96%E5%86%B3%E7%AD%96%E6%A0%91/:1:1","tags":["可视化"],"title":"可视化决策树结果","uri":"/2021/08/ml-%E5%8F%AF%E8%A7%86%E5%8C%96%E5%86%B3%E7%AD%96%E6%A0%91/"},{"categories":["机器学习"],"content":"安装 dtreeviz 通过 pip 安装，Windows 可以直接打开 Anaconda Prompt pip install dtreeviz # install dtreeviz for sklearn pip install dtreeviz[xgboost] # install XGBoost related dependency pip install dtreeviz[pyspark] # install pyspark related dependency pip install dtreeviz[lightgbm] # install LightGBM related dependency 这里有酷炫的决策树介绍文档 ","date":"2021-08-19","objectID":"/2021/08/ml-%E5%8F%AF%E8%A7%86%E5%8C%96%E5%86%B3%E7%AD%96%E6%A0%91/:1:2","tags":["可视化"],"title":"可视化决策树结果","uri":"/2021/08/ml-%E5%8F%AF%E8%A7%86%E5%8C%96%E5%86%B3%E7%AD%96%E6%A0%91/"},{"categories":["机器学习"],"content":"Reference https://explained.ai/decision-tree-viz/index.html ↩︎ https://github.com/parrt/dtreeviz#install ↩︎ ","date":"2021-08-19","objectID":"/2021/08/ml-%E5%8F%AF%E8%A7%86%E5%8C%96%E5%86%B3%E7%AD%96%E6%A0%91/:2:0","tags":["可视化"],"title":"可视化决策树结果","uri":"/2021/08/ml-%E5%8F%AF%E8%A7%86%E5%8C%96%E5%86%B3%E7%AD%96%E6%A0%91/"},{"categories":["数据分析"],"content":"【Mark】通过正则表达式选择相应的列 在涉及子查询时，平时习惯直接把需要的列全写出来，也没想太多。 最近有小伙伴谈起正则选择需要的列，一顿操作后做个记录。建模取特征时，常见这种操作 Spark 和 Hive 都是支持这种操作的 只是相应的设置不同 spark/hive set hive1 set hive.support.quoted.identifiers=none spark2 set spark.sql.parser.quotedRegexColumnNames=true 其中，正则表达式的写法可参考 JAVA regex 语法 ","date":"2021-08-16","objectID":"/2021/08/sql-%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E9%80%89%E6%8B%A9%E5%88%97%E5%90%8D/:0:0","tags":["SQL"],"title":"Spark、Hive QL-通过正则表达式选取需要的列","uri":"/2021/08/sql-%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E9%80%89%E6%8B%A9%E5%88%97%E5%90%8D/"},{"categories":["数据分析"],"content":"例1，查询去除某几列的所有列 select 去除 user_no, cust_no 的所有列 select `(user_no|cust_no)?+.+` from table1 select 去除以 no 结尾的所有列 select `(.*no)?+.+` from table1 ","date":"2021-08-16","objectID":"/2021/08/sql-%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E9%80%89%E6%8B%A9%E5%88%97%E5%90%8D/:1:0","tags":["SQL"],"title":"Spark、Hive QL-通过正则表达式选取需要的列","uri":"/2021/08/sql-%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E9%80%89%E6%8B%A9%E5%88%97%E5%90%8D/"},{"categories":["数据分析"],"content":"例2，查询符合某特征的所有列 select 以 no 结尾的所有列 select `.+no` from table1 ","date":"2021-08-16","objectID":"/2021/08/sql-%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E9%80%89%E6%8B%A9%E5%88%97%E5%90%8D/:2:0","tags":["SQL"],"title":"Spark、Hive QL-通过正则表达式选取需要的列","uri":"/2021/08/sql-%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E9%80%89%E6%8B%A9%E5%88%97%E5%90%8D/"},{"categories":["数据分析"],"content":"Reference https://community.cloudera.com/t5/Community-Articles/Spark-to-support-REGEX-column-specification-for-Hive-Queries/ta-p/316579 ↩︎ https://stackoverflow.com/questions/52526768/does-spark-sql-supports-hive-select-all-query-with-except-columns-using-regex-sp ↩︎ ","date":"2021-08-16","objectID":"/2021/08/sql-%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E9%80%89%E6%8B%A9%E5%88%97%E5%90%8D/:3:0","tags":["SQL"],"title":"Spark、Hive QL-通过正则表达式选取需要的列","uri":"/2021/08/sql-%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E9%80%89%E6%8B%A9%E5%88%97%E5%90%8D/"},{"categories":["数据分析"],"content":"类似Excel的数据透视表，分类聚合。也可以协助实现行转列，Pivoting “Wide” to “Long” Format 在统计分析时总会遇到分类汇总的场景，类似Excel的数据透视表。SQL中按照 case when 或 IF 的写法往往会显得臃肿，较为方便的便是通过 pivot 1实现，但 Hive 不支持😢 以下基于 spark-2.4.5U3 及以上版本 ","date":"2021-08-09","objectID":"/2021/08/sql-pivot/:0:0","tags":["SQL"],"title":"Spark SQL-Pivot","uri":"/2021/08/sql-pivot/"},{"categories":["数据分析"],"content":"基本语法 PIVOT ( { aggregate_expression [ AS aggregate_expression_alias ] } [ , ... ] FOR column_list IN ( expression_list ) ) The PIVOT clause can be specified after the table name or subquery. ","date":"2021-08-09","objectID":"/2021/08/sql-pivot/:1:0","tags":["SQL"],"title":"Spark SQL-Pivot","uri":"/2021/08/sql-pivot/"},{"categories":["数据分析"],"content":"实际应用 假设有张存有各个地区、各个产品的月销量的表（sales_table），我们需要统计各个月份所有地区产品销量的加总，形如👇 select month ,'毛巾' ,'肥皂' from sales_table pivot ( sum(sales) for product in ('毛巾','肥皂') ) ; ","date":"2021-08-09","objectID":"/2021/08/sql-pivot/:2:0","tags":["SQL"],"title":"Spark SQL-Pivot","uri":"/2021/08/sql-pivot/"},{"categories":["数据分析"],"content":"Reference https://spark.apache.org/docs/3.1.2/sql-ref-syntax-qry-select-pivot.html ↩︎ ","date":"2021-08-09","objectID":"/2021/08/sql-pivot/:3:0","tags":["SQL"],"title":"Spark SQL-Pivot","uri":"/2021/08/sql-pivot/"},{"categories":["数据分析"],"content":"已经2021年了，SQL条件函数已不局限于case when 了，针对常见场景已新增许多 conditional functions 汇总 Hive SQL 常用的条件函数，👇 ","date":"2021-07-31","objectID":"/2021/07/hql-conditional-functions/:0:0","tags":["SQL"],"title":"Hive SQL-条件函数汇总","uri":"/2021/07/hql-conditional-functions/"},{"categories":["数据分析"],"content":"if(condition, value True, value FalseOrNull) This is the one of best Hive Conditional Function 类似Excel中的 if 函数 select if(state = 'online','在线','离线') as state; ","date":"2021-07-31","objectID":"/2021/07/hql-conditional-functions/:1:0","tags":["SQL"],"title":"Hive SQL-条件函数汇总","uri":"/2021/07/hql-conditional-functions/"},{"categories":["数据分析"],"content":"case when then end case when 较为常见，可注意执行顺序问题：从上至下依次执行，直到满足条件则跳出 常见写法有两种，主要取决于是否单变量作判断 select case dayofweek when 1 then '星期一' when 2 then '星期二' end as week ; -- OR -- select case when dayofweek = 1 then '星期一' when dayofweek = 2 then '星期二' end as week ; ","date":"2021-07-31","objectID":"/2021/07/hql-conditional-functions/:2:0","tags":["SQL"],"title":"Hive SQL-条件函数汇总","uri":"/2021/07/hql-conditional-functions/"},{"categories":["数据分析"],"content":"isnull(a) 判断是否为null（数据库特有的一种数据类型），留意字符型 'null', 'NULL' select isnull(''); /*return false */ ","date":"2021-07-31","objectID":"/2021/07/hql-conditional-functions/:3:0","tags":["SQL"],"title":"Hive SQL-条件函数汇总","uri":"/2021/07/hql-conditional-functions/"},{"categories":["数据分析"],"content":"isnotnull(a) 非null select isnotnull(''); /*return true */ ","date":"2021-07-31","objectID":"/2021/07/hql-conditional-functions/:4:0","tags":["SQL"],"title":"Hive SQL-条件函数汇总","uri":"/2021/07/hql-conditional-functions/"},{"categories":["数据分析"],"content":"nullif(a,b) 如果 a=b 则返回null，否则返回a 等同于 case when a = b then null else a end select nullif(1,1); /*return NULL */ select nullif(4,3); /*return 4 */ ","date":"2021-07-31","objectID":"/2021/07/hql-conditional-functions/:5:0","tags":["SQL"],"title":"Hive SQL-条件函数汇总","uri":"/2021/07/hql-conditional-functions/"},{"categories":["数据分析"],"content":"nvl(arg1,arg2) 可以理解为用arg2的值替换 arg1 中值为 null 的部分 select nvl(null,999); /*return 999 */ select nvl('null',999); /*return null */ ","date":"2021-07-31","objectID":"/2021/07/hql-conditional-functions/:6:0","tags":["SQL"],"title":"Hive SQL-条件函数汇总","uri":"/2021/07/hql-conditional-functions/"},{"categories":["数据分析"],"content":"coalesce(value1,value2,…) 返回第一个非null的值 往往只想得到众多列中非 null 的值 select coalesce(null,7,8); /*return 7 */ 涉及null的问题要留意数据库中的数据类型。譬如，某列数据格式为string，'null' 并不等同于 null ","date":"2021-07-31","objectID":"/2021/07/hql-conditional-functions/:7:0","tags":["SQL"],"title":"Hive SQL-条件函数汇总","uri":"/2021/07/hql-conditional-functions/"},{"categories":["写作"],"content":"将博客源文件托管在某个地方，换台电脑继续编辑。再加上触发机制更好，即一上传⏫就同步更新博客～ 在之前快速搭建个人博客的文章中有提到 将 public 文件夹下的文件推送至GitHub仓库 每次这么操作还是有点繁琐的，所以就想如果更新完hugo源文件，博客自动更新就好了。此外，换台电脑💻，依然正常操作就更更更好了～ 终于，是找到了GitHub的 Actions 中 Workflows 功能 将Hugo源文件维护在GitHub上，只要源文件的仓库更新，自动更新存有 public 文件的仓库，那么博客也就随之更新了。 在此记录下实现过程 👇 ","date":"2021-07-14","objectID":"/2021/07/20210714-workflows/:0:0","tags":["blog"],"title":"远程管理hugo源文件以自动更新blog","uri":"/2021/07/20210714-workflows/"},{"categories":["写作"],"content":"1. 生成SSH key （Windows 环境） 参考这个 通过git bash cd 至 .ssh 文件夹 cd ~/.ssh/ 如果提示 No such file or directory，可以手动的创建一个 .ssh文件夹，BY mkdir ~/.ssh 配置全局 name 和 email git config --global user.name \"你的用户名\" git config --global user.email \"你的公司或个人邮箱\" 生成 key ssh-keygen -t rsa -C \"你的公司或个人邮箱\" 连续按 3 次回车 最后得到俩文件： id_rsa 和 id_rsa.pub ","date":"2021-07-14","objectID":"/2021/07/20210714-workflows/:1:0","tags":["blog"],"title":"远程管理hugo源文件以自动更新blog","uri":"/2021/07/20210714-workflows/"},{"categories":["写作"],"content":"2. 创建并配置仓库 参考这个 ","date":"2021-07-14","objectID":"/2021/07/20210714-workflows/:2:0","tags":["blog"],"title":"远程管理hugo源文件以自动更新blog","uri":"/2021/07/20210714-workflows/"},{"categories":["写作"],"content":"2.1 配置hugo源文件的仓库 仓库名称不限，在此以 unclehuzi.github.io.source 为例 进入unclehuzi.github.io.source仓库，添加Secrets，名称为ACTIONS_DEPLOY_KEY，将 id_rsa 文件的内容粘过去，得到内容如下所示 上传 hugo源文件 把 themes 主题文件夹中的 .git 文件删除 不然Github 会检测到是别的仓库，上传后文件夹是灰色的 ","date":"2021-07-14","objectID":"/2021/07/20210714-workflows/:2:1","tags":["blog"],"title":"远程管理hugo源文件以自动更新blog","uri":"/2021/07/20210714-workflows/"},{"categories":["写作"],"content":"2.2 配置 unclehuzi.github.io 仓库 仓库名称有讲究，得是这个 github_user_name.github.io 进入unclehuzi.github.io 仓库，添加Deploy keys ，名称不限制，将id_rsa.pub文件的内容粘过去。 ","date":"2021-07-14","objectID":"/2021/07/20210714-workflows/:2:2","tags":["blog"],"title":"远程管理hugo源文件以自动更新blog","uri":"/2021/07/20210714-workflows/"},{"categories":["写作"],"content":"2.3 配置工作流（Workflows） 进入unclehuzi.github.io.source仓库，创建 Actions 代码如下 👇 name: Deploy Hugo Site to Github Pages on Master Branch on: push: branches: - master # Attention 1 jobs: build-deploy: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: '0.83.1' extended: true # 使用扩展版 # Attention 2 - name: Build run: hugo #--minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: deploy_key: ${{ secrets.ACTIONS_DEPLOY_KEY }} # 这里的 ACTIONS_DEPLOY_KEY 则是上面设置 Private Key的变量名 external_repository: unclehuzi/unclehuzi.github.io # Pages 远程仓库 publish_dir: ./public keep_files: false # remove existing files publish_branch: master # deploying branch # Attention 3 commit_message: ${{ github.event.head_commit.message }} Attention 1 source 仓库的分支名称为 master Attention 2 hugo 的版本 Attention 3 unclehuzi.github.io 仓库的分支名称 ","date":"2021-07-14","objectID":"/2021/07/20210714-workflows/:2:3","tags":["blog"],"title":"远程管理hugo源文件以自动更新blog","uri":"/2021/07/20210714-workflows/"},{"categories":["写作"],"content":"3. Finished 以后维护好source这个仓库就能实现 触发机制以自动更新blog 换个电脑 💻 继续写blog ","date":"2021-07-14","objectID":"/2021/07/20210714-workflows/:3:0","tags":["blog"],"title":"远程管理hugo源文件以自动更新blog","uri":"/2021/07/20210714-workflows/"},{"categories":["写作"],"content":"Reference https://jinnzy.github.io/shi-yong-hugolai-da-jian-ge-ren-blog/#%E5%88%A9%E7%94%A8github-pages%E9%83%A8%E7%BD%B2blog https://www.jianshu.com/p/95262f5eba7a ","date":"2021-07-14","objectID":"/2021/07/20210714-workflows/:4:0","tags":["blog"],"title":"远程管理hugo源文件以自动更新blog","uri":"/2021/07/20210714-workflows/"},{"categories":["数据分析","机器学习"],"content":"RT，SQL计算多个变量的IV（Information Value） ","date":"2021-07-08","objectID":"/2021/07/20210708-sql%E8%AE%A1%E7%AE%97iv/:0:0","tags":["Model","SQL"],"title":"SQL计算多个变量的IV","uri":"/2021/07/20210708-sql%E8%AE%A1%E7%AE%97iv/"},{"categories":["数据分析","机器学习"],"content":"背景 变量的预测能力往往可以通过IV值来判断，类似之前的 SQL计算PSI IV值也有经验区间供参考，以及可通过SQL完成指标的计算 Information Value Predictive Power \u003c 0.02 useless for prediction 0.02 - 0.1 weak predictor 0.1 - 0.3 medium predictor 0.3 - 0.5 strong predictor \u003e 0.5 suspicious or too good ","date":"2021-07-08","objectID":"/2021/07/20210708-sql%E8%AE%A1%E7%AE%97iv/:1:0","tags":["Model","SQL"],"title":"SQL计算多个变量的IV","uri":"/2021/07/20210708-sql%E8%AE%A1%E7%AE%97iv/"},{"categories":["数据分析","机器学习"],"content":"计算公式 关于 IV 的详细介绍，可参考这篇文章 具体计算公式如下 $$IV=\\sum_{i=1}^{n}(\\frac{Bad_i}{Bad_T} - \\frac{Good_i}{Good_T}) \\times WOE_i$$ 其中， $$WOE_i=\\ln(\\frac{Bad_i}{Bad_T}) - \\ln(\\frac{Good_i}{Good_T})$$ Bad、Good即表示正负样本，风控场景有好、坏的称呼 $n$ 为分箱的个数 $Bad_i$, $Good_i$ 表示第i个箱子“坏”、“好”人数 $Bad_T$, $Good_T$ 表示“坏”、“好”总人数 ","date":"2021-07-08","objectID":"/2021/07/20210708-sql%E8%AE%A1%E7%AE%97iv/:2:0","tags":["Model","SQL"],"title":"SQL计算多个变量的IV","uri":"/2021/07/20210708-sql%E8%AE%A1%E7%AE%97iv/"},{"categories":["数据分析","机器学习"],"content":"计算样例 分箱方式：等频（缺失值单独划为一箱） score_group group_bad_i group_good_i woe_i iv_i r1 271 31882 0.218363 0.0054 r2 225 30572 0.074301 0.0006 r3 195 29107 -0.01969 0.0000 r4 188 28761 -0.04429 0.0002 r5 163 28400 -0.17435 0.0025 r6 182 27387 -0.02778 0.0001 r7 194 28058 0.01187 0.0000 r8 160 24564 -0.04782 0.0002 r9 158 29625 -0.24774 0.0052 r10 70 17302 -0.52404 0.0118 missing 327 36519 0.270413 0.0098 以上例子最终得到 $IV=\\sum_{i=1}^{11}(IV_i)=0.0358$ ","date":"2021-07-08","objectID":"/2021/07/20210708-sql%E8%AE%A1%E7%AE%97iv/:3:0","tags":["Model","SQL"],"title":"SQL计算多个变量的IV","uri":"/2021/07/20210708-sql%E8%AE%A1%E7%AE%97iv/"},{"categories":["数据分析","机器学习"],"content":"SQL实现 准备好预测变量（$X$）和目标变量（$y$），score表形如 ym no x1 x2 x3 x4 y 202101 a1 617 481 773 671.68 1 202102 a2 585 585 522 600.56 0 202102 a3 617 548 677 635.68 1 202102 a4 647 null 765 655.63 0 202102 a5 596 478 656 635.3 0 202102 a6 636 618 595 630 0 202102 a7 714 572 842 644.28 0 202012 a8 null 495 720 628.79 0 202012 a9 636 618 595 426 0 202012 a10 557 562 null 589 1 基于此得到各个变量在不同月份的预测能力 这里依然涉及窗口函数的应用以及行列互转 窗口函数-聚合 窗口函数-排序 窗口函数的“窗口” 行转列、列转行 类似PSI的计算思路，计算IV的整体思路依然参照公式，（等频）分箱后，基于数据的断点（Breakpoint Value）统计出每个箱子的好坏人数 ","date":"2021-07-08","objectID":"/2021/07/20210708-sql%E8%AE%A1%E7%AE%97iv/:4:0","tags":["Model","SQL"],"title":"SQL计算多个变量的IV","uri":"/2021/07/20210708-sql%E8%AE%A1%E7%AE%97iv/"},{"categories":["数据分析","机器学习"],"content":"1. 列转行 将score表进行列转行，变为key-value 键值对的形式 drop table if exists score_value; create table score_value as select no ,ym ,y ,score ,score_value from( select no ,ym ,x1 ,x2 ,x3 ,x4 ,y from score ) lateral view outer explode(map('x1',x1,'x2',x2,'x3',x3,'x4',x4)) t as score,score_value ; ","date":"2021-07-08","objectID":"/2021/07/20210708-sql%E8%AE%A1%E7%AE%97iv/:4:1","tags":["Model","SQL"],"title":"SQL计算多个变量的IV","uri":"/2021/07/20210708-sql%E8%AE%A1%E7%AE%97iv/"},{"categories":["数据分析","机器学习"],"content":"2. 分箱统计好坏人数 这里采用的是 等频分箱 drop table if exists score_group_nums; create table score_group_nums as select ym ,score ,score_group ,group_bad_i ,group_good_i ,sum(group_bad_i) over(partition by ym,score) as group_bad_total ,sum(group_good_i) over(partition by ym,score) as group_good_total from( select ym ,score ,score_group ,count(case when y=1 then no end) as group_bad_i ,count(case when y=0 then no end) as group_good_i from( select a.* ,case when a.score_value is null or a.score_value in ('','null','NULL') then 'missing' when a.score_value \u003c= r.score_array[0] then 'r1' when a.score_value \u003c= r.score_array[1] then 'r2' when a.score_value \u003c= r.score_array[2] then 'r3' when a.score_value \u003c= r.score_array[3] then 'r4' when a.score_value \u003c= r.score_array[4] then 'r5' when a.score_value \u003c= r.score_array[5] then 'r6' when a.score_value \u003c= r.score_array[6] then 'r7' when a.score_value \u003c= r.score_array[7] then 'r8' when a.score_value \u003c= r.score_array[8] then 'r9' when a.score_value \u003c= r.score_array[9] then 'r10' end as score_group from score_value a left join (-- 等频分箱 10 bins select ym ,score ,percentile_approx(score_value,array(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1),999999) as score_array from score_value group by 1,2 ) r on (a.ym = r.ym and a.score = r.score) ) group by 1,2,3 ) ; ","date":"2021-07-08","objectID":"/2021/07/20210708-sql%E8%AE%A1%E7%AE%97iv/:4:2","tags":["Model","SQL"],"title":"SQL计算多个变量的IV","uri":"/2021/07/20210708-sql%E8%AE%A1%E7%AE%97iv/"},{"categories":["数据分析","机器学习"],"content":"3. 计算IV 回顾下公式 $$IV=\\sum_{i=1}^{n}(\\frac{Bad_i}{Bad_T} - \\frac{Good_i}{Good_T}) \\times WOE_i$$ 其中， $$WOE_i=\\ln(\\frac{Bad_i}{Bad_T}) - \\ln(\\frac{Good_i}{Good_T})$$ select ym ,score ,sum(iv_i) as iv from( select ym ,score ,score_group ,(ln(group_bad_i/group_bad_total)-ln(group_good_i/group_good_total))*(group_bad_i/group_bad_total - group_good_i/group_good_total) as iv_i from score_group_nums ) group by 1,2 ","date":"2021-07-08","objectID":"/2021/07/20210708-sql%E8%AE%A1%E7%AE%97iv/:4:3","tags":["Model","SQL"],"title":"SQL计算多个变量的IV","uri":"/2021/07/20210708-sql%E8%AE%A1%E7%AE%97iv/"},{"categories":["数据分析","机器学习"],"content":"总结 在非建模场景，只想大概看下（或监控）各变量的预测能力时，为省去导出数据用Python计算IV的麻烦，本文便以IV的计算公式出发详细记录SQL计算过程 ","date":"2021-07-08","objectID":"/2021/07/20210708-sql%E8%AE%A1%E7%AE%97iv/:5:0","tags":["Model","SQL"],"title":"SQL计算多个变量的IV","uri":"/2021/07/20210708-sql%E8%AE%A1%E7%AE%97iv/"},{"categories":["数据分析","机器学习"],"content":"RT，SQL批量计算各个模型分的PSI，更方便的搭建模型分稳定性的监控，满足模型应用的充分条件 — 样本分布一致性 ","date":"2021-06-18","objectID":"/2021/06/20210619-sql%E8%AE%A1%E7%AE%97psi/:0:0","tags":["Model","SQL","Python"],"title":"SQL计算多个模型分的PSI","uri":"/2021/06/20210619-sql%E8%AE%A1%E7%AE%97psi/"},{"categories":["数据分析","机器学习"],"content":"背景 应用模型的一大前提便是建模样本尽量和实际生产样本在分布上保持一致性，保证跨期层面的准确性 当模型分偏移到一定程度时，也该考虑迭代一版了 偏移程度可以用 PSI 这个指标来评价，而对于这个程度业界有个经验值1 PSI \u003c 0.1: no significant population change PSI \u003c 0.2: moderate population change PSI \u003e= 0.2: significant population change ","date":"2021-06-18","objectID":"/2021/06/20210619-sql%E8%AE%A1%E7%AE%97psi/:1:0","tags":["Model","SQL","Python"],"title":"SQL计算多个模型分的PSI","uri":"/2021/06/20210619-sql%E8%AE%A1%E7%AE%97psi/"},{"categories":["数据分析","机器学习"],"content":"计算公式 关于PSI的详细介绍，可参考我司模型大佬的这篇文章 具体计算公式如下 $$PSI=\\sum_{i=1}^{n}((Actual_i\\% - Expected_i\\%)\\times \\ln(\\frac{Actual_i\\%}{Expected_i\\%}))$$ n 为分箱的个数 $Actual_i\\%$ 表示第i个箱子的实际占比 $Expected_i\\%$ 表示第i个箱子的预期占比，（称其为比较的基准） ","date":"2021-06-18","objectID":"/2021/06/20210619-sql%E8%AE%A1%E7%AE%97psi/:2:0","tags":["Model","SQL","Python"],"title":"SQL计算多个模型分的PSI","uri":"/2021/06/20210619-sql%E8%AE%A1%E7%AE%97psi/"},{"categories":["数据分析","机器学习"],"content":"计算样例 以某一个模型分为例，计算跨期的psi bucket excepted_num except_rate actual_num actual_rate psi 1 26780 0.1010 31779 0.1359 0.01036 2 26355 0.0994 27439 0.1173 0.00298 3 26532 0.1000 26008 0.1112 0.00118 4 27416 0.1034 25816 0.1104 0.00046 5 26495 0.0999 24113 0.1031 0.00010 6 26588 0.1002 23146 0.0990 0.00002 7 25957 0.0979 21176 0.0905 0.00057 8 27530 0.1038 21442 0.0917 0.00150 9 25898 0.0976 18310 0.0783 0.00428 10 25710 0.0969 14682 0.0628 0.01484 以上例子最终得到 $PSI=\\sum_{i=1}^{10}(psi)=0.0362$ ","date":"2021-06-18","objectID":"/2021/06/20210619-sql%E8%AE%A1%E7%AE%97psi/:3:0","tags":["Model","SQL","Python"],"title":"SQL计算多个模型分的PSI","uri":"/2021/06/20210619-sql%E8%AE%A1%E7%AE%97psi/"},{"categories":["数据分析","机器学习"],"content":"SQL实现 我们希望得到的是从存有各个模型分的表（命名为 score）得到上图👆，score表样例如下 no week scoreA scoreB scoreC scoreD scoreE a1 9 617 481 773 671.68 561 a2 2 585 585 522 600.56 588 a3 16 617 548 677 635.68 563 a4 7 647 564 765 655.63 586 a5 12 596 478 656 635.3 586 a6 7 636 618 595 630 572 a7 22 714 572 842 644.28 563 a8 23 638 495 720 628.79 563 a9 3 636 618 595 426 526 a10 3 557 562 526 589 535 一行表示该用户对应的各种模型分数，scoreA…scoreE 其中， week 表示第几周，这里以2021年第一周（[2021-01-04,2021-01-10]）的数据作为基准，即 excepted 这里会涉及之前一些文章的知识点 窗口函数-聚合 窗口函数-排序 窗口函数的“窗口” 行转列、列转行 整体思路还是跟着 PSI 的计算公式走，按照某种方式（等频 / 等距）将基准的数据分成 n 箱子，基于基准数据的断点（Breakpoint Value）统计实际占比（$Actual$） 为了方便计算，先进行 列转行 ","date":"2021-06-18","objectID":"/2021/06/20210619-sql%E8%AE%A1%E7%AE%97psi/:4:0","tags":["Model","SQL","Python"],"title":"SQL计算多个模型分的PSI","uri":"/2021/06/20210619-sql%E8%AE%A1%E7%AE%97psi/"},{"categories":["数据分析","机器学习"],"content":"1. 列转行 将score表进行列转行，变为key-value 键值对的形式 drop table if exists score_value_weekly; create table score_value_weekly as select no ,week ,score ,score_value from( select no ,week ,score ,score_value from score lateral view explode(map('scoreA',scoreA,'scoreB',scoreB,'scoreC',scoreC,'scoreD',scoreD,'scoreE',scoreE)) t as score,score_value ) where score_value is not null and score_value not in ('null','NULL') ; ","date":"2021-06-18","objectID":"/2021/06/20210619-sql%E8%AE%A1%E7%AE%97psi/:4:1","tags":["Model","SQL","Python"],"title":"SQL计算多个模型分的PSI","uri":"/2021/06/20210619-sql%E8%AE%A1%E7%AE%97psi/"},{"categories":["数据分析","机器学习"],"content":"2. 基于基准数据统计各箱nums 这里就要分成两种情况： 等频分箱 等距分箱 具体使用哪种分箱方式还是要结合模型分的实际应用情况 但是，当模型分呈现较为严重的偏态分布时，等频分箱会出现好几个箱子重合的情况（如下图所示）。这种情况算出来的PSI会小于真实值，此时可以采用等距分箱 等频分箱 drop table if exists score_group_nums_weekly; create table score_group_nums_weekly as select score ,week ,score_group ,count(no) as nums from( select a.* ,case when a.score_value \u003c= r.score_array[0] then 'r1' when a.score_value \u003c= r.score_array[1] then 'r2' when a.score_value \u003c= r.score_array[2] then 'r3' when a.score_value \u003c= r.score_array[3] then 'r4' when a.score_value \u003c= r.score_array[4] then 'r5' when a.score_value \u003c= r.score_array[5] then 'r6' when a.score_value \u003c= r.score_array[6] then 'r7' when a.score_value \u003c= r.score_array[7] then 'r8' when a.score_value \u003c= r.score_array[8] then 'r9' when a.score_value \u003c= r.score_array[9] then 'r10' end as score_group from score_value_weekly a left join (-- 2. 等频分箱 select score ,percentile_approx(score_value,array(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1),99999) as score_array from score_value_weekly where week = 1 -- 以第一周为基准 group by 1 ) r on a.score = r.score ) group by 1,2,3 ; 等距分箱 等距分箱相比等频分箱而言稍微复杂点，我的思路是先算出基准数据各个模型分区间的上下限，再统计各箱nums -- 10个箱子 -- -- 统计各箱nums drop table if exists score_group_nums_weekly; create table score_group_nums_weekly as select score ,week ,n as score_group ,count(no) as nums from( select a.* ,r.n ,case when a.score_value \u003e= r.range_down and a.score_value \u003c r.range_up then 'Y' when a.score_value = r.range_up then 'Y' else 'N' end as is_range from score_value_weekly a left join (-- 基准月各分数间隔 select score ,n ,min_score ,max_score ,( min_score + (n-1) * step ) as range_down ,( min_score + n * step ) as range_up from( select a.* -- 10 箱 ,case when a.score_value=b.min_score then 1 else ceil( 10 * (a.score_value-b.min_score) / (b.max_score-b.min_score)) end as n ,b.min_score ,b.max_score ,b.step from( select * from score_value_weekly where week = 1 ) a left join ( select score ,min(score_value) as min_score ,max(score_value) as max_score -- 10 个箱子 ,( (max(score_value) - min(score_value)) / 10 ) as step from score_value_weekly where week = 1 group by 1 ) b on a.score = b.score ) group by 1,2,3,4,5,6 ) r on a.score = r.score ) where is_range = 'Y' group by 1,2,3 ; ","date":"2021-06-18","objectID":"/2021/06/20210619-sql%E8%AE%A1%E7%AE%97psi/:4:2","tags":["Model","SQL","Python"],"title":"SQL计算多个模型分的PSI","uri":"/2021/06/20210619-sql%E8%AE%A1%E7%AE%97psi/"},{"categories":["数据分析","机器学习"],"content":"3. 计算PSI 回顾下公式 $$PSI=\\sum_{i=1}^{n}((Actual_i\\% - Expected_i\\%)\\times \\ln(\\frac{Actual_i\\%}{Expected_i\\%}))$$ drop table if exists score_stability_result_weekly; create table score_stability_result_weekly as select a.* ,b.psi from(-- 各箱nums select score ,week ,score_group_value[\"r1\"] as r1 ,score_group_value[\"r2\"] as r2 ,score_group_value[\"r3\"] as r3 ,score_group_value[\"r4\"] as r4 ,score_group_value[\"r5\"] as r5 ,score_group_value[\"r6\"] as r6 ,score_group_value[\"r7\"] as r7 ,score_group_value[\"r8\"] as r8 ,score_group_value[\"r9\"] as r9 ,score_group_value[\"r10\"] as r10 from(-- 行转列 select score ,week ,str_to_map(concat_ws(',', collect_set(concat_ws(':', score_group, nums)))) as score_group_value from score_group_nums_weekly group by 1,2 ) ) a left join (-- psi select f.score ,f.week ,sum( (f.act_rate-b.exp_rate)*log(f.act_rate/b.exp_rate) ) as psi from(-- Actual select score ,week ,score_group ,( nums / sum(nums) over(partition by score,week) ) as act_rate from score_group_nums_weekly where week \u003e 1 ) f left join (-- Excepted select score ,week ,score_group ,( nums / sum(nums) over(partition by score,week) ) as exp_rate from score_group_nums_weekly where week = 1 ) b on (f.score = b.score and f.score_group = b.score_group) where f.score_group is not null and f.score_group not in ('null','NULL') group by 1,2 ) b on (a.score = b.score and a.week = b.week) ; ","date":"2021-06-18","objectID":"/2021/06/20210619-sql%E8%AE%A1%E7%AE%97psi/:4:3","tags":["Model","SQL","Python"],"title":"SQL计算多个模型分的PSI","uri":"/2021/06/20210619-sql%E8%AE%A1%E7%AE%97psi/"},{"categories":["数据分析","机器学习"],"content":"可视化 最后，可以用Excel或BI软件完成对应的可视化 本文选择的是面积图 Python代码示例2 👇 # libraries import numpy as np import matplotlib.pyplot as plt import seaborn as sns import pandas as pd # Make data data = pd.DataFrame({ 'group_A':[1,4,6,8,9], 'group_B':[2,24,7,10,12], 'group_C':[2,8,5,10,6], }, index=range(1,6)) # We need to transform the data from raw data to percentage (fraction) data_perc = data.divide(data.sum(axis=1), axis=0) # Make the plot plt.stackplot(range(1,6), data_perc[\"group_A\"], data_perc[\"group_B\"], data_perc[\"group_C\"], labels=['A','B','C']) plt.legend(loc='upper left') plt.margins(0,0) plt.title('100 % stacked area chart') plt.show() area chart ","date":"2021-06-18","objectID":"/2021/06/20210619-sql%E8%AE%A1%E7%AE%97psi/:5:0","tags":["Model","SQL","Python"],"title":"SQL计算多个模型分的PSI","uri":"/2021/06/20210619-sql%E8%AE%A1%E7%AE%97psi/"},{"categories":["数据分析","机器学习"],"content":"总结 本文主要是提供了通过SQL计算多个模型分PSI的方案，并采用了等频、等距分箱两种分箱方法，增加了适用性 ","date":"2021-06-18","objectID":"/2021/06/20210619-sql%E8%AE%A1%E7%AE%97psi/:6:0","tags":["Model","SQL","Python"],"title":"SQL计算多个模型分的PSI","uri":"/2021/06/20210619-sql%E8%AE%A1%E7%AE%97psi/"},{"categories":["数据分析","机器学习"],"content":"Reference https://mwburke.github.io/data%20science/2018/04/29/population-stability-index.html ↩︎ https://www.python-graph-gallery.com/255-percentage-stacked-area-chart ↩︎ ","date":"2021-06-18","objectID":"/2021/06/20210619-sql%E8%AE%A1%E7%AE%97psi/:7:0","tags":["Model","SQL","Python"],"title":"SQL计算多个模型分的PSI","uri":"/2021/06/20210619-sql%E8%AE%A1%E7%AE%97psi/"},{"categories":["数据分析"],"content":"SQL, Python 中解决行转列、列转行的问题 在日常工作中总会遇到类似下图中的问题 👇 我把这种情况称为 行转列 《Python for Data Analysis》 书中将其称为 Pivoting “Wide” to “Long” Format 还有这种问题 👇 我把这种情况称为 列转行 《Python for Data Analysis》 书中将其称为 Pivoting “Long” to “Wide” Format 那么，接下来将针对此类问题，汇总SQL、Python中的实现方式 ","date":"2021-06-15","objectID":"/2021/06/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/:0:0","tags":["SQL","Python"],"title":"行转列、列转行","uri":"/2021/06/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/"},{"categories":["数据分析"],"content":"行转列 / “Wide” to “Long” ","date":"2021-06-15","objectID":"/2021/06/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/:1:0","tags":["SQL","Python"],"title":"行转列、列转行","uri":"/2021/06/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/"},{"categories":["数据分析"],"content":"SQL 基于 spark-2.4.5U3 及以上版本 select score ,ym ,score_group_value[\"r1\"] as r1 ,score_group_value[\"r2\"] as r2 ,score_group_value[\"r3\"] as r3 from ( select score ,ym ,str_to_map(concat_ws(',', collect_set(concat_ws(':', range_label, nums)))) as score_group_value from score_group_nums group by 1,2 ) 基本思路是将表中 range_label和nums转化为类似json的格式，之后通过 key 索引得到对应的value 这里用的是collect_set()，得到的是聚合、去重后无序的array，若需要有序则可用sort_array() ","date":"2021-06-15","objectID":"/2021/06/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/:1:1","tags":["SQL","Python"],"title":"行转列、列转行","uri":"/2021/06/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/"},{"categories":["数据分析"],"content":"Python 构造数据 df_wide = pd.DataFrame({'score_name': ['ScoreA']*3 ,'ym': ['202012']*3 ,'range_label': ['r1','r2','r3'] ,'nums': [1110,1105,1054]}) df_wide pivot() 函数 df_wide.pivot(index=['score_name','ym'] ,columns='range_label' ,values=['nums']) ","date":"2021-06-15","objectID":"/2021/06/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/:1:2","tags":["SQL","Python"],"title":"行转列、列转行","uri":"/2021/06/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/"},{"categories":["数据分析"],"content":"列转行 / “Long” to “Wide” ","date":"2021-06-15","objectID":"/2021/06/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/:2:0","tags":["SQL","Python"],"title":"行转列、列转行","uri":"/2021/06/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/"},{"categories":["数据分析"],"content":"SQL 基于 spark-2.4.5U3 及以上版本 select biz_no ,ym ,range_label ,nums from score lateral view outer explode(map('r1',r1,'r2',r2,'r3',r3)) t as range_label,nums map 之后，结合 lateral view explode1 实现列转行的问题 ","date":"2021-06-15","objectID":"/2021/06/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/:2:1","tags":["SQL","Python"],"title":"行转列、列转行","uri":"/2021/06/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/"},{"categories":["数据分析"],"content":"Python 构造数据 df_long = pd.DataFrame({'score_name': ['ScoreA'] ,'ym': ['202012'] ,'r1': [1110] ,'r2': [1105] ,'r3':[1054]}) df_long stack()函数 df_long.set_index(['score_name','ym']).stack(dropna=False).reset_index().rename(columns={\"level_2\": \"range_label\",0:\"nums\"}) ","date":"2021-06-15","objectID":"/2021/06/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/:2:2","tags":["SQL","Python"],"title":"行转列、列转行","uri":"/2021/06/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/"},{"categories":["数据分析"],"content":"Reference https://blog.csdn.net/oopsoom/article/details/26001307 ↩︎ ","date":"2021-06-15","objectID":"/2021/06/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/:3:0","tags":["SQL","Python"],"title":"行转列、列转行","uri":"/2021/06/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/"},{"categories":["数据分析"],"content":"以官方例子：微博转发关系图为例，说明所需要的数据格式 ","date":"2021-06-07","objectID":"/2021/06/20210607-%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%85%B3%E7%B3%BB%E5%9B%BE/:0:0","tags":["可视化","pyecharts","Python"],"title":"pyecharts-关系图","uri":"/2021/06/20210607-%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%85%B3%E7%B3%BB%E5%9B%BE/"},{"categories":["数据分析"],"content":"数据样例 import json from pyecharts import options as opts from pyecharts.charts import Graph with open(\"weibo.json\", \"r\", encoding=\"utf-8\") as f: j = json.load(f) nodes, links, categories, cont, mid, userl = j c = ( Graph(init_opts=opts.InitOpts(width=\"1920px\" ,height=\"1080px\")) .add( \"\", nodes, links, categories, repulsion=900, # 节点之间的斥力因子。值越大则斥力越大 # 支持设置成数组表达斥力的范围，此时不同大小的值会线性映射到不同的斥力。 gravity=0.01, # 节点受到的向中心的引力因子。该值越大节点越往中心点靠拢。 linestyle_opts=opts.LineStyleOpts(curve=0.2), label_opts=opts.LabelOpts(is_show=False), ) .set_global_opts( legend_opts=opts.LegendOpts(is_show=False), title_opts=opts.TitleOpts(title=\"Graph-微博转发关系图\"), ) .render(\"graph_weibo.html\") ) weibo.json 文件，可从 这儿 获取 主要由5部分组成 nodes links categories cont mid userl ","date":"2021-06-07","objectID":"/2021/06/20210607-%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%85%B3%E7%B3%BB%E5%9B%BE/:1:0","tags":["可视化","pyecharts","Python"],"title":"pyecharts-关系图","uri":"/2021/06/20210607-%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%85%B3%E7%B3%BB%E5%9B%BE/"},{"categories":["数据分析"],"content":"格式说明 本文聚焦在前三个的数据格式说明。每一部分是个list，每个list 又由多个dict组成 以“转发微博”作为场景简单阐述关系图所展示的信息：某位具有影响力的微博用户A 发了条微博，被用户B、C、D看到并转发了；之后，用户E、F、G也转发了B所转发的这篇文章，以此类推 那么，这个过程中涉及到的每个用户便是一个node。为此，也以 nodes作为切入点展开说明 ","date":"2021-06-07","objectID":"/2021/06/20210607-%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%85%B3%E7%B3%BB%E5%9B%BE/:2:0","tags":["可视化","pyecharts","Python"],"title":"pyecharts-关系图","uri":"/2021/06/20210607-%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%85%B3%E7%B3%BB%E5%9B%BE/"},{"categories":["数据分析"],"content":"nodes 样例如下所示， 记录着节点的信息12， { \"name\": \"Camel3942\", # 节点名称，即博主昵称 \"symbolSize\": 5, # 图中标志大小 \"draggable\": \"False\", # 是否可拖动 \"value\": 1, # 被再次转发次数 \"category\": \"Camel3942\", # From Where \"label\": { # 此博主被再次转发后，含有此标签，否则不含 \"normal\": { \"show\": \"True\" } } } 节点名称（name）不能重复 ","date":"2021-06-07","objectID":"/2021/06/20210607-%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%85%B3%E7%B3%BB%E5%9B%BE/:2:1","tags":["可视化","pyecharts","Python"],"title":"pyecharts-关系图","uri":"/2021/06/20210607-%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%85%B3%E7%B3%BB%E5%9B%BE/"},{"categories":["数据分析"],"content":"links 个人理解作用是将每个node 连接起来 { \"source\": \"新浪体育\", \"target\": \"Beijingold4\" }, { \"source\": \"Camel3942\", \"target\": \"xiaoA\" } ","date":"2021-06-07","objectID":"/2021/06/20210607-%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%85%B3%E7%B3%BB%E5%9B%BE/:2:2","tags":["可视化","pyecharts","Python"],"title":"pyecharts-关系图","uri":"/2021/06/20210607-%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%85%B3%E7%B3%BB%E5%9B%BE/"},{"categories":["数据分析"],"content":"categories 而这部分则记录着有被他人转发的用户名称（name），即 links 中 source 所对应的内容 { \"name\": \"新浪体育\" }, { \"name\": \"Camel3942\" } ","date":"2021-06-07","objectID":"/2021/06/20210607-%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%85%B3%E7%B3%BB%E5%9B%BE/:2:3","tags":["可视化","pyecharts","Python"],"title":"pyecharts-关系图","uri":"/2021/06/20210607-%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%85%B3%E7%B3%BB%E5%9B%BE/"},{"categories":["数据分析"],"content":"Reference https://blog.csdn.net/qq_35006861/article/details/116721589 ↩︎ https://blog.csdn.net/Kevin_HZH/article/details/91043392 ↩︎ ","date":"2021-06-07","objectID":"/2021/06/20210607-%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%85%B3%E7%B3%BB%E5%9B%BE/:3:0","tags":["可视化","pyecharts","Python"],"title":"pyecharts-关系图","uri":"/2021/06/20210607-%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%85%B3%E7%B3%BB%E5%9B%BE/"},{"categories":["写作"],"content":"详述Hugo+Github搭建个人博客 受我司同期大佬的影响，我也便搭建个人博客折腾下，记录点什么~ 在这demo成型之际，以小白视角记录下基于 HuGo 和 Github 完成搭建的历程 所以，最初的准备工作便是（假设已安装Git） ","date":"2021-05-28","objectID":"/2021/05/20210528-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/:0:0","tags":["blog"],"title":"GitHub+Hugo快速搭建个人博客","uri":"/2021/05/20210528-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"categories":["写作"],"content":"安装 Hugo 可以参考官方文档完成在Windows, Mac等平台的安装 虽然HuGo是基于Go语言编写的，但并不是一定要安装Go才能使用HuGo。可跨平台 在此，以 Windows 系统为例记录安装过程 在这儿下载对应的压缩包 解压 hugo_0.83.1_Windows-64bit.zip解压后得到的文件如下图所示 添加至环境变量 将hugo.exe文件放入bin文件夹（若无可新建） 验证是否安装成功 hugo version # hugo v0.83.1-5AFE0A57 windows/amd64 BuildDate=2021-05-02T14:38:05Z VendorInfo=gohugoio 本地创建博客 终端 cd 至某个文件下 hugo new site unclehuzi # blog目录就是创建的博客目录 # Congratulations! Your new Hugo site is created in D:\\unclehuzi. # Just a few more steps and you're ready to go: # 1. Download a theme into the same-named folder. # Choose a theme from https://themes.gohugo.io/ or # create your own with the \"hugo new theme \u003cTHEMENAME\u003e\" command. # 2. Perhaps you want to add some content. You can add single files # with \"hugo new \u003cSECTIONNAME\u003e\\\u003cFILENAME\u003e.\u003cFORMAT\u003e\". # 3. Start the built-in live server via \"hugo server\". # Visit https://gohugo.io/ for quickstart guide and full documentation. tree unclehuzi/ ##### D:\\unclehuzi ├─archetypes ├─content # 博客文章存放目录（markdown文件） ├─data ├─layouts ├─static # 静态文件/图片/CSS/JS文件 ├─themes # 博客主题模板存放目录 └─config.toml # 博客的配置文件 选择主题 我选择的是 Maupassant，通过Git 的方式获取 # cd 至 unclehuzi 文件夹 git clone https://github.com/flysnow-org/maupassant-hugo themes/maupassant cp themes/maupassant/exampleSite/config.toml . # 使用模板自带的配置文件替换默认配置文件 mkdir content/post # 创建博客文章md文件存放路径（该主题模板要求放在content/post目录下） 根据需要调整 D:\\unclehuzi\\config.toml 文件 baseURL = \"your_github_name.github.io\" # 修改为博客的网址，此处使用github pages地址，后面具体介绍 languageCode = \"zh-CN\" title = \"胡子叔叔的小站\" # 博客的名字 theme = \"maupassant\" 具体可以参考 官方说明 进行配置 本地测试 # cd D:\\unclehuzi hugo new post/my-first-blog.md vim content/post/my-first-blog.md # 以下为md文件内容 +++ title=\"My First Blog\" tags=[\"blog\"] categories=[\"博客相关\"] date=2020-01-16T10:37:32+08:00 draft=false # 此处要改为false，否则在首页不会显示！ +++ #### Hello World! 通过 hugo server -D 命令启动，访问 http://localhost:1313/ 即可 ","date":"2021-05-28","objectID":"/2021/05/20210528-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/:1:0","tags":["blog"],"title":"GitHub+Hugo快速搭建个人博客","uri":"/2021/05/20210528-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"categories":["写作"],"content":"建立博客专属的仓库 主要的事情说三遍： Repository name 填 github名字.github.io，如 unclehuzi.github.io Repository name 填 github名字.github.io，如 unclehuzi.github.io Repository name 填 github名字.github.io，如 unclehuzi.github.io 仓库创建完成之后记得修改 D:\\unclehuzi\\config.toml 文件的 baseURL ","date":"2021-05-28","objectID":"/2021/05/20210528-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/:2:0","tags":["blog"],"title":"GitHub+Hugo快速搭建个人博客","uri":"/2021/05/20210528-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"categories":["写作"],"content":"生成 public 文件 创建完成之后，通过 hugo 生成 public 文件 hugo --theme=maupassant --baseUrl=\"https://your_github_name.github.io\" # theme为主题模板名称，url为上一步创建的github仓库名称 ","date":"2021-05-28","objectID":"/2021/05/20210528-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/:2:1","tags":["blog"],"title":"GitHub+Hugo快速搭建个人博客","uri":"/2021/05/20210528-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"categories":["写作"],"content":"通过 git 命令将 public 文件推送至仓库 cd D:\\unclehuzi\\public # 1. 初始化 git init # 2. 将文件夹下所有文件加入本地仓库 git add . # 3. 添加注释 git commit -m \"comments\" # git commit -m \"updates $(date)\" # 4. 建立连接 BY HTTPS git remote add origin https://github.com/unclehuzi/unclehuzi.github.io.git # 5. 远程仓库拉到本地（如果远程仓库内没有文件可跳过步骤5） git pull --rebase origin master # 之后更新本地： git pull origin master # 6. 上传 push git push -u origin master # git push -u origin master -f # 强制上传 # 备注 # 和远程建立连接之后，执行 2-3-6 步骤即可。 最后，访问 https://your_github_name.github.io 即可 ","date":"2021-05-28","objectID":"/2021/05/20210528-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/:2:2","tags":["blog"],"title":"GitHub+Hugo快速搭建个人博客","uri":"/2021/05/20210528-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"categories":["写作"],"content":"总结 本文基于 Github Pages 服务，使用成熟的框架及主题快速搭建个人博客demo。 更新网站两步走： 在博客文件夹（D:\\unclehuzi）下生成 public 文件夹 将 public 文件夹内的所有文件推送至GitHub仓库 后续在网站设计方面还需要了解下Web开发相关知识，针对性的修改主题的源码以实现自己的需求~ ","date":"2021-05-28","objectID":"/2021/05/20210528-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/:3:0","tags":["blog"],"title":"GitHub+Hugo快速搭建个人博客","uri":"/2021/05/20210528-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"不打羽毛球、不写代码的骑行人不是一名好分析师","date":"2021-05-28","objectID":"/about/","tags":null,"title":"CV","uri":"/about/"},{"categories":null,"content":"工作经历 ","date":"2021-05-28","objectID":"/about/:1:0","tags":null,"title":"CV","uri":"/about/"},{"categories":null,"content":"中原消金 2023年05月23日 至今 希望事情能搞好~许愿~ ","date":"2021-05-28","objectID":"/about/:1:1","tags":null,"title":"CV","uri":"/about/"},{"categories":null,"content":"360数科 2020年06月16日~2023年05月22日 思维层面 🤔 💫 （直接/间接）抽象职场通用 skills 🤺 理论指导实践，如 客群划分 技术层面 👨‍💻 精进SQL（Spark、Hive），如 sql计算PSI sql计算IV 快、准、狠 🏃 🏃‍♂️ 数据建模 试图做一个从理论出发的的“调包侠” ","date":"2021-05-28","objectID":"/about/:1:2","tags":null,"title":"CV","uri":"/about/"},{"categories":null,"content":"实习经历 在 数据分析 这条路上的探索，“一顿操作”（实习）之后得到的主要结论（/经验）： 👇 数据分析依托于行业 / 场景，但更加需要基于某个行业抽象出复用的部分； 基于1，一定要把 数据分析 单拎出来的话，更像是中台赋能的味道（或者说“乙方”）； 公司内对数据的重视程度决定了数分的地位（或者说数分的负责人是否能“话事”），否则就是 “SQL-boy”。 资源的重要性往往远远大于能力。公司存活与发展靠的是制度，并非个人英雄主义～ 正是因为这一层特性，除了 “big boss”，没有人是不可替代的。真的到了一定程度，“big boss” 也是可以换的 业务、技术加点方向可以围绕价值链进行：从数据的产生 👉 存储 👉 离线分析与挖掘 👉 反哺。其实各个阶段都需要面向业务，如，存储阶段中数仓的主题域 行业 公司 岗位 主要干啥 收获了啥 互联网 哈啰出行 🚴‍♀️ 数据分析 对接UI、运营的需求 指标体系；用户转化（/迁移）；Presto、Hive 房地产 旭辉 市场研究 经济政策、微观行为 量化指标；逻辑至上、数据支撑 咨询 Teradata 数据分析与挖掘 骚扰电话特征挖掘 分析思路；框架先行 汽车 通用·GM China 市场研究 数据基建、数据管理 VBA、SQL；经济学思维启蒙 融资租赁 开心汽车 数据分析 盘借贷逾期的逻辑 要面向业务逻辑写SQL ","date":"2021-05-28","objectID":"/about/:2:0","tags":null,"title":"CV","uri":"/about/"},{"categories":null,"content":"研究经历 矛盾性追加评论对感知有用性及购买意愿的影响研究 最初是用京东的评论写了个小论文，水了个会议。 硕士毕业论文时，主要从 数据源（一手问卷和二手电商平台评论数据）和 模型（零膨胀计数模型）两个维度更近了一步。 虽然一顿操作猛如虎，一看结论真是虎～ 但是，整个过程就像自己 owner 一个项目，从0到1、一步一步推进 💃、精准打击 👊 各个困难点～ 无论是为了满足会议的时间截止时间还是毕业论文阶段的各个节点，都让我离“时间管理大师”更近了一步 😄 当然，除了时间管理、项目管理，还有学习能力。即，需要在短时间内掌握相关知识以解决相应的问题。 爬虫 情感二分类 研究方法论 中介、调节以及有调节的中介效应分析 R语言 。。。 ","date":"2021-05-28","objectID":"/about/:3:0","tags":null,"title":"CV","uri":"/about/"},{"categories":null,"content":"平时干些啥 ","date":"2021-05-28","objectID":"/about/:4:0","tags":null,"title":"CV","uri":"/about/"},{"categories":null,"content":"羽毛球 🏸️ 平时（主要是周末）也会在下面俩地方打羽毛球 🏸 虽然技术不咋地，但就是玩~约球~ 上海市浦东新区羽山路1200号(近崮山路) 上海市浦东新区杨高中路2100号七位数体育培训园 上海市浦东新区峨山路91弄140号同学汇综合运动馆 ","date":"2021-05-28","objectID":"/about/:4:1","tags":null,"title":"CV","uri":"/about/"},{"categories":null,"content":"游戏 🎮 领略“海拉鲁大陆”的风光，看心情拯救公主 👸 ","date":"2021-05-28","objectID":"/about/:4:2","tags":null,"title":"CV","uri":"/about/"},{"categories":null,"content":"写文章 该个人博客便是个例子，以及我的个人公众号 ~欢迎关注一波~ ","date":"2021-05-28","objectID":"/about/:4:3","tags":null,"title":"CV","uri":"/about/"},{"categories":["数据分析"],"content":"分场景汇总日期函数 工作中总会遇到处理时间的问题，参考营销理论中基于利益细分的市场细分理论，我从使用场景的角度出发，将常用的日期函数分为四大类： 时间计算 时间提取 格式转换 当前时间 本文重点在于整合日期函数 ","date":"2021-05-20","objectID":"/2021/05/hql-%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0/:0:0","tags":["SQL"],"title":"Spark, Hive QL-日期函数汇总","uri":"/2021/05/hql-%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0/"},{"categories":["数据分析"],"content":"时间计算 这部分主要是计算时间差（datediff(end_date,start_date), months_between(date1,date2)）、时间加减（date_add(),date_sub(),add_months()）等 ","date":"2021-05-20","objectID":"/2021/05/hql-%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0/:1:0","tags":["SQL"],"title":"Spark, Hive QL-日期函数汇总","uri":"/2021/05/hql-%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0/"},{"categories":["数据分析"],"content":"时间提取 提取时间戳的年、季度、月、周、日、小时、分钟、秒 可以直接调用对应的函数，也可使用extract(field from column_name) 函数指定 field，其中field 支持day, dayofweek, hour, minute, month, quarter, second, week and year. ","date":"2021-05-20","objectID":"/2021/05/hql-%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0/:2:0","tags":["SQL"],"title":"Spark, Hive QL-日期函数汇总","uri":"/2021/05/hql-%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0/"},{"categories":["数据分析"],"content":"格式转换 有时为了适应不同时间格式的需求，需要做个转换，如yyyy-MM-dd 或 yyyy-MM-dd HH:mm:ss的形式转为yyyyMMdd 等 常用： to_date() 返回 date 形式的日期，即yyyy-MM-dd date_format() 转为指定格式的时间，如 date_format('2015-04-08','y') =\u003e '2015' ","date":"2021-05-20","objectID":"/2021/05/hql-%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0/:3:0","tags":["SQL"],"title":"Spark, Hive QL-日期函数汇总","uri":"/2021/05/hql-%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0/"},{"categories":["数据分析"],"content":"当前时间 若需要时间戳格式，则用current_timestamp 若只需要精确到天，即date格式，则用current_date ","date":"2021-05-20","objectID":"/2021/05/hql-%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0/:4:0","tags":["SQL"],"title":"Spark, Hive QL-日期函数汇总","uri":"/2021/05/hql-%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0/"},{"categories":["数据分析"],"content":"总结 本文重点在于从使用场景的角度出发，整合了hive, spark 环境下常用的日期函数。最后再以表格的形式简单汇总 场景 函数 返回值类型 描述 示例 当前时间 unix_timestamp() bigint 当前 Unix时间戳（e.g. 1622451519 ），但因查询优化问题推荐使用 current_timestamp 当前时间 current_date date 当前日期 2021-05-31 当前时间 current_timestamp timestamp 当前时间戳 2021-05-31 17:12:14.968 - - - - - 格式转换 from_unixtime(bigint unixtime[, string format]) string 数字转为格式形如 2021-05-31 17:12:14 的字符串 格式转换 to_date(string timestamp) date to_date(yyyy-MM-dd HH:mm:ss) =\u003e yyyy-MM-dd 格式转换 date_format(date/timestamp/string ts, string fmt) string 得到指定格式的时间 date_format(‘2015-04-08’, ‘y’) =\u003e ‘2015’ 格式转换 trunc(string date, string format) string 得到被指定format截断的日期，format支持MONTH/MON/MM, YEAR/YYYY/YY trunc(‘2015-03-17’, ‘MM’) =\u003e 2015-03-01 - - - - - 时间提取 year(string date) int 年 时间提取 quarter(date/timestamp/string) int 季度 时间提取 weekofyear(string date) int 该年的第几周 时间提取 month(string date) int 月 时间提取 day(string date) dayofmonth(date) int 日 时间提取 hour(string date) int 小时 时间提取 minute(string date) int 分钟 时间提取 second(string date) int 秒 时间提取 extract(field FROM source) int field 支持day, dayofweek, hour, minute, month, quarter, second, week and year. - - - - - 时间计算 datediff(string enddate, string startdate) int 天数差 datediff(‘2009-03-01’, ‘2009-02-27’) =\u003e 2 时间计算 date_add(date/timestamp/string startdate, tinyint/smallint/int days) date 加（减）x天后的日期 date_add(‘2008-12-31’, 1) =\u003e 2009-01-01, date_add(‘2008-12-31’, -1) =\u003e 2008-12-30 时间计算 date_sub(date/timestamp/string startdate, tinyint/smallint/int days) date 加（减）x天后的日期 date_sub(‘2008-12-31’, 1) =\u003e 2008-12-30, date_sub(‘2008-12-31’, -1) =\u003e 2009-01-01 时间计算 add_months(string start_date, int num_months, output_date_format) string x月后。如果start_date是该月的最后一天 或者 x月后的天数不是“大月”则结果为x月后该月的最后一天 add_months(‘2017-12-31 14:15:16’, 2, ‘YYYY-MM-dd HH:mm:ss’) =\u003e ‘2018-02-28 14:15:16’ 时间计算 last_day(string date) string 该月最后一天的日期 last_day(2021-05-11) =\u003e ‘2021-05-31’ 时间计算 next_day(string start_date, string day_of_week) string 返回大于 start_date 的日期中最近的一个周x next_day(‘2021-05-31’,‘Monday’) 时间计算 months_between(date1, date2) double date1-date2 月数差 months_between(‘1997-02-28 10:30:00’, ‘1996-10-30’) =\u003e 3.94959677 ","date":"2021-05-20","objectID":"/2021/05/hql-%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0/:5:0","tags":["SQL"],"title":"Spark, Hive QL-日期函数汇总","uri":"/2021/05/hql-%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0/"},{"categories":["数据分析"],"content":"以 “计算当前和上一次事件的时间间隔” 引入 positional function 截止到目前，窗口函数整理了聚合、排序场景，解决了“组内占比”、“定位连续3天登录用户”等问题 在平时的分析工作中，还有个比较常见的问题：计算当前和上一次事件的时间间隔。比如，相邻两次外呼的时间间隔 这个时候，lead() 或 lag() 函数可较为方便的解决该类问题 ","date":"2021-05-10","objectID":"/2021/05/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-positionalfunctions/:0:0","tags":["SQL"],"title":"窗口函数-Positional Functions","uri":"/2021/05/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-positionalfunctions/"},{"categories":["数据分析"],"content":"实现的功能 lead(), lag() 实现的功能比较类似。 ","date":"2021-05-10","objectID":"/2021/05/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-positionalfunctions/:1:0","tags":["SQL"],"title":"窗口函数-Positional Functions","uri":"/2021/05/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-positionalfunctions/"},{"categories":["数据分析"],"content":"lead() 上移 select seller_name ,sale_value ,lead(sale_value) over(order by sale_value) as next_sale_value from sale ; ","date":"2021-05-10","objectID":"/2021/05/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-positionalfunctions/:1:1","tags":["SQL"],"title":"窗口函数-Positional Functions","uri":"/2021/05/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-positionalfunctions/"},{"categories":["数据分析"],"content":"lag() 下移 select seller_name ,sale_value ,lag(sale_value) over(order by sale_value) as previous_sale_value from sale ; ","date":"2021-05-10","objectID":"/2021/05/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-positionalfunctions/:1:2","tags":["SQL"],"title":"窗口函数-Positional Functions","uri":"/2021/05/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-positionalfunctions/"},{"categories":["数据分析"],"content":"基本语法 lag(expression [,offset[,default_value]]) over([partition by expr1, expr2, ...] order by expr1 [asc|desc], expr2 [asc|desc], ... ) lead(expression [,offset[,default_value]]) over([partition by expr1, expr2, ...] order by expr1 [asc|desc], expr2 [asc|desc], ... ) lead(), lag() 中的3个参数： expression - string 被操作的列名 offset - int 移动的行数（/偏移量） default_value 定义为空的情况赋给的默认值 其中，参数 expression 是必须的。而 default_value（默认是 NULL） 是只有当 offset（默认是 1） 有值时才能使用 over() 语句中，order by 是必须要有的 ","date":"2021-05-10","objectID":"/2021/05/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-positionalfunctions/:2:0","tags":["SQL"],"title":"窗口函数-Positional Functions","uri":"/2021/05/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-positionalfunctions/"},{"categories":["数据分析"],"content":"应用 计算用户相邻两次登录的天数间隔 -- 如果只有1天有登录信息，则 diff_days 为 null select * ,datediff(session_date,lag_session_date) as diff_days from(-- 下移 select * ,lag(session_date) over(partition by user_id order by session_date asc) as lag_session_date from( -- 按天去重 select user_id ,date_format(session_time,'yyyy-MM-dd') as session_date from table1 group by 1,2 ) ) ; 窗口函数还有俩常见的：first_value(), last_value()，在此就略过了。 有时候可以用 row_number() over() 结合 having 一起使用，如 确定用户最后一次登录时间 select user_id ,row_number() over(order by session_date desc) as rk from table1 having rk = 1 ; ","date":"2021-05-10","objectID":"/2021/05/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-positionalfunctions/:3:0","tags":["SQL"],"title":"窗口函数-Positional Functions","uri":"/2021/05/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-positionalfunctions/"},{"categories":["数据分析"],"content":"详述“窗口”的概念，结合初中数学中区间的概念来理解\u003cwindow_frame\u003e，并以计算累计占比为例深化理解。此外，也分享了他人整理的窗口函数汇总表 基于之前整理的 排序 聚合 Positional functions: lead(), lag() 在窗口函数应用场景方面算是告一段落了。但是在 “窗口” 这个概念上陈述较少，在窗口函数部分的里程碑之际重新 “定义” “窗口” 另外，之前在浏览网页的时候发现了窗口函数的汇总图 而本文与图中对应的便是 WINDOW FAME 部分 ","date":"2021-04-30","objectID":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E7%AA%97%E5%8F%A3/:0:0","tags":["SQL"],"title":"窗口函数的“窗口”","uri":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E7%AA%97%E5%8F%A3/"},{"categories":["数据分析"],"content":"实现的功能 简单来说是定义窗口函数作用的范围（“FRAME”），通过下面这张图1可以更好的了解 FRAME 的概念 一般而言， 一张表（Table）基于WHERE条件的作用得到图中 Result Set 部分； 窗口函数 over() 语句中 partition（若有）得到图中 Partition 1…Partition m fram 语句（若有）在partition基础上得到图中 Frame 1…Frame n ","date":"2021-04-30","objectID":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E7%AA%97%E5%8F%A3/:1:0","tags":["SQL"],"title":"窗口函数的“窗口”","uri":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E7%AA%97%E5%8F%A3/"},{"categories":["数据分析"],"content":"语法、规则 \u003cwindow_frame\u003e := [rows | range | groups ] between [ unbounded preceding | \u003cn\u003e preceding | current row ] and [ unbounded following | \u003cn\u003e following | current row ] 目前，只有 PostgreSQL 11 及以上版本支持 groups \u003cwindow_frame\u003e语句表明，相对于当前行（current row）对应的值而言，还有“区间”的概念，“区间”又受到 rows或range 控制：是行数范围还是值的范围。 rows 对应是行的条件 如rows between 1 preceding and unbounded following 表示最终的范围是排序后（若有），基于当前行的上 1 行和该partition本身的最后一行 range 对应是值的范围 如range between 1 preceding and 2 following 这里我们遵循小学数学中区间的性质：左区间的值小于等于右区间的值 因为涉及到值的范围，这里就要分两种情况讨论了，假设当前行对应的值为 x 顺序排序，即从小到大，order by column asc [x-1,x+2]，左区间为当前行的值减1（x-1）；右区间为当前行的值加2（x+2） 逆序排序，即从大到小，order by column desc [x-2,x+1]，左区间为当前行的值减2（x-2）；右区间为当前行的值加1（x+1） 最后再说明下没有 \u003cwindow_frame\u003e 语句时对应的Frame，此时将取决于是否有order by语句，即 无 \u003cwindow_frame\u003e 语句、有 order by 语句 Frame 为 range between unbounded preceding and current row 即Frame的第一行为该partition的上边界，当前行（current row）为下边界 无 \u003cwindow_frame\u003e 语句、无 order by 语句 Frame 为 rows between unbounded preceding and unbounded following 即Frame的边界就是partition的边界 关于，无\u003cwindow_frame\u003e语句的情况，总结如下 \\ 无 \u003cwindow_frame\u003e 有 order by rows between unbounded preceding and current row 无 order by rows between unbounded preceding and unbounded following ","date":"2021-04-30","objectID":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E7%AA%97%E5%8F%A3/:2:0","tags":["SQL"],"title":"窗口函数的“窗口”","uri":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E7%AA%97%E5%8F%A3/"},{"categories":["数据分析"],"content":"应用：一个例子 一堆枯涩的陈述，不如直接来个小例子：计算累计占比 实际业务中，在定义模型目标变量y的时候，往往也会结合数据的分布。如，风控场景中定义逾期 x 天以上为bad 假设samples 表中记录着一笔订单的逾期状态，over_due_days 表示逾期天数 希望得到的数据样式如下表所示 over_due_days c_sum c_sum_rate 0 1000 1 1 100 0.1 2 90 0.09 3 85 0.085 4 80 0.08 … … … over_due_days 为1的那一行表示 $逾期天数 \\geq 1$的订单数以及占总订单的比例，即 $$c\\_sum\\_rate=\\frac{over\\_due\\_days \\geq 1 的订单数}{总订单数}$$ select over_due_days ,sum(nums) over(order by over_due_days nulls last range between current row and unbounded following) as c_sum ,sum(nums) over(order by over_due_days nulls last range between current row and unbounded following) / (select count(1) from samples) as c_sum_rate from(-- 分逾期天数统计订单数量 select over_due_days ,count(1) as nums from samples group by 1 ) ; ","date":"2021-04-30","objectID":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E7%AA%97%E5%8F%A3/:3:0","tags":["SQL"],"title":"窗口函数的“窗口”","uri":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E7%AA%97%E5%8F%A3/"},{"categories":["数据分析"],"content":"总结 本文便是窗口函数部分的“收官之作”了。 主要是对“窗口”的概念展开了详细的陈述，结合初中数学中区间的概念来理解\u003cwindow_frame\u003e，并以计算累计占比为例深化理解。此外，也分享了他人整理的窗口函数 ","date":"2021-04-30","objectID":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E7%AA%97%E5%8F%A3/:4:0","tags":["SQL"],"title":"窗口函数的“窗口”","uri":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E7%AA%97%E5%8F%A3/"},{"categories":["数据分析"],"content":"Reference https://en.wikibooks.org/wiki/Structured_Query_Language/Window_functions ↩︎ ","date":"2021-04-30","objectID":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E7%AA%97%E5%8F%A3/:5:0","tags":["SQL"],"title":"窗口函数的“窗口”","uri":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E7%AA%97%E5%8F%A3/"},{"categories":["数据分析"],"content":"“抛” 计算组内占比 “引” 聚合窗口函数 窗口函数中 求和（sum）、均值（avg）、极值（max, min）、计数（count）等结合聚合函数使用的场景也较多。 数据分析过程中经常会遇到计算组内占比的情况。 计算 多个模型分以及多个时间段 的 psi 时，（等频/等距）分箱之后计算各箱样本占总样本数的百分比 示例如下表所示， model ym bucket act_rate A 202103 1 0.1209 A 202103 2 0.1148 A 202103 3 0.1089 A 202103 4 0.1041 A 202103 5 0.1004 A 202103 6 0.0983 A 202103 7 0.0984 A 202103 8 0.0937 A 202103 9 0.0892 A 202103 10 0.0714 比较方便的操作方式就是结合 sum() over() 函数计算组内占比。 select model ,ym ,bucket ,( nums / sum(nums) over(partition by model,ym) ) as act_rate from model_bucket_nums 其他几个聚合函数只是实现的功能不同，最后还是要各取所需了。 ","date":"2021-04-19","objectID":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E8%81%9A%E5%90%88/:0:0","tags":["SQL"],"title":"窗口函数-聚合","uri":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E8%81%9A%E5%90%88/"},{"categories":["数据分析"],"content":"整理排序场景常用函数，row_number() over(), rank() over(), dense_rank() over(), ntile(n) over()，并以连续登录问题为例深化理解 ","date":"2021-04-09","objectID":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/:0:0","tags":["SQL"],"title":"窗口函数-排序","uri":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/"},{"categories":["数据分析"],"content":"row_number() over() ","date":"2021-04-09","objectID":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/:1:0","tags":["SQL"],"title":"窗口函数-排序","uri":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/"},{"categories":["数据分析"],"content":"实现的功能 从1开始依次排序，生成不会重复的编号 -- 按照nums 列，降序排序 select id ,nums ,row_number() over(order by nums desc) as rank from table id nums rank 1x 45 3 2x 78 2 3x 87 1 4x 32 4 ","date":"2021-04-09","objectID":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/:1:1","tags":["SQL"],"title":"窗口函数-排序","uri":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/"},{"categories":["数据分析"],"content":"语法 row_number() over([partition by expr1, expr2, ...] order by expr1 [asc|desc], expr2 [asc|desc], ... ) partition by表示基于某（些）维度（/列）分组之后，再基于order by的规则实现组内排序。 select id ,nums ,row_number() over(partition by id order by nums desc) as rank from table ","date":"2021-04-09","objectID":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/:1:2","tags":["SQL"],"title":"窗口函数-排序","uri":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/"},{"categories":["数据分析"],"content":"应用 如何确定连续登录天数超过3天的用户 找到连续3天登录用户所表现的数据特征。比如，按照登录日期排序得到编号，两者作差，若连续登录则作差后的值是一样的 基于这个现象，可用row_number实现 select user_id ,(session_date - rk) as diff ,count(1) as nums from( select * ,row_number() over(partition by user_id order by session_date) as rk from( -- 按天去重 select user_id ,date_format(session_time,'yyyyMMdd') as session_date from table1 group by 1,2 ) ) group by 1,2 having nums \u003e= 3 ; ","date":"2021-04-09","objectID":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/:1:3","tags":["SQL"],"title":"窗口函数-排序","uri":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/"},{"categories":["数据分析"],"content":"rank() over() 基本语法类似于row_number() rank() over([partition by expr1, expr2, ...] order by expr1 [asc|desc], expr2 [asc|desc], ... ) 但不同的是，当值相等时 rank() 排序会出现重复序号的情况，且下个序号和当前序号之差为当前相同值的个数 ","date":"2021-04-09","objectID":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/:2:0","tags":["SQL"],"title":"窗口函数-排序","uri":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/"},{"categories":["数据分析"],"content":"示例 select dealer_id ,emp_name ,sales ,rank() over(order by sales) as rk from q1_sales ; dealer_id emp_name sales rank 1 Raphael Hull 8227 1 3 May Stout 9308 2 2 Haviva Montoya 9308 2 1 Jack Salazar 9710 4 3 Abel Kim 12369 5 3 Ursa George 15427 6 2 Beverly Lang 16233 7 2 Kameko French 16233 7 1 Ferris Brown 19745 9 1 Noel Meyer 19745 9 ","date":"2021-04-09","objectID":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/:2:1","tags":["SQL"],"title":"窗口函数-排序","uri":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/"},{"categories":["数据分析"],"content":"dense_rank() over() row_number() over() 、 rank() over() 和 dense_rank() over() 之间的差别主要在于对相同值的序号处理方式不同。 和rank() over()一样，遇到相同值时序号会重复，但是dense_rank() over() 的下一个序号和当前序号之差依然是1，不会出现空位的情况。 ","date":"2021-04-09","objectID":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/:3:0","tags":["SQL"],"title":"窗口函数-排序","uri":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/"},{"categories":["数据分析"],"content":"示例 select dealer_id ,emp_name ,sales ,dense_rank() over(order by sales) as denserank from q1_sales ; dealer_id emp_name sales denserank 1 Raphael Hull 8227 1 3 May Stout 9308 2 2 Haviva Montoya 9308 2 1 Jack Salazar 9710 3 3 Abel Kim 12369 4 3 Ursa George 15427 5 2 Beverly Lang 16233 6 2 Kameko French 16233 6 1 Ferris Brown 19745 7 1 Noel Meyer 19745 7 ","date":"2021-04-09","objectID":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/:3:1","tags":["SQL"],"title":"窗口函数-排序","uri":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/"},{"categories":["数据分析"],"content":"ntile(n) over() ntile(n) over() 和之前那三个排序函数不太一样。形式来看，多了个参数n，是指按照顺序平均分成n份（/箱），返回当前所在的位置。且需要order by 语句。 但对于不能实现平均分的情况，会基于约定来操作： 每箱记录数不能大于上一个箱子的记录数。即第1组的记录数大于等于第2组的记录数。 所有箱子的记录数要么相同。要么从某一记录数较少的箱子（命名为X）开始，后面所有箱子内的记录数都与该箱（X）的记录数相同。即如果前3箱的记录数都是9，而第4箱的记录数是8，那么第5、6箱及其之后箱子内的记录数也必须是8。 最先分出来的箱子，采取向上取整（ceil()）的方式 比如，53条记录，基于ntile的约定分到5个箱子，则每个箱子的记录数如下所示 bucket nums 1 11 2 11 3 11 4 10 5 10 ntile的方法能较好实现等频的效果，相比分位数作为分割点而言，不易受数据分布的影响。 ","date":"2021-04-09","objectID":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/:4:0","tags":["SQL"],"title":"窗口函数-排序","uri":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/"},{"categories":["数据分析"],"content":"示例 select emp_mgr ,sales ,ntile(5) over(order by sales) as ntilerank from q1_sales ; emp_mgr sales ntilerank Kari Phelps 8227 1 Rich Hernandez 9308 1 Kari Phelps 9710 2 Rich Hernandez 12369 2 Mike Palomino 13181 3 Rich Hernandez 15427 3 Kari Phelps 15547 4 Mike Palomino 16233 4 Dan Brodi 19745 5 Mike Palomino 23176 5 ","date":"2021-04-09","objectID":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/:4:1","tags":["SQL"],"title":"窗口函数-排序","uri":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/"},{"categories":["数据分析"],"content":"总结 窗口函数 返回类型 描述 row_number() int 从1开始依次排序，生成不会重复的序号 rank() int 从1开始依次排序。若值相等则得到同样的序号；且下一个序号将会出现空位，即若2个相等的值序号是1，则下一个序号是3 dense_rank() int 从1开始依次排序。若值相等则得到同样的序号；但下一个序号不会出现空位，即若2个相等的值序号是1，则下一个序号依然是2 ntile(n) int 将分组数据按照顺序平均分成n箱，返回当前值所在位置，n-th ","date":"2021-04-09","objectID":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/:5:0","tags":["SQL"],"title":"窗口函数-排序","uri":"/2021/04/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/"},{"categories":["数据分析","写作"],"content":"调节效应分析（ Moderation Analysis ），回答 WHEN 的问题 之前整理了中介效应分析，解决了怎么看中介效应是否显著的问题。 这篇继续整理调节效应分析（Moderation Analysis） 中介变量回答的是关于 HOW 的问题，而调节变量回答的是关于 WHEN 的问题 $X$ 什么时候影响 $Y$，或 $X$ 影响 $Y$ 的过程中是否取决于变量 $W$ ，而变量 $W$ 就是调节变量 典型且简单的调节效应模型图如下所示 ","date":"2021-03-25","objectID":"/2021/03/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%B0%83%E8%8A%82%E6%95%88%E5%BA%94%E5%88%86%E6%9E%90/:0:0","tags":["论文专题"],"title":"【论文专题】-调节效应分析","uri":"/2021/03/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%B0%83%E8%8A%82%E6%95%88%E5%BA%94%E5%88%86%E6%9E%90/"},{"categories":["数据分析","写作"],"content":"理论先行 调节效应理论模型用 statistical diagram 表示为， 即， $$ Y=i_Y+b_1X+b_2W+b_3XW+e_Y $$ ","date":"2021-03-25","objectID":"/2021/03/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%B0%83%E8%8A%82%E6%95%88%E5%BA%94%E5%88%86%E6%9E%90/:1:0","tags":["论文专题"],"title":"【论文专题】-调节效应分析","uri":"/2021/03/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%B0%83%E8%8A%82%E6%95%88%E5%BA%94%E5%88%86%E6%9E%90/"},{"categories":["数据分析","写作"],"content":"系数解释 各系数的解释如下 $b_1$ $b_1$ 是当 $W=0$ 时，$X$ 改变一个单位，$Y$ 改变 $b_1$ $$ b_1=[\\widehat{Y}|(X=x+1,W=0)] - [\\widehat{Y}|(X=x,W=0)] $$ $b_2$ $b_2$ 是当 $X=0$ 时时，$W$ 和 $Y$ 之间的关系 $$ b_2=[\\widehat{Y}|(W=w+1,X=0)] - [\\widehat{Y}|(W=w,X=0)] $$ $b_3$ 这是个大头，他是比较两组之间的差异， 一组是 $W$ 不变，$X$ 改变一个单位 另一组是，$W$ 和 $X$ 都改变一个单位 即， $$ b_3=([\\widehat{Y}|(X=x+1,W=w)] - [\\widehat{Y}|(X=x,W=w)]) - ([\\widehat{Y}|(X=x+1,W=w+1)] - [\\widehat{Y}|(X=x,W=w)]) $$ 做调节效应分析的时候， 理论上是希望 $X$ 影响 $Y$ 的过程中取决于变量 $W$ 对应着，公式（1）也可以改写为， $$ Y=i_Y+ \\theta_{X \\rightarrow Y}X + b_2W + e_Y $$ 其中，$\\theta_{X \\rightarrow Y} = b_1+b_3W$ 这也就生动形象的表示了， 如果 $b_3$ 显著性不等于 0 ，那么 $W$ 的值不同，$X$ 对 $Y$ 的影响也不同 所以当回归结果中，系数 $b_3$ 显著时（$p\u003c0.05$），即变量 $W$ 的确起到调节作用时 我们将会进一步分析对应不同 $W$，$X$ 是如何影响 $Y$ 的 常用的方法便是 pick-a-point approach ，又称 spotlight analysis 我第一次看到 spotlight analysis 这个名词，是在一篇JM的文章上，当时查了半天也不知道啥意思。。。 ","date":"2021-03-25","objectID":"/2021/03/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%B0%83%E8%8A%82%E6%95%88%E5%BA%94%E5%88%86%E6%9E%90/:1:1","tags":["论文专题"],"title":"【论文专题】-调节效应分析","uri":"/2021/03/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%B0%83%E8%8A%82%E6%95%88%E5%BA%94%E5%88%86%E6%9E%90/"},{"categories":["数据分析","写作"],"content":"pick-a-point approach 基本思路是根据 $W$ 的数据选三个值，进而表示低-中-高三种状态 一般就选数据16th, 50th, and 84th分位数分别表示低-中-高，进而分析 $X$ 对 $Y$ 的影响是否显著 如果 $W$ 是分类变量就直接看各自类别的情况了，不用取点了。 所以，综上所述，基于公式(1) 构建回归模型，根据交互项系数 $XW$（$b_3$）是否显著，进而确定调节效应是否存在。 以上这些都能通过PROCESS1很好的实现。 ","date":"2021-03-25","objectID":"/2021/03/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%B0%83%E8%8A%82%E6%95%88%E5%BA%94%E5%88%86%E6%9E%90/:1:2","tags":["论文专题"],"title":"【论文专题】-调节效应分析","uri":"/2021/03/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%B0%83%E8%8A%82%E6%95%88%E5%BA%94%E5%88%86%E6%9E%90/"},{"categories":["数据分析","写作"],"content":"实际操作 步骤如下： SPSS加载 process的语法文件 使用过程中可以自主编写语法、也可以菜单式的操作，如 process y=justify/x=frame/w=skeptic/model=1/plot=1. 变量和数据字段一一对应 基于理论研究模型，选择PROCESS的模型（本例对应的是model 1） 选项中勾选 Generate code for visualizing interactions 如果是用spss语法的话，加上 plot=1 即可 这能方便用SPSS作斜率图，用于可视化调节效应 复制PROCESS分析结果中的可视化脚本即可，如 （可选）中心化 有些文章中会说做调节效应分析前，对变量 $X$ 和 $Y$ 进行中心化处理，可能会见到 scaling 这样的术语 但其实无所谓啦，而且就算对和进行中心化处理，也不会影响 $W$、$XW$ 的系数，只是会影响 $X$ 的系数（$b_1$）罢了 因为之前有提到，$b_1$ 是表示 $W$ 为0时，$X$ 对 $Y$ 的影响，如果对 $W$ 做中心化处理， 即 $W^,=W - \\overline{W}$ 那么这时候 $X$ 的系数对应的是 $W$ 取样本均值（$\\overline{W}$）时，$X$ 对 $Y$ 的影响 得到结果之后，直奔交互项系数（本例对应的是 $b_3$）即可 若显著（$p\u003c0.05$），PROCESS便会生成低-中-高状态下，$X$ 和 $Y$ 之间的关系如下所示， ","date":"2021-03-25","objectID":"/2021/03/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%B0%83%E8%8A%82%E6%95%88%E5%BA%94%E5%88%86%E6%9E%90/:2:0","tags":["论文专题"],"title":"【论文专题】-调节效应分析","uri":"/2021/03/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%B0%83%E8%8A%82%E6%95%88%E5%BA%94%E5%88%86%E6%9E%90/"},{"categories":["数据分析","写作"],"content":"参考资料 Hayes A F: Introduction_to_Mediation_Moderation_and_Conditional_Process_Analysis_A_Regression_Based[M].2ed.2018 ↩︎ ","date":"2021-03-25","objectID":"/2021/03/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%B0%83%E8%8A%82%E6%95%88%E5%BA%94%E5%88%86%E6%9E%90/:3:0","tags":["论文专题"],"title":"【论文专题】-调节效应分析","uri":"/2021/03/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%B0%83%E8%8A%82%E6%95%88%E5%BA%94%E5%88%86%E6%9E%90/"},{"categories":["数据分析"],"content":"过去的一段时间里一直在琢磨客群划分的问题 segmentation 隐隐约约觉得所谓的 客群划分 和 市场细分 不谋而合，并且我发现风控领域很重视 “圈客群” 但因为部门不同，最后关注的目的也存在一定的差异。对于风控而言，在兼顾风险的同时，给出差异性的策略。在贷前，差异性策略方面可能更多是关注授信额度的问题。贷中，更多关注调额方面。 本文将整理市场细分/客群划分的一些方法 ","date":"2020-09-02","objectID":"/2020/09/da-segmentation/:0:0","tags":["用户画像"],"title":"客群划分思路大集合","uri":"/2020/09/da-segmentation/"},{"categories":["数据分析"],"content":"有监督学习—树模型 相关文章： 决策树简介 可视化决策树结果 样本不均衡的问题 decision tree 将客群划分（/市场细分）看成是一个分类问题，因为做客群划分肯定是有目的/目标的，比如是否违约、客户忠诚等等 针对我们的目标，定义好我们的问题，进一步得到模型需要的label（y值）。基于提取的变量，最后可采用决策树实现客群划分，甚至可以采用随机森林、XGBoost，可视化前几棵树，看看模型给出的变量规则。 除了对算法本身的了解外，我觉得 找变量（影响label的影响因素）也是难点，毕竟需要面向业务建模（最近新造的词）。除了关注模型区分度等，更多需要注意的是 解释性，是否make sense，能不能从业务的角度去解释树模型给出的规则。 所以，在特征选择以及构造新特征方面真的需要花很大的功夫。 得到树模型输出的规则后，我们还需要注意 客群之间的差异性 基于决策树得到的规则，看客群之间在目标方面（如，违约率）的差异性 客群的稳定性 基于规则，看未来的人数分布及目标（如，违约率） 这里还涉及到一个外部数据的问题。客群划分时，尽量避免使用外部数据、尤其是被加工过的一些指标。一是不知道计算逻辑；二是不稳定。所以一般直接选取用户本身属性变量。当然，这也取决于分群的场景。 ","date":"2020-09-02","objectID":"/2020/09/da-segmentation/:1:0","tags":["用户画像"],"title":"客群划分思路大集合","uri":"/2020/09/da-segmentation/"},{"categories":["数据分析"],"content":"聚类 clustering 聚类用于市场细分也是比较常见的。 但最近我觉得，聚类目的性不明确。换句话说，市场细分的目的性不明显。 聚类更多是在某些变量下将相似的归为一簇 但在车企，还是会采用聚类细分市场的，如基于价格、投影面积、离地高度等变量划分车型。这也符合最初的目的：根据某些车辆参数相似的归为一类。 到底是视为聚类还是分类问题，还是要具体问题具体分析 ","date":"2020-09-02","objectID":"/2020/09/da-segmentation/:2:0","tags":["用户画像"],"title":"客群划分思路大集合","uri":"/2020/09/da-segmentation/"},{"categories":["数据分析"],"content":"基于常规的细分变量 人口统计变量 性别、年龄、职业、收入等，但“收入”的数据一般比较难获取，大多数情况下可能也是通过各种方式去预测 地理位置 “地域决定论” + 一方水土养一方人 这个还是要考虑具体业务 如果从逾期等违约情况来看的话：经济基础决定上层建筑，而一个城市的文明程度和经济发展也是有很大关系的。而经济发展又会受到地域的限制，正是所谓的“地域决定论”，所以经济发展差距较大的城市往往违约率也存在一定差异 ","date":"2020-09-02","objectID":"/2020/09/da-segmentation/:3:0","tags":["用户画像"],"title":"客群划分思路大集合","uri":"/2020/09/da-segmentation/"},{"categories":["数据分析"],"content":"不成熟的想法 在现金贷背景下，基于入不敷出的逻辑来关注风险的问题，我通过构建“收支”模型（收入和支出之间的关系）实现客群的划分。 seg 收入 支出 1 高 高 2 高 低 3 低 高 4 低 低 当然，这里的高、低是针对产品的目标用户而言 显然，对于低收入、高支出的客群，更有可能发生逾期的情况，但同时这部分人群也是更有可能产生收益的人群，所以针对这部分人群就需要深挖，兼顾风险的同时给予一定的高额度。 但难点就是在于对“收入”、“支出”的测量，在无法准确获取收入、支出数据的情况下，无论是用于测量收入还是支出的变量都需要满足产品所服务对象的特征，以能较为准确的测量“收入”与“支出”的状态。 ","date":"2020-09-02","objectID":"/2020/09/da-segmentation/:4:0","tags":["用户画像"],"title":"客群划分思路大集合","uri":"/2020/09/da-segmentation/"},{"categories":["数据分析"],"content":"总结 本文分别阐述了 有监督、无监督以及 常规细分变量三大划分客群的方法，具体还是要结合实际业务场景采用相应的方法 基于相应的规则完成划分后，还要基于目标问题进行横纵向对比： 横向比较客群的稳定性 纵向比较客群的差异性 ","date":"2020-09-02","objectID":"/2020/09/da-segmentation/:5:0","tags":["用户画像"],"title":"客群划分思路大集合","uri":"/2020/09/da-segmentation/"},{"categories":["写作","数据分析"],"content":"基于R，总结零膨胀计数模型的应用流程 我之所以用计数模型，主要是受到清华水利专业某博士某篇论文1的启发。我也将他构造变量的思路也写进了我论文的展望部分。 在经济学及社会科学领域也会遇到对计数数据（Count Data）建模的任务 计数数据是一种数据类型，取值只能是非负整数{0,1,2,3,…}，并且数值并不是排名而是计数 泊松回归（Poisson Regression）是处理计数数据的常用方法 stats package - glm() 函数 但是泊松回归并不能很好的解决计数变量数据中“过度分散”（over-dispersion）的问题 针对 over-dispersion 的问题，往往会采用负二项回归（Negative Binomial Regression）的方法 MASS package - glm.nb() 函数 但，无论是泊松回归还是负二项回归都不能很好的解决计数数据零过多的问题 此时，零膨胀计数模型（zero-inflated models）就诞生了 zero-inflated models are mixture models that combine a count component and a point mass at zero. 关于零膨胀计数模型，各自的软件或语言都有自己的实现方法。从我查阅的资料来看，目前 stata 和 R 在这方面资料比较多，Python 相对较少。 我选择的是R，因为Anaconda装rstudio比较便捷，且学习成本比stata低。 所以本文基于R，在确定计数数据存在零膨胀的前提下（一般看计数数据的频率直方图，或者直接用vuong()完成模型选择），总结零膨胀计数模型的应用流程 ","date":"2020-05-06","objectID":"/2020/05/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E9%9B%B6%E8%86%A8%E8%83%80%E8%AE%A1%E6%95%B0%E6%A8%A1%E5%9E%8B/:0:0","tags":["论文专题"],"title":"【论文专题】零膨胀计数模型","uri":"/2020/05/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E9%9B%B6%E8%86%A8%E8%83%80%E8%AE%A1%E6%95%B0%E6%A8%A1%E5%9E%8B/"},{"categories":["写作","数据分析"],"content":"启动rstudio 用 Anaconda 安装 Rstudio 的过程中，需要手动创建一个R运行的新环境（如，r_env） 打开 anaconda 比较费时儿，所以会在 conda命令端 启动Rstudio # 查看环境目录 conda info -e # 切换至文件目录下启动 cd \"工作目录\" # 激活环境 conda activate r_env # 启动 Rstudio rstudio ","date":"2020-05-06","objectID":"/2020/05/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E9%9B%B6%E8%86%A8%E8%83%80%E8%AE%A1%E6%95%B0%E6%A8%A1%E5%9E%8B/:1:0","tags":["论文专题"],"title":"【论文专题】零膨胀计数模型","uri":"/2020/05/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E9%9B%B6%E8%86%A8%E8%83%80%E8%AE%A1%E6%95%B0%E6%A8%A1%E5%9E%8B/"},{"categories":["写作","数据分析"],"content":"读取数据文件 R打开csv格式的文件比较省事儿 # 数据文件保存在rstudio启动的目录下 my.data1\u003c-read.csv(\"data.csv\") ","date":"2020-05-06","objectID":"/2020/05/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E9%9B%B6%E8%86%A8%E8%83%80%E8%AE%A1%E6%95%B0%E6%A8%A1%E5%9E%8B/:2:0","tags":["论文专题"],"title":"【论文专题】零膨胀计数模型","uri":"/2020/05/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E9%9B%B6%E8%86%A8%E8%83%80%E8%AE%A1%E6%95%B0%E6%A8%A1%E5%9E%8B/"},{"categories":["写作","数据分析"],"content":"Over-Dispersion？ 有两种方法检验计数数据是否存在over-dispersion的现象，但对象不同，用的模型不同 odTest() dispersiontest() ","date":"2020-05-06","objectID":"/2020/05/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E9%9B%B6%E8%86%A8%E8%83%80%E8%AE%A1%E6%95%B0%E6%A8%A1%E5%9E%8B/:3:0","tags":["论文专题"],"title":"【论文专题】零膨胀计数模型","uri":"/2020/05/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E9%9B%B6%E8%86%A8%E8%83%80%E8%AE%A1%E6%95%B0%E6%A8%A1%E5%9E%8B/"},{"categories":["写作","数据分析"],"content":"odTest() 需要 pscl package odTest(glmnb_obj, alpha=.05, digits = max(3, getOption(\"digits\") - 3)) 先用负二项模型跑一次回归 library(MASS) nb \u003c- glm.nb(y ~ x1+x2+x3, data=my.data1) library(pscl) odTest(nb) $p-value\u003c0.05$，说明计数数据存在 over-dispersion 现象 ","date":"2020-05-06","objectID":"/2020/05/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E9%9B%B6%E8%86%A8%E8%83%80%E8%AE%A1%E6%95%B0%E6%A8%A1%E5%9E%8B/:3:1","tags":["论文专题"],"title":"【论文专题】零膨胀计数模型","uri":"/2020/05/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E9%9B%B6%E8%86%A8%E8%83%80%E8%AE%A1%E6%95%B0%E6%A8%A1%E5%9E%8B/"},{"categories":["写作","数据分析"],"content":"dispersiontest() glm_p \u003c- glm(y ~ x1+x2+x3, data = my.data1, family = poisson) library(AER) dispersiontest(glm_p,trafo=1) 计数数据存在零膨胀且over-dispersion的现象，那么就需要采用零膨胀负二项模型 若不存在over-dispersion的现象，则采用零膨胀泊松模型 当然，可以两个模型都跑一次，最后通过vuong()完成模型的选择 所以，也可以比较零膨胀泊松模型和泊松模型 ","date":"2020-05-06","objectID":"/2020/05/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E9%9B%B6%E8%86%A8%E8%83%80%E8%AE%A1%E6%95%B0%E6%A8%A1%E5%9E%8B/:3:2","tags":["论文专题"],"title":"【论文专题】零膨胀计数模型","uri":"/2020/05/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E9%9B%B6%E8%86%A8%E8%83%80%E8%AE%A1%E6%95%B0%E6%A8%A1%E5%9E%8B/"},{"categories":["写作","数据分析"],"content":"run regressions 零膨胀计数模型都依赖 pscl package ","date":"2020-05-06","objectID":"/2020/05/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E9%9B%B6%E8%86%A8%E8%83%80%E8%AE%A1%E6%95%B0%E6%A8%A1%E5%9E%8B/:4:0","tags":["论文专题"],"title":"【论文专题】零膨胀计数模型","uri":"/2020/05/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E9%9B%B6%E8%86%A8%E8%83%80%E8%AE%A1%E6%95%B0%E6%A8%A1%E5%9E%8B/"},{"categories":["写作","数据分析"],"content":"零膨胀负二项回归模型 m3 \u003c- zeroinfl(y ~ x1+x2+x3|x4+x5+x6, data=my.data1,dist=\"negbin\") 零膨胀计数模型是分成了两部分建模：一部分是计数部分，另一部分处理为二分类 $(0,1)$ 的情况 $x_1,x_2,x_3$ 是选定的计数部分的影响因素；$x_4,x_5,x_6$ 是二分类情况的影响因素 如果两者的影响因素一样的，则公式形式可以简单写为 m3 \u003c- zeroinfl(y ~ x1+x2+x3, data=my.data1,dist=\"negbin\") # 若数据中除y之外均为影响因素 m3 \u003c- zeroinfl(y ~ ., data=my.data1,dist=\"negbin\") ","date":"2020-05-06","objectID":"/2020/05/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E9%9B%B6%E8%86%A8%E8%83%80%E8%AE%A1%E6%95%B0%E6%A8%A1%E5%9E%8B/:4:1","tags":["论文专题"],"title":"【论文专题】零膨胀计数模型","uri":"/2020/05/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E9%9B%B6%E8%86%A8%E8%83%80%E8%AE%A1%E6%95%B0%E6%A8%A1%E5%9E%8B/"},{"categories":["写作","数据分析"],"content":"零膨胀泊松回归模型 m4 \u003c- zeroinfl(y ~ x1+x2+x3|x4+x5+x6, data=my.data1,dist = 'poisson') $x_1,x_2,x_3$ 的表现方式同上 ","date":"2020-05-06","objectID":"/2020/05/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E9%9B%B6%E8%86%A8%E8%83%80%E8%AE%A1%E6%95%B0%E6%A8%A1%E5%9E%8B/:4:2","tags":["论文专题"],"title":"【论文专题】零膨胀计数模型","uri":"/2020/05/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E9%9B%B6%E8%86%A8%E8%83%80%E8%AE%A1%E6%95%B0%E6%A8%A1%E5%9E%8B/"},{"categories":["写作","数据分析"],"content":"模型选择 vuong(m3,m4) 根据结果选择模型即可 ","date":"2020-05-06","objectID":"/2020/05/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E9%9B%B6%E8%86%A8%E8%83%80%E8%AE%A1%E6%95%B0%E6%A8%A1%E5%9E%8B/:5:0","tags":["论文专题"],"title":"【论文专题】零膨胀计数模型","uri":"/2020/05/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E9%9B%B6%E8%86%A8%E8%83%80%E8%AE%A1%E6%95%B0%E6%A8%A1%E5%9E%8B/"},{"categories":["写作","数据分析"],"content":"参考资料 Hanchen Jiang et al.: 10.3390/su10051509 ↩︎ ","date":"2020-05-06","objectID":"/2020/05/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E9%9B%B6%E8%86%A8%E8%83%80%E8%AE%A1%E6%95%B0%E6%A8%A1%E5%9E%8B/:6:0","tags":["论文专题"],"title":"【论文专题】零膨胀计数模型","uri":"/2020/05/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E9%9B%B6%E8%86%A8%E8%83%80%E8%AE%A1%E6%95%B0%E6%A8%A1%E5%9E%8B/"},{"categories":["写作","数据分析"],"content":"这篇是文本情感分析的应用篇 运用情感分析技术，让我们的研究更丰富 本文所讨论的情感分析聚焦在 二分类 情况，即判断一句话（短文本）的情感倾向是正面还是负面 我们可以简单的理解为： 存在一个很牛逼的箱子，这个箱子有进口处和出口处，我们需要做的便是把某句话通过进口处放入这个箱子，之后这个箱子从出口处吐出结果 其中情感倾向的结果方面，大多数箱子是会告诉我们情感倾向为正的概率是多少（假设是 $a$ ），显然情感倾向为负的概率便是 $1-a$ 若 $a\u003e1-a$ ，即 $a\u003e0.5$ ，“箱子”认为这句话的情感倾向是正面的 总之，我们可以根据研究的需要，根据箱子吐出的结果构造变量用于下游的任务。 那么，本文就系统的整理了好用的“箱子” ","date":"2020-04-29","objectID":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E6%96%87%E6%9C%AC%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/:0:0","tags":["论文专题"],"title":"【论文专题】文本情感分析","uri":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E6%96%87%E6%9C%AC%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/"},{"categories":["写作","数据分析"],"content":"ERNIE1 谷歌的BERT问世之后，预训练模型那是备受关注啊，算是自然语言处理领域的里程碑事件了。 我为了蹭热度，琢磨百度的这个ERNIE，也是废了点时间 在本地装好各种环境之后，在我这个小破电脑上训练了一天一夜吧 但最终的方案是蹭了百度的 AI Studo 注册账号，运行项目还送算力卡，这样就能用GPU训练了 小破电脑一天一夜的活，几分钟就搞定了 本地装包，没梯子的话，一定要用清华的镜像 conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/Paddle/ Python代码 #需要更改训练集、验证集、测试集的文件位置 import paddlehub as hub !hub install ernie module = hub.Module(name=\"ernie\") class DemoDataset(BaseNLPDataset): \"\"\"DemoDataset\"\"\" def __init__(self): # 数据集存放位置 self.dataset_dir = \"work\" super(DemoDataset, self).__init__( base_path=self.dataset_dir, train_file=\"train.tsv\", dev_file=\"dev.tsv\", test_file=\"test.tsv\", # 如果还有待预测数据，可以放在predict.tsv predict_file=\"predict.tsv\", train_file_with_header=True, dev_file_with_header=True, test_file_with_header=True, predict_file_with_header=True, # 数据集类别 label_list=[\"0\", \"1\"]) dataset = DemoDataset() reader = hub.reader.ClassifyReader( dataset=dataset, vocab_path=module.get_vocab_path(), sp_model_path=module.get_spm_path(), word_dict_path=module.get_word_dict_path(), max_seq_len=128) strategy = hub.AdamWeightDecayStrategy( weight_decay=0.01, warmup_proportion=0.1, learning_rate=5e-5) config = hub.RunConfig( use_cuda=True, num_epoch=1, checkpoint_dir=\"ernie_txt_cls_turtorial_demo\", batch_size=128, #一般为2^n eval_interval=10, strategy=strategy) inputs, outputs, program = module.context( trainable=True, max_seq_len=128) # Use \"pooled_output\" for classification tasks on an entire sentence. pooled_output = outputs[\"pooled_output\"] feed_list = [ inputs[\"input_ids\"].name, inputs[\"position_ids\"].name, inputs[\"segment_ids\"].name, inputs[\"input_mask\"].name, ] cls_task = hub.TextClassifierTask( data_reader=reader, feature=pooled_output, feed_list=feed_list, num_classes=dataset.num_labels, config=config) run_states = cls_task.finetune_and_eval() # 预测 data = [[d.text_a] for d in dataset.get_predict_examples()] run_states = cls_task.predict(data=data) results = [run_state.run_results for run_state in run_states] ","date":"2020-04-29","objectID":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E6%96%87%E6%9C%AC%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/:1:0","tags":["论文专题"],"title":"【论文专题】文本情感分析","uri":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E6%96%87%E6%9C%AC%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/"},{"categories":["写作","数据分析"],"content":"senta2 百度的senta模型 有种模型即软件的味道 对于我这种小白很友好，比ERNIE方便 加载好模型就能用 CNN, GRU, LSTM, BiLSTM import paddlehub as hub # 加载模型 cnn = hub.Module(name='senta_cnn') # 预测 data_dict = {\"text\":[\"你怎么那么好看\"]} results = cnn.sentiment_classify(data = data_dict) ","date":"2020-04-29","objectID":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E6%96%87%E6%9C%AC%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/:2:0","tags":["论文专题"],"title":"【论文专题】文本情感分析","uri":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E6%96%87%E6%9C%AC%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/"},{"categories":["写作","数据分析"],"content":"snownlp3 snownlp比较老了，但他的训练集都是电商评论的数据 契合我的主题，所以我也用了 这个用起来也方便 from snownlp import SnowNLP s = SnowNLP(u'这个东西真心很赞') s.sentiments # 输出情感倾向为正面的概率 当然，snownlp还能干别的，如分词、繁体转简体、提取关键词… ","date":"2020-04-29","objectID":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E6%96%87%E6%9C%AC%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/:3:0","tags":["论文专题"],"title":"【论文专题】文本情感分析","uri":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E6%96%87%E6%9C%AC%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/"},{"categories":["写作","数据分析"],"content":"参考资料 https://aistudio.baidu.com/aistudio/index ↩︎ https://www.paddlepaddle.org.cn/modelbasedetail/senta ↩︎ https://github.com/isnowfy/snownlp ↩︎ ","date":"2020-04-29","objectID":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E6%96%87%E6%9C%AC%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/:4:0","tags":["论文专题"],"title":"【论文专题】文本情感分析","uri":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E6%96%87%E6%9C%AC%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/"},{"categories":["写作"],"content":"毕业论文模板，样式先行 三年前的我搞毕业设计，第一次接触这玩意儿，一脸懵逼 好在我朱哥搞过大创（还是国家级的），当时给我各种科普单片机的知识 搞大创的好处就是当我们不知道是画机械图还是搞电路的时候，朱哥设计的成品以及论文都搞定了，，，跑马灯跑起来、酒精浓度测起来、小屏幕亮起来 不过朱哥也没继续搞汽车，后来投身了我国交通事业。依稀记得朱哥远程面试的时候，寝室几个人都在打游戏，，，在我们的影响下，朱哥最终去了广东某985高校 但那时候我们对Word排版都不怎么了解 以下情景历历在目： 这个参考文献的上标怎么弄？ 又要加篇参考文献？序号不得又重写？ 参考文献的引用格式是啥？ 这些字体都要改成三号、加粗？然后就用格式刷一顿更新 三线表是什么鬼？又要画三线表？ 。。。。。。 总之，我们都在Word上花了很长时间，不断的进行重复性的工作，以满足格式上要求 但当我们面对硕士毕业论文时，在格式方面花的时间就很少很少了，没有了各种重复性的操作 因为我们秉承着**样式先行。**在写论文之前，就根据学校的要求，把字体、表格的格式调整好，写作的过程中随时切换，而且就算后续要调整，统一调整对应的样式即可，避免了重复性操作。 本文并不是记录如何去调整/设计样式，因为我认为这个真的是太多了，重点是基于毕业论文格式记录word的正确打开方式，抽象出复用的部分。这也是我开发模板的原因。面对不同的需求，后续只需要微调即可。 可以在我的公众号内回复 word， 获取华东师范大学毕业论文模板 （用过的朋友都说好） ","date":"2020-04-21","objectID":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/:0:0","tags":["论文专题"],"title":"【论文专题】毕业论文模板","uri":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/"},{"categories":["写作"],"content":"模块拆解 根据论文的总体框架，分别设计对应的样式。 换句话说便是先弄清楚整篇论文的字体、段落会涉及到哪些不同的格式要求，在正式写作之前，分别设计好对应的样式。以便写作过程调用。 毕业论文主体部分的格式要求，往往会涉及到各级标题、正文、脚注、参考文献（参考文献部分后续会单拎出来记录）字体的格式，理工科专业往往会要求表格是三线表。 确定好字体、段落的格式要求后，就可以针对性的修改/设计样式 为了方便后续的写作，可以设计相应的快捷键（样式-\u003e格式-\u003e快捷键） ","date":"2020-04-21","objectID":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/:1:0","tags":["论文专题"],"title":"【论文专题】毕业论文模板","uri":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/"},{"categories":["写作"],"content":"参考文献格式 正文中往往会引用相关参考文献 这时候就要放出文献管理大杀器——NoteExpress 有了他，妈妈再也不用担心我修改参考文献的格式了 在软件中记录好被引用的内容，如作者、论文标题、年份、期刊或会议名称等等（大部分pdf、caj文献都能有效识别） 每当需要标注引用时，直接点击“引用”即可 通过NoteExpress引用至word后主要涉及两大部分： 正文部分的标注 上标序号 或 作者+年份 的形式 附在最后的参考文献 如 [1] LIU Y. Word of mouth for movies: Its dynamics and impact on box office revenue[J]. Journal of Marketing. 2006, 70(3): 74-89. 依然是样式先行的逻辑，简便的办法是先在NoteExpress样式库中选择与自己要求相似的样式，当然，完全满足需求就更好了。 接着，在所选样式的基础上修改相关格式以满足自己的需求 引文下的修改便是对应修改“正文部分的标注”的格式 题录下的修改便是对应修改“附在最后的参考文献”的格式 值得一提的是，题录中可设置排序的规则，因为有些学校要求英文文献在前面、之后再按照时间或作者排序。 ","date":"2020-04-21","objectID":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/:2:0","tags":["论文专题"],"title":"【论文专题】毕业论文模板","uri":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/"},{"categories":["写作"],"content":"Tips 最后再记录些杂七杂八的tips ","date":"2020-04-21","objectID":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/:3:0","tags":["论文专题"],"title":"【论文专题】毕业论文模板","uri":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/"},{"categories":["写作"],"content":"表格、图片名称 选中表格（/图片），右键“插入题注”，标签选择“表”，编号选择“包含章节号” ","date":"2020-04-21","objectID":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/:3:1","tags":["论文专题"],"title":"【论文专题】毕业论文模板","uri":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/"},{"categories":["写作"],"content":"交叉引用 论文中往往会看到如图xxx所示、如表xxx所示等表述方式，并且希望能定位到相关表格或图片时，就需要采用文内交叉引用的方法 ","date":"2020-04-21","objectID":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/:3:2","tags":["论文专题"],"title":"【论文专题】毕业论文模板","uri":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/"},{"categories":["写作"],"content":"公式 当我们用MathType编辑公式，粘贴至word时，往往会影响word的格式，主要体现在行与行之间的距离变大。 对应的解决方案便：在对应的段落内，右键选择“段落”，取消勾选下图中所示内容 ","date":"2020-04-21","objectID":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/:3:3","tags":["论文专题"],"title":"【论文专题】毕业论文模板","uri":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/"},{"categories":["写作"],"content":"代码高亮 涉及到代码的话，为了美观，往往希望word中代码也实现高亮 推荐 planetB 暂时统计了这几个tips，欢迎交流 ","date":"2020-04-21","objectID":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/:3:4","tags":["论文专题"],"title":"【论文专题】毕业论文模板","uri":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/"},{"categories":["写作"],"content":"关于爬虫的文章，之前写过两篇： 爬取拉勾网数据分析职位相关的数据 基于Scrapy框架爬取京东评论数据 京东那个其实也是为了写论文，虽说拿着那篇参加了个会议，但我觉得诟病比较多。 如今，为了毕业论文，又重操旧业了 这次选择的对象是苏宁易购手机评论数据 收购家乐福中国事件吸引了我的眼球 整体的逻辑也比较简单，没有很复杂的反爬技术，直接上流程图吧 ","date":"2020-04-05","objectID":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%8B%8F%E5%AE%81%E8%AF%84%E8%AE%BA%E6%95%B0%E6%8D%AE/:0:0","tags":["论文专题"],"title":"【论文专题】苏宁易购评论爬虫","uri":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%8B%8F%E5%AE%81%E8%AF%84%E8%AE%BA%E6%95%B0%E6%8D%AE/"},{"categories":["写作"],"content":"提取url的共性 我觉得像我这种低端爬虫的基本思想就是所见即所得，代替人工的复制、粘贴 我们在网络上见到的东西，都会有个url与之对应 通过url给服务器发送请求 就像 https://www.baidu.com/ 服务器返回相应的数据，浏览器解析这些数据，最后就是大家看到的样子 爬虫也是这个逻辑 所以写代码之前需要分析苏宁易购评论数据的url 苏宁评论数据是动态加载的，需要抓包分析 寻找url的异同点，比如不同商品、不同页面之间url的差异，哪些是变的、哪些是不变的。 一顿操作之后，发现变动的主要是三部分： 商品ID 店铺ID Cluster_ID 商品、店铺ID还好理解，你这个东西是什么、在哪家卖的，不能把A家商品的评论数据放到B家商品那儿 但这个 Cluster_ID 是什么 问就是不知道 但还是要清楚这玩意儿可以从哪儿得到，不然评论数据的url也不知道呀 有幸结识了位美团的前端大佬,在大佬的帮助下，找到了Cluster_ID 结论是，在商品详情页的源代码中有这么个东西 所以在最终确定评论数据的URL之前，需要通过解析商品详情页的数据，获取 Cluster_ID def get_clusterId(product_id,ua,shop_id=\"0000000000\"): ''' 解析商品详情页url 得到clusterId ''' url = \"https://product.suning.com/{}/{}.html\".format(shop_id,product_id) header = {\"Referer\":\"https://search.suning.com/%E6%89%8B%E6%9C%BA/#second-filter\",\"User-Agent\": ua} response = requests.get(url, headers=header) html = response.text soup = bs(html,\"html.parser\") t = soup.select(\"head script\")[0] tstr = t.get_text() cluster_id = re.search(r\"clusterId\\\":\\\"(\\d*).*?\\\"\",tstr).group(1) # string return cluster_id shop_id=0000000000 表示店铺是苏宁自营 正如流程图中所示，通过商品、店铺ID，确定商品详情页的url，从服务器返回的数据中找到 Cluster_ID 其实到这，就已经结束了 后续的操作就是获取并解析json文件 ","date":"2020-04-05","objectID":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%8B%8F%E5%AE%81%E8%AF%84%E8%AE%BA%E6%95%B0%E6%8D%AE/:1:0","tags":["论文专题"],"title":"【论文专题】苏宁易购评论爬虫","uri":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%8B%8F%E5%AE%81%E8%AF%84%E8%AE%BA%E6%95%B0%E6%8D%AE/"},{"categories":["写作"],"content":"json文件 根据url请求服务器，让其返回评论数据的json文件 def again_content(cluster_id,product_id,page,ua,shopid=\"0000000000\"): product_id_0 = \"0\"*(18-len(str(product_id))) + str(product_id) url = \"https://review.suning.com/ajax/cluster_review_lists/cluster-{}-{}-{}-again-{}-default-10-----reviewList.htm?callback=reviewList\".format(cluster_id,product_id_0,shopid,page) header = {\"User-Agent\": ua, \"Referer\":\"https://product.suning.com/{}/{}.html\".format(shopid,product_id), \"Host\": \"review.suning.com\", \"Accept\": \"*/*\", \"Accept-Encoding\": \"gzip, deflate, br\", \"Accept-Language\": \"zh-CN,zh;q=0.9,zh-TW;q=0.8,en;q=0.7\"} response = requests.get(url, headers=header) html = response.text text = json.loads(html.lstrip(\"reviewList(\").rstrip(\")\") ) reviews = text[\"commodityReviews\"] print(text[\"returnMsg\"],product_id,page) return reviews 根据json文件找到想要的数据，根据key-value的对应形式，慢慢获取就可以了,如 add_reviewID = reviews[\"againReview\"][\"againId\"] reviewId = reviews[\"commodityReviewId\"] # 之后要利用这个匹配 useful_vote first_review = reviews[\"content\"] first_review_pt = reviews[\"publishTime\"] add_review = reviews[\"againReview\"][\"againContent\"] add_review_pt = reviews[\"againReview\"][\"publishTime\"] diff_first_add_pt = reviews[\"againReview\"][\"publishTimeStr\"] qualityStar = reviews[\"qualityStar\"] first_pic = reviews[\"imgCnt\"] 最后保存相关数据即可 ","date":"2020-04-05","objectID":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%8B%8F%E5%AE%81%E8%AF%84%E8%AE%BA%E6%95%B0%E6%8D%AE/:2:0","tags":["论文专题"],"title":"【论文专题】苏宁易购评论爬虫","uri":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%8B%8F%E5%AE%81%E8%AF%84%E8%AE%BA%E6%95%B0%E6%8D%AE/"},{"categories":["写作"],"content":"其他细节 ","date":"2020-04-05","objectID":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%8B%8F%E5%AE%81%E8%AF%84%E8%AE%BA%E6%95%B0%E6%8D%AE/:3:0","tags":["论文专题"],"title":"【论文专题】苏宁易购评论爬虫","uri":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%8B%8F%E5%AE%81%E8%AF%84%E8%AE%BA%E6%95%B0%E6%8D%AE/"},{"categories":["写作"],"content":"循环次数 因为我是 FOR 循环的形式获取评论数据的，并且有些商品的追评数据比较少。为了避免无效的循环，所以我还额外通过追评总数计算了页面数，以决定循环次数。最多展示50页 ","date":"2020-04-05","objectID":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%8B%8F%E5%AE%81%E8%AF%84%E8%AE%BA%E6%95%B0%E6%8D%AE/:3:1","tags":["论文专题"],"title":"【论文专题】苏宁易购评论爬虫","uri":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%8B%8F%E5%AE%81%E8%AF%84%E8%AE%BA%E6%95%B0%E6%8D%AE/"},{"categories":["写作"],"content":"反反爬 这里面学问比较多，对效率要求不高的话，可以设置停留时间，休息一会儿再请求服务器 模拟随机的UserAgent，就像是换个浏览器 这个时候就要安利下fake_useragent import time import numpy as np from fake_useragent import UserAgent # 随机休息3-10秒 time.sleep(np.random.randint(3,10)) # useragent ua = UserAgent() ua.random 其实，最好的方法是随机更换IP地址 ","date":"2020-04-05","objectID":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%8B%8F%E5%AE%81%E8%AF%84%E8%AE%BA%E6%95%B0%E6%8D%AE/:3:2","tags":["论文专题"],"title":"【论文专题】苏宁易购评论爬虫","uri":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%8B%8F%E5%AE%81%E8%AF%84%E8%AE%BA%E6%95%B0%E6%8D%AE/"},{"categories":["写作"],"content":"增强稳健性 为了保证代码的正常运行，预判会报错的地方，采取相应的方式 爬虫主要是以放服务器拒绝请求 我的方式比较粗暴，歇息时间长一点继续工作 try: clusterId = get_clusterId(product_id,ua.random) except: time.sleep(np.random.randint(5,15)) continue ","date":"2020-04-05","objectID":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%8B%8F%E5%AE%81%E8%AF%84%E8%AE%BA%E6%95%B0%E6%8D%AE/:3:3","tags":["论文专题"],"title":"【论文专题】苏宁易购评论爬虫","uri":"/2020/04/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E8%8B%8F%E5%AE%81%E8%AF%84%E8%AE%BA%E6%95%B0%E6%8D%AE/"},{"categories":["数据分析","写作"],"content":"Bootstrapping基本思想 之前几篇关于 中介效应 有调节的中介效应模型 文章中都有提到 Bootstrapping 这篇就简单的记录Bootstrapping 的基本思想 平时在做分析的时候，总体的数据往往是比较难获取的 所以，我们会基于抽样理论，从总体中抽取具有代表性的样本去估计总体的信息 比如用样本均值 $\\bar X$ 估计总体均值 $\\mu$ ；样本方差 $S^2$ 估计总体方差 $\\sigma^2$ 等等 或者用区间估计的方法给出总体的均值的置信区间 本文以样本均值估计总体均值为例，探究Bootstrap方法的实现方式 Bootstrapping1 是一种重采样的方法（resampling method） 之前有提到，从总体中进行抽样，得到样本数据， $x_1,x_2,…,x_n$ 而Bootstrapping呢，从得到的样本中再进行有放回的抽样 如果抽样个数等于样本数据个数（$n$），则称其为 Bootstrap Sample $$ S_i^={x_{i1}^,x_{i2}^,…,x_{in}^} $$ 以这种方式不断的对样本进行重采样，就会得到 bootstrap samples，$S^*$ $$ S^={S_{1}^,S_{2}^,…,S_{R}^} $$ 其中，$R$ 一般要大于等于1000 $R$ 便是对应着 number of bootstrap samples 的选择 Bootstrapping 估计样本均值就是先分别计算 $R$ 个Bootstrap Sample的均值，最后再计算 $R$ 个均值的均值 Python代码示例 import numpy as np # 假设总体为X X = np.random.normal(size=10000000) # 抽样 n = 1000 x_i = np.random.permutation(X)[:n] # Bootstrapping估计 R = 5000 boot_samples = [x_i[np.random.randint(0,n,n)].mean() for _ in range(R)] boot_mean = np.sum(boot_samples) / R 当然，也可以给出均值的 Bootstrap置信区间 需要先将每个Bootstrap Sample得到的均值从小到大排序 进而计算 $\\alpha /2$ 及 $(1- \\alpha/2)$ 分位数作为区间的上下限 s_sorted = np.sort(boot_samples) alpha = 0.05 s_sorted[[round(R*alpha/2), round(R*(1-alpha/2))]] ","date":"2020-03-30","objectID":"/2020/03/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-bootstrapping/:0:0","tags":["论文专题"],"title":"【论文专题】Bootstrapping","uri":"/2020/03/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-bootstrapping/"},{"categories":["数据分析","写作"],"content":"参考资料 Brad Efron: http://www.jstor.org/discover/10.2307/2958830?uid=3739568\u0026uid=2\u0026uid=4\u0026uid=3739256\u0026sid=21102342537691 ↩︎ ","date":"2020-03-30","objectID":"/2020/03/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-bootstrapping/:1:0","tags":["论文专题"],"title":"【论文专题】Bootstrapping","uri":"/2020/03/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-bootstrapping/"},{"categories":["数据分析","写作"],"content":"在营销、管理领域，发现 $X$ 会影响 $Y$ 后，还会进一步的琢磨是如何影响，回答一个关于 HOW 的问题。 我觉得是沿用了心理学的研究方法，这里就不谈流派了，毕业要紧 所以憋论文的时候除了找到变量 $X$、$Y$，往往还要憋个变量 $M$ 出来，这个变量 $M$ 就用来回答 $X$ 如何影响 $Y$，$M$ 被称为中介变量（Mediator Variable） 为了得到因果关系，之后往往会设计实验，以问卷的形式收集数据，最后用统计学的方法一顿操作验证 $X$ 是否会影响 $M$ 进而影响 $Y$ 这篇就是记录如何用 PROCESS1 完成中介效应的分析，以简单的中介效应模型为例。 ","date":"2020-03-24","objectID":"/2020/03/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E4%B8%AD%E4%BB%8B%E6%95%88%E5%BA%94%E5%88%86%E6%9E%90/:0:0","tags":["论文专题"],"title":"【论文专题】中介效应分析","uri":"/2020/03/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E4%B8%AD%E4%BB%8B%E6%95%88%E5%BA%94%E5%88%86%E6%9E%90/"},{"categories":["数据分析","写作"],"content":"1 理论部分 上图的理论模型用数学数学语言可写为 $$ M = i_M+aX+e_M $$ $$ Y = i_Y + c^,X + bM + e_Y $$ 正如下图所示 直接效应 $c^,$ 表示 $X$ 影响 $Y$ 的直接效应 $$ c^,=[\\widehat{Y}|(X=x+1,M=m)] - [\\widehat{Y}|(X=x,M=m)] $$ $c^,$ 可解释为：在变量 $M$ 保持不变的情况下，自变量 $X$ 增加一个单位，因变量 $Y$ 均值变化 $c^,$ 。 间接效应（indirect effect） 将公式$\\ref{M}$ 代入公式$\\ref{Y}$，可发现系数 $a \\times b$ 便是估计中介效应的，所以中介效应是否存在，就需要关注系数 $ab$ 的情况了 PROCESS也是采用最小二乘法得到系数的 但PROCESS特别的地方在于，他是采用 Bootstrap Confidence Interval 的方法对检验以下假设 $$ H0: ab=0 $$ 「MARK」之后再另起灶炉简单扯一点Bootstrapping 用PROCESS做中介效应分析，结果的最后会给出间接效应的 95% bootstrap confidence interval 如果区间内不包含0，则说明中介效应成立 ","date":"2020-03-24","objectID":"/2020/03/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E4%B8%AD%E4%BB%8B%E6%95%88%E5%BA%94%E5%88%86%E6%9E%90/:1:0","tags":["论文专题"],"title":"【论文专题】中介效应分析","uri":"/2020/03/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E4%B8%AD%E4%BB%8B%E6%95%88%E5%BA%94%E5%88%86%E6%9E%90/"},{"categories":["数据分析","写作"],"content":"2 实际操作 步骤如下： SPSS加载 process的语法文件 使用过程中可以自主编写语法、也可以菜单式的操作 变量和数据字段一一对应 基于理论研究模型，选择PROCESS的模型（本例对应的是model 4） 我感觉这也算是PROCESS的一个弊端吧，灵活性不高。 其他可选 number of bootstrap samples 一般是5000，数据量小的时候可往大了选 选项(options) 标准化、中心化、产生画图的数据 调节效应分析中，spotlight analysis 选择16th、84th分位数表示低高，还是选择 均值±标准差 表示低、高 多分类变量的处理 如果是二分类（dichotomous）就不管 因为多分类变量(假设4类)的1，2，3，4并没有意义，只是表示不同的类别而已，一般通过indicator coding（也叫dummy coding）的方式将变量转为dummy variable ，用 $4-1=3$ 个字段表示 一顿操作之后，便可得到如下结果 正如理论部分所说，是否存在中介效应， 就看结果中 Indirect effect(s) of X on Y 的部分 Bootstrap置信区间不包含0，则说明中介效应存在。 ","date":"2020-03-24","objectID":"/2020/03/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E4%B8%AD%E4%BB%8B%E6%95%88%E5%BA%94%E5%88%86%E6%9E%90/:2:0","tags":["论文专题"],"title":"【论文专题】中介效应分析","uri":"/2020/03/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E4%B8%AD%E4%BB%8B%E6%95%88%E5%BA%94%E5%88%86%E6%9E%90/"},{"categories":["数据分析","写作"],"content":"参考资料 Hayes A F: Introduction_to_Mediation_Moderation_and_Conditional_Process_Analysis_A_Regression_Based[M].2ed.2018 ↩︎ ","date":"2020-03-24","objectID":"/2020/03/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E4%B8%AD%E4%BB%8B%E6%95%88%E5%BA%94%E5%88%86%E6%9E%90/:3:0","tags":["论文专题"],"title":"【论文专题】中介效应分析","uri":"/2020/03/%E8%AE%BA%E6%96%87%E4%B8%93%E9%A2%98-%E4%B8%AD%E4%BB%8B%E6%95%88%E5%BA%94%E5%88%86%E6%9E%90/"}]