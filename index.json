[{"categories":["写作"],"content":"将博客源文件托管在某个地方，换台电脑继续编辑。再加上触发机制更好，即一上传⏫就同步更新博客～ 在之前快速搭建个人博客的文章中有提到 将 public 文件夹下的文件推送至GitHub仓库 每次这么操作还是有点繁琐的，所以就想如果更新完hugo源文件，博客自动更新就好了。此外，换台电脑💻，依然正常操作就更更更好了～ 终于，是找到了GitHub的 Actions 中 Workflows 功能 将Hugo源文件维护在GitHub上，只要源文件的仓库更新，自动更新存有 public 文件的仓库，那么博客也就随之更新了。 在此记录下实现过程 👇 ","date":"2021-07-14","objectID":"/posts/20210714-workflows/:0:0","tags":["blog"],"title":"远程管理hugo源文件以自动更新blog","uri":"/posts/20210714-workflows/"},{"categories":["写作"],"content":"1. 生成SSH key （Windows 环境）参考这个 通过git bash cd 至 .ssh 文件夹 cd ~/.ssh/ 如果提示 No such file or directory，可以手动的创建一个 .ssh文件夹，BY mkdir ~/.ssh 配置全局 name 和 email git config --global user.name \"你的用户名\" git config --global user.email \"你的公司或个人邮箱\" 生成 key ssh-keygen -t rsa -C \"你的公司或个人邮箱\" 连续按 3 次回车 最后得到俩文件： id_rsa 和 id_rsa.pub ","date":"2021-07-14","objectID":"/posts/20210714-workflows/:1:0","tags":["blog"],"title":"远程管理hugo源文件以自动更新blog","uri":"/posts/20210714-workflows/"},{"categories":["写作"],"content":"2. 创建并配置仓库参考这个 ","date":"2021-07-14","objectID":"/posts/20210714-workflows/:2:0","tags":["blog"],"title":"远程管理hugo源文件以自动更新blog","uri":"/posts/20210714-workflows/"},{"categories":["写作"],"content":"2.1 配置hugo源文件的仓库仓库名称不限，在此以 unclehuzi.github.io.source 为例 进入unclehuzi.github.io.source仓库，添加Secrets，名称为ACTIONS_DEPLOY_KEY，将 id_rsa 文件的内容粘过去，得到内容如下所示 上传 hugo源文件 把 themes 主题文件夹中的 .git 文件删除 不然Github 会检测到是别的仓库，上传后文件夹是灰色的 ","date":"2021-07-14","objectID":"/posts/20210714-workflows/:2:1","tags":["blog"],"title":"远程管理hugo源文件以自动更新blog","uri":"/posts/20210714-workflows/"},{"categories":["写作"],"content":"2.2 配置 unclehuzi.github.io 仓库仓库名称有讲究，得是这个 github_user_name.github.io 进入unclehuzi.github.io 仓库，添加Deploy keys ，名称不限制，将id_rsa.pub文件的内容粘过去。 ","date":"2021-07-14","objectID":"/posts/20210714-workflows/:2:2","tags":["blog"],"title":"远程管理hugo源文件以自动更新blog","uri":"/posts/20210714-workflows/"},{"categories":["写作"],"content":"2.3 配置工作流（Workflows）进入unclehuzi.github.io.source仓库，创建 Actions 代码如下 👇 name:Deploy Hugo Site to Github Pages on Master Branchon:push:branches:- master # Attention 1jobs:build-deploy:runs-on:ubuntu-lateststeps:- uses:actions/checkout@v2- name:Setup Hugouses:peaceiris/actions-hugo@v2with:hugo-version:'0.83.1'extended:true# 使用扩展版# Attention 2- name:Buildrun:hugo#--minify- name:Deployuses:peaceiris/actions-gh-pages@v3with:deploy_key:${{ secrets.ACTIONS_DEPLOY_KEY }}# 这里的 ACTIONS_DEPLOY_KEY 则是上面设置 Private Key的变量名external_repository:unclehuzi/unclehuzi.github.io# Pages 远程仓库 publish_dir:./publickeep_files:false# remove existing filespublish_branch:master # deploying branch# Attention 3commit_message:${{ github.event.head_commit.message }} 备注 Attention 1 source 仓库的分支名称为 master Attention 2 hugo 的版本 Attention 3 unclehuzi.github.io 仓库的分支名称 ","date":"2021-07-14","objectID":"/posts/20210714-workflows/:2:3","tags":["blog"],"title":"远程管理hugo源文件以自动更新blog","uri":"/posts/20210714-workflows/"},{"categories":["写作"],"content":"3. Finished 以后维护好source这个仓库就能实现 触发机制以自动更新blog 换个电脑 💻 继续写blog ","date":"2021-07-14","objectID":"/posts/20210714-workflows/:3:0","tags":["blog"],"title":"远程管理hugo源文件以自动更新blog","uri":"/posts/20210714-workflows/"},{"categories":["写作"],"content":"Reference https://jinnzy.github.io/shi-yong-hugolai-da-jian-ge-ren-blog/#%E5%88%A9%E7%94%A8github-pages%E9%83%A8%E7%BD%B2blog https://www.jianshu.com/p/95262f5eba7a ","date":"2021-07-14","objectID":"/posts/20210714-workflows/:4:0","tags":["blog"],"title":"远程管理hugo源文件以自动更新blog","uri":"/posts/20210714-workflows/"},{"categories":["数据分析","机器学习"],"content":"RT，SQL计算多个变量的IV（Information Value） ","date":"2021-07-08","objectID":"/posts/20210708-sql%E8%AE%A1%E7%AE%97iv/:0:0","tags":["Model","SQL"],"title":"SQL计算多个变量的IV","uri":"/posts/20210708-sql%E8%AE%A1%E7%AE%97iv/"},{"categories":["数据分析","机器学习"],"content":"背景变量的预测能力往往可以通过IV值来判断，类似之前的 SQL计算PSI IV值也有经验区间供参考，以及可通过SQL完成指标的计算 Information Value Predictive Power \u003c 0.02 useless for prediction 0.02 - 0.1 weak predictor 0.1 - 0.3 medium predictor 0.3 - 0.5 strong predictor \u003e 0.5 suspicious or too good ","date":"2021-07-08","objectID":"/posts/20210708-sql%E8%AE%A1%E7%AE%97iv/:1:0","tags":["Model","SQL"],"title":"SQL计算多个变量的IV","uri":"/posts/20210708-sql%E8%AE%A1%E7%AE%97iv/"},{"categories":["数据分析","机器学习"],"content":"计算公式关于 IV 的详细介绍，可参考这篇文章 具体计算公式如下 $$IV=\\sum_{i=1}^{n}(\\frac{Bad_i}{Bad_T} - \\frac{Good_i}{Good_T}) \\times WOE_i$$ 其中， $$WOE_i=\\ln(\\frac{Bad_i}{Bad_T}) - \\ln(\\frac{Good_i}{Good_T})$$ 公式说明 Bad、Good即表示正负样本，风控场景有好、坏的称呼 $n$ 为分箱的个数 $Bad_i$, $Good_i$ 表示第i个箱子“坏”、“好”人数 $Bad_T$, $Good_T$ 表示“坏”、“好”总人数 ","date":"2021-07-08","objectID":"/posts/20210708-sql%E8%AE%A1%E7%AE%97iv/:2:0","tags":["Model","SQL"],"title":"SQL计算多个变量的IV","uri":"/posts/20210708-sql%E8%AE%A1%E7%AE%97iv/"},{"categories":["数据分析","机器学习"],"content":"计算样例分箱方式：等频（缺失值单独划为一箱） score_group group_bad_i group_good_i woe_i iv_i r1 271 31882 0.218363 0.0054 r2 225 30572 0.074301 0.0006 r3 195 29107 -0.01969 0.0000 r4 188 28761 -0.04429 0.0002 r5 163 28400 -0.17435 0.0025 r6 182 27387 -0.02778 0.0001 r7 194 28058 0.01187 0.0000 r8 160 24564 -0.04782 0.0002 r9 158 29625 -0.24774 0.0052 r10 70 17302 -0.52404 0.0118 missing 327 36519 0.270413 0.0098 以上例子最终得到 $IV=\\sum_{i=1}^{11}(IV_i)=0.0358$ ","date":"2021-07-08","objectID":"/posts/20210708-sql%E8%AE%A1%E7%AE%97iv/:3:0","tags":["Model","SQL"],"title":"SQL计算多个变量的IV","uri":"/posts/20210708-sql%E8%AE%A1%E7%AE%97iv/"},{"categories":["数据分析","机器学习"],"content":"SQL实现准备好预测变量（$X$）和目标变量（$y$），score表形如 ym no x1 x2 x3 x4 y 202101 a1 617 481 773 671.68 1 202102 a2 585 585 522 600.56 0 202102 a3 617 548 677 635.68 1 202102 a4 647 null 765 655.63 0 202102 a5 596 478 656 635.3 0 202102 a6 636 618 595 630 0 202102 a7 714 572 842 644.28 0 202012 a8 null 495 720 628.79 0 202012 a9 636 618 595 426 0 202012 a10 557 562 null 589 1 基于此得到各个变量在不同月份的预测能力 这里依然涉及窗口函数的应用以及行列互转 窗口函数-聚合 窗口函数-排序 窗口函数的“窗口” 行转列、列转行 思路 类似PSI的计算思路，计算IV的整体思路依然参照公式，（等频）分箱后，基于数据的断点（Breakpoint Value）统计出每个箱子的好坏人数 ","date":"2021-07-08","objectID":"/posts/20210708-sql%E8%AE%A1%E7%AE%97iv/:4:0","tags":["Model","SQL"],"title":"SQL计算多个变量的IV","uri":"/posts/20210708-sql%E8%AE%A1%E7%AE%97iv/"},{"categories":["数据分析","机器学习"],"content":"1. 列转行将score表进行列转行，变为key-value 键值对的形式 droptableifexistsscore_value;createtablescore_valueasselectno,ym,y,score,score_valuefrom(selectno,ym,x1,x2,x3,x4,yfromscore)lateralviewouterexplode(map('x1',x1,'x2',x2,'x3',x3,'x4',x4))tasscore,score_value; ","date":"2021-07-08","objectID":"/posts/20210708-sql%E8%AE%A1%E7%AE%97iv/:4:1","tags":["Model","SQL"],"title":"SQL计算多个变量的IV","uri":"/posts/20210708-sql%E8%AE%A1%E7%AE%97iv/"},{"categories":["数据分析","机器学习"],"content":"2. 分箱统计好坏人数这里采用的是 等频分箱 droptableifexistsscore_group_nums;createtablescore_group_numsasselectym,score,score_group,group_bad_i,group_good_i,sum(group_bad_i)over(partitionbyym,score)asgroup_bad_total,sum(group_good_i)over(partitionbyym,score)asgroup_good_totalfrom(selectym,score,score_group,count(casewheny=1thennoend)asgroup_bad_i,count(casewheny=0thennoend)asgroup_good_ifrom(selecta.*,casewhena.score_valueisnullora.score_valuein('','null','NULL')then'missing'whena.score_value\u003c=r.score_array[0]then'r1'whena.score_value\u003c=r.score_array[1]then'r2'whena.score_value\u003c=r.score_array[2]then'r3'whena.score_value\u003c=r.score_array[3]then'r4'whena.score_value\u003c=r.score_array[4]then'r5'whena.score_value\u003c=r.score_array[5]then'r6'whena.score_value\u003c=r.score_array[6]then'r7'whena.score_value\u003c=r.score_array[7]then'r8'whena.score_value\u003c=r.score_array[8]then'r9'whena.score_value\u003c=r.score_array[9]then'r10'endasscore_groupfromscore_valuealeftjoin(-- 等频分箱 10 bins selectym,score,percentile_approx(score_value,array(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1),999999)asscore_arrayfromscore_valuegroupby1,2)ron(a.ym=r.ymanda.score=r.score))groupby1,2,3); ","date":"2021-07-08","objectID":"/posts/20210708-sql%E8%AE%A1%E7%AE%97iv/:4:2","tags":["Model","SQL"],"title":"SQL计算多个变量的IV","uri":"/posts/20210708-sql%E8%AE%A1%E7%AE%97iv/"},{"categories":["数据分析","机器学习"],"content":"3. 计算IV回顾下公式 $$IV=\\sum_{i=1}^{n}(\\frac{Bad_i}{Bad_T} - \\frac{Good_i}{Good_T}) \\times WOE_i$$ 其中， $$WOE_i=\\ln(\\frac{Bad_i}{Bad_T}) - \\ln(\\frac{Good_i}{Good_T})$$ selectym,score,sum(iv_i)asivfrom(selectym,score,score_group,(ln(group_bad_i/group_bad_total)-ln(group_good_i/group_good_total))*(group_bad_i/group_bad_total-group_good_i/group_good_total)asiv_ifromscore_group_nums)groupby1,2 ","date":"2021-07-08","objectID":"/posts/20210708-sql%E8%AE%A1%E7%AE%97iv/:4:3","tags":["Model","SQL"],"title":"SQL计算多个变量的IV","uri":"/posts/20210708-sql%E8%AE%A1%E7%AE%97iv/"},{"categories":["数据分析","机器学习"],"content":"总结在非建模场景，只想大概看下（或监控）各变量的预测能力时，为省去导出数据用Python计算IV的麻烦，本文便以IV的计算公式出发详细记录SQL计算过程 ","date":"2021-07-08","objectID":"/posts/20210708-sql%E8%AE%A1%E7%AE%97iv/:5:0","tags":["Model","SQL"],"title":"SQL计算多个变量的IV","uri":"/posts/20210708-sql%E8%AE%A1%E7%AE%97iv/"},{"categories":["数据分析","机器学习"],"content":"RT，SQL批量计算各个模型分的PSI，更方便的搭建模型分稳定性的监控，满足模型应用的充分条件 — 样本分布一致性 ","date":"2021-06-18","objectID":"/posts/20210619-sql%E8%AE%A1%E7%AE%97psi/:0:0","tags":["Model","SQL","Python"],"title":"SQL计算多个模型分的PSI","uri":"/posts/20210619-sql%E8%AE%A1%E7%AE%97psi/"},{"categories":["数据分析","机器学习"],"content":"背景应用模型的一大前提便是建模样本尽量和实际生产样本在分布上保持一致性，保证跨期层面的准确性 当模型分偏移到一定程度时，也该考虑迭代一版了 偏移程度可以用 PSI 这个指标来评价，而对于这个程度业界有个经验值1 psi PSI \u003c 0.1: no significant population change PSI \u003c 0.2: moderate population change PSI \u003e= 0.2: significant population change ","date":"2021-06-18","objectID":"/posts/20210619-sql%E8%AE%A1%E7%AE%97psi/:1:0","tags":["Model","SQL","Python"],"title":"SQL计算多个模型分的PSI","uri":"/posts/20210619-sql%E8%AE%A1%E7%AE%97psi/"},{"categories":["数据分析","机器学习"],"content":"计算公式关于PSI的详细介绍，可参考我司模型大佬的这篇文章 具体计算公式如下 $$PSI=\\sum_{i=1}^{n}((Actual_i\\% - Expected_i\\%)\\times \\ln(\\frac{Actual_i\\%}{Expected_i\\%}))$$ 公式说明 n 为分箱的个数 $Actual_i\\%$ 表示第i个箱子的实际占比 $Expected_i\\%$ 表示第i个箱子的预期占比，（称其为比较的基准） ","date":"2021-06-18","objectID":"/posts/20210619-sql%E8%AE%A1%E7%AE%97psi/:2:0","tags":["Model","SQL","Python"],"title":"SQL计算多个模型分的PSI","uri":"/posts/20210619-sql%E8%AE%A1%E7%AE%97psi/"},{"categories":["数据分析","机器学习"],"content":"计算样例以某一个模型分为例，计算跨期的psi bucket excepted_num except_rate actual_num actual_rate psi 1 26780 0.1010 31779 0.1359 0.01036 2 26355 0.0994 27439 0.1173 0.00298 3 26532 0.1000 26008 0.1112 0.00118 4 27416 0.1034 25816 0.1104 0.00046 5 26495 0.0999 24113 0.1031 0.00010 6 26588 0.1002 23146 0.0990 0.00002 7 25957 0.0979 21176 0.0905 0.00057 8 27530 0.1038 21442 0.0917 0.00150 9 25898 0.0976 18310 0.0783 0.00428 10 25710 0.0969 14682 0.0628 0.01484 以上例子最终得到 $PSI=\\sum_{i=1}^{10}(psi)=0.0362$ ","date":"2021-06-18","objectID":"/posts/20210619-sql%E8%AE%A1%E7%AE%97psi/:3:0","tags":["Model","SQL","Python"],"title":"SQL计算多个模型分的PSI","uri":"/posts/20210619-sql%E8%AE%A1%E7%AE%97psi/"},{"categories":["数据分析","机器学习"],"content":"SQL实现 我们希望得到的是从存有各个模型分的表（命名为 score）得到上图👆，score表样例如下 no week scoreA scoreB scoreC scoreD scoreE a1 9 617 481 773 671.68 561 a2 2 585 585 522 600.56 588 a3 16 617 548 677 635.68 563 a4 7 647 564 765 655.63 586 a5 12 596 478 656 635.3 586 a6 7 636 618 595 630 572 a7 22 714 572 842 644.28 563 a8 23 638 495 720 628.79 563 a9 3 636 618 595 426 526 a10 3 557 562 526 589 535 备注 一行表示该用户对应的各种模型分数，scoreA…scoreE 其中， week 表示第几周，这里以2021年第一周（[2021-01-04,2021-01-10]）的数据作为基准，即 excepted 这里会涉及之前一些文章的知识点 窗口函数-聚合 窗口函数-排序 窗口函数的“窗口” 行转列、列转行 思路 整体思路还是跟着 PSI 的计算公式走，按照某种方式（等频 / 等距）将基准的数据分成 n 箱子，基于基准数据的断点（Breakpoint Value）统计实际占比（$Actual$） 为了方便计算，先进行 列转行 ","date":"2021-06-18","objectID":"/posts/20210619-sql%E8%AE%A1%E7%AE%97psi/:4:0","tags":["Model","SQL","Python"],"title":"SQL计算多个模型分的PSI","uri":"/posts/20210619-sql%E8%AE%A1%E7%AE%97psi/"},{"categories":["数据分析","机器学习"],"content":"1. 列转行将score表进行列转行，变为key-value 键值对的形式 droptableifexistsscore_value_weekly;createtablescore_value_weeklyasselectno,week,score,score_valuefrom(selectno,week,score,score_valuefromscorelateralviewexplode(map('scoreA',scoreA,'scoreB',scoreB,'scoreC',scoreC,'scoreD',scoreD,'scoreE',scoreE))tasscore,score_value)wherescore_valueisnotnullandscore_valuenotin('null','NULL'); ","date":"2021-06-18","objectID":"/posts/20210619-sql%E8%AE%A1%E7%AE%97psi/:4:1","tags":["Model","SQL","Python"],"title":"SQL计算多个模型分的PSI","uri":"/posts/20210619-sql%E8%AE%A1%E7%AE%97psi/"},{"categories":["数据分析","机器学习"],"content":"2. 基于基准数据统计各箱nums这里就要分成两种情况： 等频分箱 等距分箱 具体使用哪种分箱方式还是要结合模型分的实际应用情况 但是，当模型分呈现较为严重的偏态分布时，等频分箱会出现好几个箱子重合的情况（如下图所示）。这种情况算出来的PSI会小于真实值，此时可以采用等距分箱 等频分箱 droptableifexistsscore_group_nums_weekly;createtablescore_group_nums_weeklyasselectscore,week,score_group,count(no)asnumsfrom(selecta.*,casewhena.score_value\u003c=r.score_array[0]then'r1'whena.score_value\u003c=r.score_array[1]then'r2'whena.score_value\u003c=r.score_array[2]then'r3'whena.score_value\u003c=r.score_array[3]then'r4'whena.score_value\u003c=r.score_array[4]then'r5'whena.score_value\u003c=r.score_array[5]then'r6'whena.score_value\u003c=r.score_array[6]then'r7'whena.score_value\u003c=r.score_array[7]then'r8'whena.score_value\u003c=r.score_array[8]then'r9'whena.score_value\u003c=r.score_array[9]then'r10'endasscore_groupfromscore_value_weeklyaleftjoin(-- 2. 等频分箱 selectscore,percentile_approx(score_value,array(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1),99999)asscore_arrayfromscore_value_weeklywhereweek=1-- 以第一周为基准 groupby1)rona.score=r.score)groupby1,2,3; 等距分箱等距分箱相比等频分箱而言稍微复杂点，我的思路是先算出基准数据各个模型分区间的上下限，再统计各箱nums -- 10个箱子 -- -- 统计各箱nums droptableifexistsscore_group_nums_weekly;createtablescore_group_nums_weeklyasselectscore,week,nasscore_group,count(no)asnumsfrom(selecta.*,r.n,casewhena.score_value\u003e=r.range_downanda.score_value\u003cr.range_upthen'Y'whena.score_value=r.range_upthen'Y'else'N'endasis_rangefromscore_value_weeklyaleftjoin(-- 基准月各分数间隔 selectscore,n,min_score,max_score,(min_score+(n-1)*step)asrange_down,(min_score+n*step)asrange_upfrom(selecta.*-- 10 箱 ,casewhena.score_value=b.min_scorethen1elseceil(10*(a.score_value-b.min_score)/(b.max_score-b.min_score))endasn,b.min_score,b.max_score,b.stepfrom(select*fromscore_value_weeklywhereweek=1)aleftjoin(selectscore,min(score_value)asmin_score,max(score_value)asmax_score-- 10 个箱子 ,((max(score_value)-min(score_value))/10)asstepfromscore_value_weeklywhereweek=1groupby1)bona.score=b.score)groupby1,2,3,4,5,6)rona.score=r.score)whereis_range='Y'groupby1,2,3; ","date":"2021-06-18","objectID":"/posts/20210619-sql%E8%AE%A1%E7%AE%97psi/:4:2","tags":["Model","SQL","Python"],"title":"SQL计算多个模型分的PSI","uri":"/posts/20210619-sql%E8%AE%A1%E7%AE%97psi/"},{"categories":["数据分析","机器学习"],"content":"3. 计算PSI回顾下公式 $$PSI=\\sum_{i=1}^{n}((Actual_i\\% - Expected_i\\%)\\times \\ln(\\frac{Actual_i\\%}{Expected_i\\%}))$$ droptableifexistsscore_stability_result_weekly;createtablescore_stability_result_weeklyasselecta.*,b.psifrom(-- 各箱nums selectscore,week,score_group_value[\"r1\"]asr1,score_group_value[\"r2\"]asr2,score_group_value[\"r3\"]asr3,score_group_value[\"r4\"]asr4,score_group_value[\"r5\"]asr5,score_group_value[\"r6\"]asr6,score_group_value[\"r7\"]asr7,score_group_value[\"r8\"]asr8,score_group_value[\"r9\"]asr9,score_group_value[\"r10\"]asr10from(-- 行转列 selectscore,week,str_to_map(concat_ws(',',collect_set(concat_ws(':',score_group,nums))))asscore_group_valuefromscore_group_nums_weeklygroupby1,2))aleftjoin(-- psi selectf.score,f.week,sum((f.act_rate-b.exp_rate)*log(f.act_rate/b.exp_rate))aspsifrom(-- Actual selectscore,week,score_group,(nums/sum(nums)over(partitionbyscore,week))asact_ratefromscore_group_nums_weeklywhereweek\u003e1)fleftjoin(-- Excepted selectscore,week,score_group,(nums/sum(nums)over(partitionbyscore,week))asexp_ratefromscore_group_nums_weeklywhereweek=1)bon(f.score=b.scoreandf.score_group=b.score_group)wheref.score_groupisnotnullandf.score_groupnotin('null','NULL')groupby1,2)bon(a.score=b.scoreanda.week=b.week); ","date":"2021-06-18","objectID":"/posts/20210619-sql%E8%AE%A1%E7%AE%97psi/:4:3","tags":["Model","SQL","Python"],"title":"SQL计算多个模型分的PSI","uri":"/posts/20210619-sql%E8%AE%A1%E7%AE%97psi/"},{"categories":["数据分析","机器学习"],"content":"可视化最后，可以用Excel或BI软件完成对应的可视化 可视化 本文选择的是面积图 Python代码示例2 👇 # libraries import numpy as np import matplotlib.pyplot as plt import seaborn as sns import pandas as pd # Make data data = pd.DataFrame({ 'group_A':[1,4,6,8,9], 'group_B':[2,24,7,10,12], 'group_C':[2,8,5,10,6], }, index=range(1,6)) # We need to transform the data from raw data to percentage (fraction) data_perc = data.divide(data.sum(axis=1), axis=0) # Make the plot plt.stackplot(range(1,6), data_perc[\"group_A\"], data_perc[\"group_B\"], data_perc[\"group_C\"], labels=['A','B','C']) plt.legend(loc='upper left') plt.margins(0,0) plt.title('100 % stacked area chart') plt.show() ","date":"2021-06-18","objectID":"/posts/20210619-sql%E8%AE%A1%E7%AE%97psi/:5:0","tags":["Model","SQL","Python"],"title":"SQL计算多个模型分的PSI","uri":"/posts/20210619-sql%E8%AE%A1%E7%AE%97psi/"},{"categories":["数据分析","机器学习"],"content":"总结本文主要是提供了通过SQL计算多个模型分PSI的方案，并采用了等频、等距分箱两种分箱方法，增加了适用性 ","date":"2021-06-18","objectID":"/posts/20210619-sql%E8%AE%A1%E7%AE%97psi/:6:0","tags":["Model","SQL","Python"],"title":"SQL计算多个模型分的PSI","uri":"/posts/20210619-sql%E8%AE%A1%E7%AE%97psi/"},{"categories":["数据分析","机器学习"],"content":"Reference https://mwburke.github.io/data%20science/2018/04/29/population-stability-index.html ↩︎ https://www.python-graph-gallery.com/255-percentage-stacked-area-chart ↩︎ ","date":"2021-06-18","objectID":"/posts/20210619-sql%E8%AE%A1%E7%AE%97psi/:7:0","tags":["Model","SQL","Python"],"title":"SQL计算多个模型分的PSI","uri":"/posts/20210619-sql%E8%AE%A1%E7%AE%97psi/"},{"categories":["数据分析"],"content":"SQL, Python 中解决行转列、列转行的问题 在日常工作中总会遇到类似下图中的问题 👇 备注 我把这种情况称为 行转列 《Python for Data Analysis》 书中将其称为 Pivoting “Wide” to “Long” Format 还有这种问题 👇 备注 我把这种情况称为 列转行 《Python for Data Analysis》 书中将其称为 Pivoting “Long” to “Wide” Format 那么，接下来将针对此类问题，汇总SQL、Python中的实现方式 ","date":"2021-06-15","objectID":"/posts/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/:0:0","tags":["SQL","Python"],"title":"行转列、列转行","uri":"/posts/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/"},{"categories":["数据分析"],"content":"行转列 / “Wide” to “Long” ","date":"2021-06-15","objectID":"/posts/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/:1:0","tags":["SQL","Python"],"title":"行转列、列转行","uri":"/posts/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/"},{"categories":["数据分析"],"content":"SQL运行环境 基于 spark-2.4.5U3 及以上版本 selectscore,ym,score_group_value[\"r1\"]asr1,score_group_value[\"r2\"]asr2,score_group_value[\"r3\"]asr3from(selectscore,ym,str_to_map(concat_ws(',',collect_set(concat_ws(':',range_label,nums))))asscore_group_valuefromscore_group_numsgroupby1,2) 基本思路是将表中 range_label和nums转化为类似json的格式，之后通过 key 索引得到对应的value 这里用的是collect_set()，得到的是聚合、去重后无序的array，若需要有序则可用sort_array() ","date":"2021-06-15","objectID":"/posts/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/:1:1","tags":["SQL","Python"],"title":"行转列、列转行","uri":"/posts/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/"},{"categories":["数据分析"],"content":"Python构造数据 df_wide = pd.DataFrame({'score_name': ['ScoreA']*3 ,'ym': ['202012']*3 ,'range_label': ['r1','r2','r3'] ,'nums': [1110,1105,1054]}) df_wide pivot() 函数 df_wide.pivot(index=['score_name','ym'] ,columns='range_label' ,values=['nums']) ","date":"2021-06-15","objectID":"/posts/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/:1:2","tags":["SQL","Python"],"title":"行转列、列转行","uri":"/posts/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/"},{"categories":["数据分析"],"content":"列转行 / “Long” to “Wide” ","date":"2021-06-15","objectID":"/posts/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/:2:0","tags":["SQL","Python"],"title":"行转列、列转行","uri":"/posts/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/"},{"categories":["数据分析"],"content":"SQL运行环境 基于 spark-2.4.5U3 及以上版本 selectbiz_no,ym,range_label,numsfromscorelateralviewouterexplode(map('r1',r1,'r2',r2,'r3',r3))tasrange_label,nums map 之后，结合 lateral view explode1 实现列转行的问题 ","date":"2021-06-15","objectID":"/posts/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/:2:1","tags":["SQL","Python"],"title":"行转列、列转行","uri":"/posts/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/"},{"categories":["数据分析"],"content":"Python构造数据 df_long = pd.DataFrame({'score_name': ['ScoreA'] ,'ym': ['202012'] ,'r1': [1110] ,'r2': [1105] ,'r3':[1054]}) df_long stack()函数 df_long.set_index(['score_name','ym']).stack(dropna=False).reset_index().rename(columns={\"level_2\": \"range_label\",0:\"nums\"}) ","date":"2021-06-15","objectID":"/posts/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/:2:2","tags":["SQL","Python"],"title":"行转列、列转行","uri":"/posts/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/"},{"categories":["数据分析"],"content":"Reference https://blog.csdn.net/oopsoom/article/details/26001307 ↩︎ ","date":"2021-06-15","objectID":"/posts/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/:3:0","tags":["SQL","Python"],"title":"行转列、列转行","uri":"/posts/hql-%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96/"},{"categories":["数据分析"],"content":"详述“窗口”的概念，结合初中数学中区间的概念来理解\u003cwindow_frame\u003e，并以计算累计占比为例深化理解。此外，也分享了他人整理的窗口函数汇总表 基于之前整理的 排序 聚合 Positional functions: lead(), lag() 在窗口函数应用场景方面算是告一段落了。但是在 “窗口” 这个概念上陈述较少，在窗口函数部分的里程碑之际重新 “定义” “窗口” 另外，之前在浏览网页的时候发现了窗口函数的汇总图 而本文与图中对应的便是 WINDOW FAME 部分 ","date":"2021-06-09","objectID":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E7%AA%97%E5%8F%A3/:0:0","tags":["SQL"],"title":"窗口函数的“窗口”","uri":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E7%AA%97%E5%8F%A3/"},{"categories":["数据分析"],"content":"实现的功能简单来说是定义窗口函数作用的范围（“FRAME”），通过下面这张图1可以更好的了解 FRAME 的概念 一般而言， 一张表（Table）基于WHERE条件的作用得到图中 Result Set 部分； 窗口函数 over() 语句中 partition（若有）得到图中 Partition 1…Partition m fram 语句（若有）在partition基础上得到图中 Frame 1…Frame n ","date":"2021-06-09","objectID":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E7%AA%97%E5%8F%A3/:1:0","tags":["SQL"],"title":"窗口函数的“窗口”","uri":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E7%AA%97%E5%8F%A3/"},{"categories":["数据分析"],"content":"语法、规则 \u003cwindow_frame\u003e:=[rows|range|groups]between[unboundedpreceding|\u003cn\u003epreceding|currentrow]and[unboundedfollowing|\u003cn\u003efollowing|currentrow] 批注 目前，只有 PostgreSQL 11 及以上版本支持 groups \u003cwindow_frame\u003e语句表明，相对于当前行（current row）对应的值而言，还有“区间”的概念，“区间”又受到 rows或range 控制：是行数范围还是值的范围。 rows 对应是行的条件 如rows between 1 preceding and unbounded following 表示最终的范围是排序后（若有），基于当前行的上 1 行和该partition本身的最后一行 range 对应是值的范围 如range between 1 preceding and 2 following 这里我们遵循小学数学中区间的性质：左区间的值小于等于右区间的值 因为涉及到值的范围，这里就要分两种情况讨论了，假设当前行对应的值为 x 顺序排序，即从小到大，order by column asc [x-1,x+2]，左区间为当前行的值减1（x-1）；右区间为当前行的值加2（x+2） 逆序排序，即从大到小，order by column desc [x-2,x+1]，左区间为当前行的值减2（x-2）；右区间为当前行的值加1（x+1） 最后再说明下没有 \u003cwindow_frame\u003e 语句时对应的Frame，此时将取决于是否有order by语句，即 无 \u003cwindow_frame\u003e 语句、有 order by 语句 Frame 为 range between unbounded preceding and current row 即Frame的第一行为该partition的上边界，当前行（current row）为下边界 无 \u003cwindow_frame\u003e 语句、无 order by 语句 Frame 为 rows between unbounded preceding and unbounded following 即Frame的边界就是partition的边界 关于，无\u003cwindow_frame\u003e语句的情况，总结如下 \\ 无 \u003cwindow_frame\u003e 有 order by range between unbounded preceding and current row 无 order by rows between unbounded preceding and unbounded following ","date":"2021-06-09","objectID":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E7%AA%97%E5%8F%A3/:2:0","tags":["SQL"],"title":"窗口函数的“窗口”","uri":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E7%AA%97%E5%8F%A3/"},{"categories":["数据分析"],"content":"应用：一个例子一堆枯涩的陈述，不如直接来个小例子：计算累计占比 实际业务中，在定义模型目标变量y的时候，往往也会结合数据的分布。如，风控场景中定义逾期 x 天以上为bad 假设samples 表中记录着一笔订单的逾期状态，over_due_days 表示逾期天数 希望得到的数据样式如下表所示 over_due_days c_sum c_sum_rate 0 1000 1 1 100 0.1 2 90 0.09 3 85 0.085 4 80 0.08 … … … over_due_days 为1的那一行表示 $逾期天数 \\geq 1$的订单数以及占总订单的比例，即 $$c\\_sum\\_rate=\\frac{over\\_due\\_days \\geq 1 的订单数}{总订单数}$$ selectover_due_days,sum(nums)over(orderbyover_due_daysnullslastrangebetweencurrentrowandunboundedfollowing)asc_sum,sum(nums)over(orderbyover_due_daysnullslastrangebetweencurrentrowandunboundedfollowing)/(selectcount(1)fromsamples)asc_sum_ratefrom(-- 分逾期天数统计订单数量 selectover_due_days,count(1)asnumsfromsamplesgroupby1); ","date":"2021-06-09","objectID":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E7%AA%97%E5%8F%A3/:3:0","tags":["SQL"],"title":"窗口函数的“窗口”","uri":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E7%AA%97%E5%8F%A3/"},{"categories":["数据分析"],"content":"总结本文便是窗口函数部分的“收官之作”了。 主要是对“窗口”的概念展开了详细的陈述，结合初中数学中区间的概念来理解\u003cwindow_frame\u003e，并以计算累计占比为例深化理解。此外，也分享了他人整理的窗口函数 ","date":"2021-06-09","objectID":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E7%AA%97%E5%8F%A3/:4:0","tags":["SQL"],"title":"窗口函数的“窗口”","uri":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E7%AA%97%E5%8F%A3/"},{"categories":["数据分析"],"content":"Reference https://en.wikibooks.org/wiki/Structured_Query_Language/Window_functions ↩︎ ","date":"2021-06-09","objectID":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E7%AA%97%E5%8F%A3/:5:0","tags":["SQL"],"title":"窗口函数的“窗口”","uri":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E7%AA%97%E5%8F%A3/"},{"categories":["数据分析"],"content":"以 “计算当前和上一次事件的时间间隔” 引入 positional function 截止到目前，窗口函数整理了聚合、排序场景，解决了“组内占比”、“定位连续3天登录用户”等问题 在平时的分析工作中，还有个比较常见的问题：计算当前和上一次事件的时间间隔。比如，相邻两次外呼的时间间隔 这个时候，lead() 或 lag() 函数可较为方便的解决该类问题 ","date":"2021-06-09","objectID":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-positionalfunctions/:0:0","tags":["SQL"],"title":"窗口函数-Positional Functions","uri":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-positionalfunctions/"},{"categories":["数据分析"],"content":"实现的功能lead(), lag() 实现的功能比较类似。 ","date":"2021-06-09","objectID":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-positionalfunctions/:1:0","tags":["SQL"],"title":"窗口函数-Positional Functions","uri":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-positionalfunctions/"},{"categories":["数据分析"],"content":"lead() 上移 selectseller_name,sale_value,lead(sale_value)over(orderbysale_value)asnext_sale_valuefromsale; ","date":"2021-06-09","objectID":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-positionalfunctions/:1:1","tags":["SQL"],"title":"窗口函数-Positional Functions","uri":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-positionalfunctions/"},{"categories":["数据分析"],"content":"lag() 下移 selectseller_name,sale_value,lag(sale_value)over(orderbysale_value)asprevious_sale_valuefromsale; ","date":"2021-06-09","objectID":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-positionalfunctions/:1:2","tags":["SQL"],"title":"窗口函数-Positional Functions","uri":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-positionalfunctions/"},{"categories":["数据分析"],"content":"基本语法 lag(expression[,offset[,default_value]])over([partitionbyexpr1,expr2,...]orderbyexpr1[asc|desc],expr2[asc|desc],...)lead(expression[,offset[,default_value]])over([partitionbyexpr1,expr2,...]orderbyexpr1[asc|desc],expr2[asc|desc],...) lead(), lag() 中的3个参数： expression - string 被操作的列名 offset - int 移动的行数（/偏移量） default_value 定义为空的情况赋给的默认值 其中，参数 expression 是必须的。而 default_value（默认是 NULL） 是只有当 offset（默认是 1） 有值时才能使用 over() 语句中，order by 是必须要有的 ","date":"2021-06-09","objectID":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-positionalfunctions/:2:0","tags":["SQL"],"title":"窗口函数-Positional Functions","uri":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-positionalfunctions/"},{"categories":["数据分析"],"content":"应用计算用户相邻两次登录的天数间隔 -- 如果只有1天有登录信息，则 diff_days 为 null select*,datediff(session_date,lag_session_date)asdiff_daysfrom(-- 下移 select*,lag(session_date)over(partitionbyuser_idorderbysession_dateasc)aslag_session_datefrom(-- 按天去重 selectuser_id,date_format(session_time,'yyyyMMdd')assession_datefromtable1groupby1,2)); 窗口函数还有俩常见的：first_value(), last_value()，在此就略过了。 有时候可以用 row_number() over() 结合 having 一起使用，如 确定用户最后一次登录时间 selectuser_id,row_number()over(orderbysession_datedesc)asrkfromtable1havingrk=1; ","date":"2021-06-09","objectID":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-positionalfunctions/:3:0","tags":["SQL"],"title":"窗口函数-Positional Functions","uri":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-positionalfunctions/"},{"categories":["数据分析"],"content":"“抛” 计算组内占比 “引” 聚合窗口函数 窗口函数中 求和（sum）、均值（avg）、极值（max, min）、计数（count）等结合聚合函数使用的场景也较多。 数据分析过程中经常会遇到计算组内占比的情况。 Example 计算 多个模型分以及多个时间段 的 psi 时，（等频/等距）分箱之后计算各箱样本占总样本数的百分比 示例如下表所示， model ym bucket act_rate A 202103 1 0.1209 A 202103 2 0.1148 A 202103 3 0.1089 A 202103 4 0.1041 A 202103 5 0.1004 A 202103 6 0.0983 A 202103 7 0.0984 A 202103 8 0.0937 A 202103 9 0.0892 A 202103 10 0.0714 比较方便的操作方式就是结合 sum() over() 函数计算组内占比。 selectmodel,ym,bucket,(nums/sum(nums)over(partitionbymodel,ym))asact_ratefrommodel_bucket_nums 其他几个聚合函数只是实现的功能不同，最后还是要各取所需了。 ","date":"2021-06-09","objectID":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E8%81%9A%E5%90%88/:0:0","tags":["SQL"],"title":"窗口函数-聚合","uri":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E8%81%9A%E5%90%88/"},{"categories":["数据分析"],"content":"整理排序场景常用函数，row_number() over(), rank() over(), dense_rank() over(), ntile(n) over()，并以连续登录问题为例深化理解 ","date":"2021-06-09","objectID":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/:0:0","tags":["SQL"],"title":"窗口函数-排序","uri":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/"},{"categories":["数据分析"],"content":"row_number() over()","date":"2021-06-09","objectID":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/:1:0","tags":["SQL"],"title":"窗口函数-排序","uri":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/"},{"categories":["数据分析"],"content":"实现的功能从1开始依次排序，生成不会重复的编号 -- 按照nums 列，降序排序 selectid,nums,row_number()over(orderbynumsdesc)asrankfromtable id nums rank 1x 45 3 2x 78 2 3x 87 1 4x 32 4 ","date":"2021-06-09","objectID":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/:1:1","tags":["SQL"],"title":"窗口函数-排序","uri":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/"},{"categories":["数据分析"],"content":"语法 row_number()over([partitionbyexpr1,expr2,...]orderbyexpr1[asc|desc],expr2[asc|desc],...) partition by表示基于某（些）维度（/列）分组之后，再基于order by的规则实现组内排序。 select id ,nums ,row_number() over(partition by id order by nums desc) as rank from table ","date":"2021-06-09","objectID":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/:1:2","tags":["SQL"],"title":"窗口函数-排序","uri":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/"},{"categories":["数据分析"],"content":"应用问题 如何确定连续登录天数超过3天的用户 思路 找到连续3天登录用户所表现的数据特征。比如，按照登录日期排序得到编号，两者作差，若连续登录则作差后的值是一样的 基于这个现象，可用row_number实现 selectuser_id,(session_date-rk)asdiff,count(1)asnumsfrom(select*,row_number()over(partitionbyuser_idorderbysession_date)asrkfrom(-- 按天去重 selectuser_id,date_format(session_time,'yyyyMMdd')assession_datefromtable1groupby1,2))groupby1,2havingnums\u003e=3; ","date":"2021-06-09","objectID":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/:1:3","tags":["SQL"],"title":"窗口函数-排序","uri":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/"},{"categories":["数据分析"],"content":"rank() over()基本语法类似于row_number() rank()over([partitionbyexpr1,expr2,...]orderbyexpr1[asc|desc],expr2[asc|desc],...) 但不同的是，当值相等时 rank() 排序会出现重复序号的情况，且下个序号和当前序号之差为当前相同值的个数 ","date":"2021-06-09","objectID":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/:2:0","tags":["SQL"],"title":"窗口函数-排序","uri":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/"},{"categories":["数据分析"],"content":"示例 selectdealer_id,emp_name,sales,rank()over(orderbysales)asrkfromq1_sales; dealer_id emp_name sales rank 1 Raphael Hull 8227 1 3 May Stout 9308 2 2 Haviva Montoya 9308 2 1 Jack Salazar 9710 4 3 Abel Kim 12369 5 3 Ursa George 15427 6 2 Beverly Lang 16233 7 2 Kameko French 16233 7 1 Ferris Brown 19745 9 1 Noel Meyer 19745 9 ","date":"2021-06-09","objectID":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/:2:1","tags":["SQL"],"title":"窗口函数-排序","uri":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/"},{"categories":["数据分析"],"content":"dense_rank() over()row_number() over() 、 rank() over() 和 dense_rank() over() 之间的差别主要在于对相同值的序号处理方式不同。 和rank() over()一样，遇到相同值时序号会重复，但是dense_rank() over() 的下一个序号和当前序号之差依然是1，不会出现空位的情况。 ","date":"2021-06-09","objectID":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/:3:0","tags":["SQL"],"title":"窗口函数-排序","uri":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/"},{"categories":["数据分析"],"content":"示例 selectdealer_id,emp_name,sales,dense_rank()over(orderbysales)asdenserankfromq1_sales; dealer_id emp_name sales denserank 1 Raphael Hull 8227 1 3 May Stout 9308 2 2 Haviva Montoya 9308 2 1 Jack Salazar 9710 3 3 Abel Kim 12369 4 3 Ursa George 15427 5 2 Beverly Lang 16233 6 2 Kameko French 16233 6 1 Ferris Brown 19745 7 1 Noel Meyer 19745 7 ","date":"2021-06-09","objectID":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/:3:1","tags":["SQL"],"title":"窗口函数-排序","uri":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/"},{"categories":["数据分析"],"content":"ntile(n) over()ntile(n) over() 和之前那三个排序函数不太一样。形式来看，多了个参数n，是指按照顺序平均分成n份（/箱），返回当前所在的位置。且需要order by 语句。 但对于不能实现平均分的情况，会基于约定来操作： 约定 每箱记录数不能大于上一个箱子的记录数。即第1组的记录数大于等于第2组的记录数。 所有箱子的记录数要么相同。要么从某一记录数较少的箱子（命名为X）开始，后面所有箱子内的记录数都与该箱（X）的记录数相同。即如果前3箱的记录数都是9，而第4箱的记录数是8，那么第5、6箱及其之后箱子内的记录数也必须是8。 注意 最先分出来的箱子，采取向上取整（ceil()）的方式 比如，53条记录，基于ntile的约定分到5个箱子，则每个箱子的记录数如下所示 bucket nums 1 11 2 11 3 11 4 10 5 10 备注 ntile的方法能较好实现等频的效果，相比分位数作为分割点而言，不易受数据分布的影响。 ","date":"2021-06-09","objectID":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/:4:0","tags":["SQL"],"title":"窗口函数-排序","uri":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/"},{"categories":["数据分析"],"content":"示例 selectemp_mgr,sales,ntile(5)over(orderbysales)asntilerankfromq1_sales; emp_mgr sales ntilerank Kari Phelps 8227 1 Rich Hernandez 9308 1 Kari Phelps 9710 2 Rich Hernandez 12369 2 Mike Palomino 13181 3 Rich Hernandez 15427 3 Kari Phelps 15547 4 Mike Palomino 16233 4 Dan Brodi 19745 5 Mike Palomino 23176 5 ","date":"2021-06-09","objectID":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/:4:1","tags":["SQL"],"title":"窗口函数-排序","uri":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/"},{"categories":["数据分析"],"content":"总结 窗口函数 返回类型 描述 row_number() int 从1开始依次排序，生成不会重复的序号 rank() int 从1开始依次排序。若值相等则得到同样的序号；且下一个序号将会出现空位，即若2个相等的值序号是1，则下一个序号是3 dense_rank() int 从1开始依次排序。若值相等则得到同样的序号；但下一个序号不会出现空位，即若2个相等的值序号是1，则下一个序号依然是2 ntile(n) int 将分组数据按照顺序平均分成n箱，返回当前值所在位置，n-th ","date":"2021-06-09","objectID":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/:5:0","tags":["SQL"],"title":"窗口函数-排序","uri":"/posts/hql-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0-%E6%8E%92%E5%BA%8F/"},{"categories":["数据分析"],"content":"以官方例子：微博转发关系图为例，说明所需要的数据格式 ","date":"2021-06-07","objectID":"/posts/20210607-%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%85%B3%E7%B3%BB%E5%9B%BE/:0:0","tags":["可视化","pyecharts","Python"],"title":"pyecharts-关系图","uri":"/posts/20210607-%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%85%B3%E7%B3%BB%E5%9B%BE/"},{"categories":["数据分析"],"content":"数据样例 import json from pyecharts import options as opts from pyecharts.charts import Graph with open(\"weibo.json\", \"r\", encoding=\"utf-8\") as f: j = json.load(f) nodes, links, categories, cont, mid, userl = j c = ( Graph(init_opts=opts.InitOpts(width=\"1920px\" ,height=\"1080px\")) .add( \"\", nodes, links, categories, repulsion=900, # 节点之间的斥力因子。值越大则斥力越大 # 支持设置成数组表达斥力的范围，此时不同大小的值会线性映射到不同的斥力。 gravity=0.01, # 节点受到的向中心的引力因子。该值越大节点越往中心点靠拢。 linestyle_opts=opts.LineStyleOpts(curve=0.2), label_opts=opts.LabelOpts(is_show=False), ) .set_global_opts( legend_opts=opts.LegendOpts(is_show=False), title_opts=opts.TitleOpts(title=\"Graph-微博转发关系图\"), ) .render(\"graph_weibo.html\") ) weibo.json 文件，可从 这儿 获取 主要由5部分组成 nodes links categories cont mid userl ","date":"2021-06-07","objectID":"/posts/20210607-%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%85%B3%E7%B3%BB%E5%9B%BE/:1:0","tags":["可视化","pyecharts","Python"],"title":"pyecharts-关系图","uri":"/posts/20210607-%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%85%B3%E7%B3%BB%E5%9B%BE/"},{"categories":["数据分析"],"content":"格式说明说明 本文聚焦在前三个的数据格式说明。每一部分是个list，每个list 又由多个dict组成 以“转发微博”作为场景简单阐述关系图所展示的信息：某位具有影响力的微博用户A 发了条微博，被用户B、C、D看到并转发了；之后，用户E、F、G也转发了B所转发的这篇文章，以此类推 那么，这个过程中涉及到的每个用户便是一个node。为此，也以 nodes作为切入点展开说明 ","date":"2021-06-07","objectID":"/posts/20210607-%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%85%B3%E7%B3%BB%E5%9B%BE/:2:0","tags":["可视化","pyecharts","Python"],"title":"pyecharts-关系图","uri":"/posts/20210607-%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%85%B3%E7%B3%BB%E5%9B%BE/"},{"categories":["数据分析"],"content":"nodes样例如下所示， 记录着节点的信息12， { \"name\": \"Camel3942\", # 节点名称，即博主昵称 \"symbolSize\": 5, # 图中标志大小 \"draggable\": \"False\", # 是否可拖动 \"value\": 1, # 被再次转发次数 \"category\": \"Camel3942\", # From Where \"label\": { # 此博主被再次转发后，含有此标签，否则不含 \"normal\": { \"show\": \"True\" } } } 警告 节点名称（name）不能重复 ","date":"2021-06-07","objectID":"/posts/20210607-%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%85%B3%E7%B3%BB%E5%9B%BE/:2:1","tags":["可视化","pyecharts","Python"],"title":"pyecharts-关系图","uri":"/posts/20210607-%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%85%B3%E7%B3%BB%E5%9B%BE/"},{"categories":["数据分析"],"content":"links个人理解作用是将每个node 连接起来 { \"source\": \"新浪体育\", \"target\": \"Beijingold4\" }, { \"source\": \"Camel3942\", \"target\": \"xiaoA\" } ","date":"2021-06-07","objectID":"/posts/20210607-%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%85%B3%E7%B3%BB%E5%9B%BE/:2:2","tags":["可视化","pyecharts","Python"],"title":"pyecharts-关系图","uri":"/posts/20210607-%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%85%B3%E7%B3%BB%E5%9B%BE/"},{"categories":["数据分析"],"content":"categories而这部分则记录着有被他人转发的用户名称（name），即 links 中 source 所对应的内容 { \"name\": \"新浪体育\" }, { \"name\": \"Camel3942\" } ","date":"2021-06-07","objectID":"/posts/20210607-%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%85%B3%E7%B3%BB%E5%9B%BE/:2:3","tags":["可视化","pyecharts","Python"],"title":"pyecharts-关系图","uri":"/posts/20210607-%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%85%B3%E7%B3%BB%E5%9B%BE/"},{"categories":["数据分析"],"content":"Reference https://blog.csdn.net/qq_35006861/article/details/116721589 ↩︎ https://blog.csdn.net/Kevin_HZH/article/details/91043392 ↩︎ ","date":"2021-06-07","objectID":"/posts/20210607-%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%85%B3%E7%B3%BB%E5%9B%BE/:3:0","tags":["可视化","pyecharts","Python"],"title":"pyecharts-关系图","uri":"/posts/20210607-%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%85%B3%E7%B3%BB%E5%9B%BE/"},{"categories":["数据分析"],"content":"分场景汇总日期函数 工作中总会遇到处理时间的问题，参考营销理论中基于利益细分的市场细分理论，我从使用场景的角度出发，将常用的日期函数分为四大类： 时间计算 时间提取 格式转换 当前时间 Tip 本文重点在于整合日期函数 ","date":"2021-06-06","objectID":"/posts/hql-%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0/:0:0","tags":["SQL"],"title":"Spark, Hive QL-日期函数汇总","uri":"/posts/hql-%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0/"},{"categories":["数据分析"],"content":"时间计算这部分主要是计算时间差（datediff(end_date,start_date), months_between(date1,date2)）、时间加减（date_add(),date_sub(),add_months()）等 ","date":"2021-06-06","objectID":"/posts/hql-%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0/:1:0","tags":["SQL"],"title":"Spark, Hive QL-日期函数汇总","uri":"/posts/hql-%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0/"},{"categories":["数据分析"],"content":"时间提取提取时间戳的年、季度、月、周、日、小时、分钟、秒 可以直接调用对应的函数，也可使用extract(field from column_name) 函数指定 field，其中field 支持day, dayofweek, hour, minute, month, quarter, second, week and year. ","date":"2021-06-06","objectID":"/posts/hql-%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0/:2:0","tags":["SQL"],"title":"Spark, Hive QL-日期函数汇总","uri":"/posts/hql-%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0/"},{"categories":["数据分析"],"content":"格式转换有时为了适应不同时间格式的需求，需要做个转换，如yyyy-MM-dd 或 yyyy-MM-dd HH:mm:ss的形式转为yyyyMMdd 等 常用： to_date() 返回 date 形式的日期，即yyyy-MM-dd date_format() 转为指定格式的时间，如 date_format('2015-04-08','y') =\u003e '2015' ","date":"2021-06-06","objectID":"/posts/hql-%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0/:3:0","tags":["SQL"],"title":"Spark, Hive QL-日期函数汇总","uri":"/posts/hql-%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0/"},{"categories":["数据分析"],"content":"当前时间若需要时间戳格式，则用current_timestamp 若只需要精确到天，即date格式，则用current_date ","date":"2021-06-06","objectID":"/posts/hql-%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0/:4:0","tags":["SQL"],"title":"Spark, Hive QL-日期函数汇总","uri":"/posts/hql-%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0/"},{"categories":["数据分析"],"content":"总结本文重点在于从使用场景的角度出发，整合了hive, spark 环境下常用的日期函数。最后再以表格的形式简单汇总 场景 函数 返回值类型 描述 示例 当前时间 unix_timestamp() bigint 当前 Unix时间戳（e.g. 1622451519 ），但因查询优化问题推荐使用 current_timestamp 当前时间 current_date date 当前日期 2021-05-31 当前时间 current_timestamp timestamp 当前时间戳 2021-05-31 17:12:14.968 - - - - - 格式转换 from_unixtime(bigint unixtime[, string format]) string 数字转为格式形如 2021-05-31 17:12:14 的字符串 格式转换 to_date(string timestamp) date to_date(yyyy-MM-dd HH:mm:ss) =\u003e yyyy-MM-dd 格式转换 date_format(date/timestamp/string ts, string fmt) string 得到指定格式的时间 date_format(‘2015-04-08’, ‘y’) =\u003e ‘2015’ 格式转换 trunc(string date, string format) string 得到被指定format截断的日期，format支持MONTH/MON/MM, YEAR/YYYY/YY trunc(‘2015-03-17’, ‘MM’) =\u003e 2015-03-01 - - - - - 时间提取 year(string date) int 年 时间提取 quarter(date/timestamp/string) int 季度 时间提取 weekofyear(string date) int 该年的第几周 时间提取 month(string date) int 月 时间提取 day(string date) dayofmonth(date) int 日 时间提取 hour(string date) int 小时 时间提取 minute(string date) int 分钟 时间提取 second(string date) int 秒 时间提取 extract(field FROM source) int field 支持day, dayofweek, hour, minute, month, quarter, second, week and year. - - - - - 时间计算 datediff(string enddate, string startdate) int 天数差 datediff(‘2009-03-01’, ‘2009-02-27’) =\u003e 2 时间计算 date_add(date/timestamp/string startdate, tinyint/smallint/int days) date 加（减）x天后的日期 date_add(‘2008-12-31’, 1) =\u003e 2009-01-01, date_add(‘2008-12-31’, -1) =\u003e 2008-12-30 时间计算 date_sub(date/timestamp/string startdate, tinyint/smallint/int days) date 加（减）x天后的日期 date_sub(‘2008-12-31’, 1) =\u003e 2008-12-30, date_sub(‘2008-12-31’, -1) =\u003e 2009-01-01 时间计算 add_months(string start_date, int num_months, output_date_format) string x月后。如果start_date是该月的最后一天 或者 x月后的天数不是“大月”则结果为x月后该月的最后一天 add_months(‘2017-12-31 14:15:16’, 2, ‘YYYY-MM-dd HH:mm:ss’) =\u003e ‘2018-02-28 14:15:16’ 时间计算 last_day(string date) string 该月最后一天的日期 last_day(2021-05-11) =\u003e ‘2021-05-31’ 时间计算 next_day(string start_date, string day_of_week) string 返回大于 start_date 的日期中最近的一个周x next_day(‘2021-05-31’,‘Monday’) 时间计算 months_between(date1, date2) double date1-date2 月数差 months_between(‘1997-02-28 10:30:00’, ‘1996-10-30’) =\u003e 3.94959677 ","date":"2021-06-06","objectID":"/posts/hql-%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0/:5:0","tags":["SQL"],"title":"Spark, Hive QL-日期函数汇总","uri":"/posts/hql-%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0/"},{"categories":["写作"],"content":"详述Hugo+Github搭建个人博客 受我司同期大佬的影响，我也便搭建个人博客折腾下，记录点什么~ 在这demo成型之际，以小白视角记录下基于 HuGo 和 Github 完成搭建的历程 所以，最初的准备工作便是（假设已安装Git） ","date":"2021-06-05","objectID":"/posts/20210528-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/:0:0","tags":["blog"],"title":"快速搭建个人博客","uri":"/posts/20210528-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"categories":["写作"],"content":"安装 Hugo可以参考官方文档完成在Windows, Mac等平台的安装 虽然HuGo是基于Go语言编写的，但并不是一定要安装Go才能使用HuGo。可跨平台 在此，以 Windows 系统为例记录安装过程 在这儿下载对应的压缩包 解压 hugo_0.83.1_Windows-64bit.zip解压后得到的文件如下图所示 添加至环境变量 将hugo.exe文件放入bin文件夹（若无可新建） 验证是否安装成功 hugo version # hugo v0.83.1-5AFE0A57 windows/amd64 BuildDate=2021-05-02T14:38:05Z VendorInfo=gohugoio 本地创建博客 终端 cd 至某个文件下 hugo new site unclehuzi # blog目录就是创建的博客目录 # Congratulations! Your new Hugo site is created in D:\\unclehuzi. # Just a few more steps and you're ready to go: # 1. Download a theme into the same-named folder. # Choose a theme from https://themes.gohugo.io/ or # create your own with the \"hugo new theme \u003cTHEMENAME\u003e\" command. # 2. Perhaps you want to add some content. You can add single files # with \"hugo new \u003cSECTIONNAME\u003e\\\u003cFILENAME\u003e.\u003cFORMAT\u003e\". # 3. Start the built-in live server via \"hugo server\". # Visit https://gohugo.io/ for quickstart guide and full documentation. tree unclehuzi/ ##### D:\\unclehuzi ├─archetypes ├─content # 博客文章存放目录（markdown文件） ├─data ├─layouts ├─static # 静态文件/图片/CSS/JS文件 ├─themes # 博客主题模板存放目录 └─config.toml # 博客的配置文件 选择主题 我选择的是 Maupassant，通过Git 的方式获取 # cd 至 unclehuzi 文件夹 git clone https://github.com/flysnow-org/maupassant-hugo themes/maupassant cp themes/maupassant/exampleSite/config.toml . # 使用模板自带的配置文件替换默认配置文件 mkdir content/post # 创建博客文章md文件存放路径（该主题模板要求放在content/post目录下） 根据需要调整 D:\\unclehuzi\\config.toml 文件 baseURL = \"your_github_name.github.io\" # 修改为博客的网址，此处使用github pages地址，后面具体介绍 languageCode = \"zh-CN\" title = \"胡子叔叔的小站\" # 博客的名字 theme = \"maupassant\" 具体可以参考 官方说明 进行配置 本地测试 # cd D:\\unclehuzi hugo new post/my-first-blog.md vim content/post/my-first-blog.md # 以下为md文件内容 +++ title=\"My First Blog\" tags=[\"blog\"] categories=[\"博客相关\"] date=2020-01-16T10:37:32+08:00 draft=false # 此处要改为false，否则在首页不会显示！ +++ #### Hello World! 通过 hugo server -D 命令启动，访问 http://localhost:1313/ 即可 ","date":"2021-06-05","objectID":"/posts/20210528-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/:1:0","tags":["blog"],"title":"快速搭建个人博客","uri":"/posts/20210528-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"categories":["写作"],"content":"建立博客专属的仓库主要的事情说三遍： Repository name 填 github名字.github.io，如 unclehuzi.github.io Repository name 填 github名字.github.io，如 unclehuzi.github.io Repository name 填 github名字.github.io，如 unclehuzi.github.io 仓库创建完成之后记得修改 D:\\unclehuzi\\config.toml 文件的 baseURL ","date":"2021-06-05","objectID":"/posts/20210528-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/:2:0","tags":["blog"],"title":"快速搭建个人博客","uri":"/posts/20210528-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"categories":["写作"],"content":"生成 public 文件创建完成之后，通过 hugo 生成 public 文件 hugo --theme=maupassant --baseUrl=\"https://your_github_name.github.io\" # theme为主题模板名称，url为上一步创建的github仓库名称 ","date":"2021-06-05","objectID":"/posts/20210528-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/:2:1","tags":["blog"],"title":"快速搭建个人博客","uri":"/posts/20210528-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"categories":["写作"],"content":"通过 git 命令将 public 文件推送至仓库 cd D:\\unclehuzi\\public # 1. 初始化 git init # 2. 将文件夹下所有文件加入本地仓库 git add . # 3. 添加注释 git commit -m \"comments\" # git commit -m \"updates $(date)\" # 4. 建立连接 BY HTTPS git remote add origin https://github.com/unclehuzi/unclehuzi.github.io.git # 5. 远程仓库拉到本地（如果远程仓库内没有文件可跳过步骤5） git pull --rebase origin master # 之后更新本地： git pull origin master # 6. 上传 push git push -u origin master # git push -u origin master -f # 强制上传 # 备注 # 和远程建立连接之后，执行 2-3-6 步骤即可。 最后，访问 https://your_github_name.github.io 即可 ","date":"2021-06-05","objectID":"/posts/20210528-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/:2:2","tags":["blog"],"title":"快速搭建个人博客","uri":"/posts/20210528-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"categories":["写作"],"content":"总结本文基于 Github Pages 服务，使用成熟的框架及主题快速搭建个人博客demo。 更新网站两步走： 在博客文件夹（D:\\unclehuzi）下生成 public 文件夹 将 public 文件夹内的所有文件推送至GitHub仓库 后续在网站设计方面还需要了解下Web开发相关知识，针对性的修改主题的源码以实现自己的需求~ ","date":"2021-06-05","objectID":"/posts/20210528-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/:3:0","tags":["blog"],"title":"快速搭建个人博客","uri":"/posts/20210528-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"不打羽毛球、不写代码的营销人不是一名好分析师","date":"2021-05-28","objectID":"/about/","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"2020年7月硕士毕业于上海-华东师范大学-市场营销专业，并荣获 上海市优秀毕业生 初心还是想基于营销等商业相关理论指导数据分析工作。因此，也致力于思维、技术双轨道发展 将以此博客记录个人的成长 :) 平时（主要是周末）也会在下面俩地方打羽毛球 🏸 虽然技术不咋地，但就是玩~约球~ 上海市浦东新区羽山路1200号(近崮山路) 上海市浦东新区峨山路91弄140号同学汇综合运动馆 以下是我的个人公众号 ~欢迎关注一波~ ","date":"2021-05-28","objectID":"/about/:0:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":["写作"],"content":"毕业论文模板，样式先行 三年前的我搞毕业设计，第一次接触这玩意儿，一脸懵逼 好在我朱哥搞过大创（还是国家级的），当时给我各种科普单片机的知识 搞大创的好处就是当我们不知道是画机械图还是搞电路的时候，朱哥设计的成品以及论文都搞定了，，，跑马灯跑起来、酒精浓度测起来、小屏幕亮起来 不过朱哥也没继续搞汽车，后来投身了我国交通事业。依稀记得朱哥远程面试的时候，寝室几个人都在打游戏，，，在我们的影响下，朱哥最终去了广东某985高校 但那时候我们对Word排版都不怎么了解 以下情景历历在目： 这个参考文献的上标怎么弄？ 又要加篇参考文献？序号不得又重写？ 参考文献的引用格式是啥？ 这些字体都要改成三号、加粗？然后就用格式刷一顿更新 三线表是什么鬼？又要画三线表？ 。。。。。。 总之，我们都在Word上花了很长时间，不断的进行重复性的工作，以满足格式上要求 但当我们面对硕士毕业论文时，在格式方面花的时间就很少很少了，没有了各种重复性的操作 因为我们秉承着**样式先行。**在写论文之前，就根据学校的要求，把字体、表格的格式调整好，写作的过程中随时切换，而且就算后续要调整，统一调整对应的样式即可，避免了重复性操作。 本文并不是记录如何去调整/设计样式，因为我认为这个真的是太多了，重点是基于毕业论文格式记录word的正确打开方式，抽象出复用的部分。这也是我开发模板的原因。面对不同的需求，后续只需要微调即可。 可以在我的公众号内回复 word， 获取华东师范大学毕业论文模板 （用过的朋友都说好） ","date":"2020-04-21","objectID":"/posts/2020-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/:0:0","tags":["论文模板"],"title":"毕业论文模板","uri":"/posts/2020-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/"},{"categories":["写作"],"content":"模块拆解根据论文的总体框架，分别设计对应的样式。 换句话说便是先弄清楚整篇论文的字体、段落会涉及到哪些不同的格式要求，在正式写作之前，分别设计好对应的样式。以便写作过程调用。 毕业论文主体部分的格式要求，往往会涉及到各级标题、正文、脚注、参考文献（参考文献部分后续会单拎出来记录）字体的格式，理工科专业往往会要求表格是三线表。 确定好字体、段落的格式要求后，就可以针对性的修改/设计样式 为了方便后续的写作，可以设计相应的快捷键（样式-\u003e格式-\u003e快捷键） ","date":"2020-04-21","objectID":"/posts/2020-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/:1:0","tags":["论文模板"],"title":"毕业论文模板","uri":"/posts/2020-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/"},{"categories":["写作"],"content":"参考文献格式正文中往往会引用相关参考文献 这时候就要放出文献管理大杀器——NoteExpress 有了他，妈妈再也不用担心我修改参考文献的格式了 在软件中记录好被引用的内容，如作者、论文标题、年份、期刊或会议名称等等（大部分pdf、caj文献都能有效识别） 每当需要标注引用时，直接点击“引用”即可 通过NoteExpress引用至word后主要涉及两大部分： 正文部分的标注 上标序号 或 作者+年份 的形式 附在最后的参考文献 如 [1] LIU Y. Word of mouth for movies: Its dynamics and impact on box office revenue[J]. Journal of Marketing. 2006, 70(3): 74-89. 依然是样式先行的逻辑，简便的办法是先在NoteExpress样式库中选择与自己要求相似的样式，当然，完全满足需求就更好了。 接着，在所选样式的基础上修改相关格式以满足自己的需求 引文下的修改便是对应修改“正文部分的标注”的格式 题录下的修改便是对应修改“附在最后的参考文献”的格式 值得一提的是，题录中可设置排序的规则，因为有些学校要求英文文献在前面、之后再按照时间或作者排序。 ","date":"2020-04-21","objectID":"/posts/2020-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/:2:0","tags":["论文模板"],"title":"毕业论文模板","uri":"/posts/2020-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/"},{"categories":["写作"],"content":"Tips最后再记录些杂七杂八的tips ","date":"2020-04-21","objectID":"/posts/2020-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/:3:0","tags":["论文模板"],"title":"毕业论文模板","uri":"/posts/2020-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/"},{"categories":["写作"],"content":"表格、图片名称 选中表格（/图片），右键“插入题注”，标签选择“表”，编号选择“包含章节号” ","date":"2020-04-21","objectID":"/posts/2020-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/:3:1","tags":["论文模板"],"title":"毕业论文模板","uri":"/posts/2020-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/"},{"categories":["写作"],"content":"交叉引用论文中往往会看到如图xxx所示、如表xxx所示等表述方式，并且希望能定位到相关表格或图片时，就需要采用文内交叉引用的方法 ","date":"2020-04-21","objectID":"/posts/2020-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/:3:2","tags":["论文模板"],"title":"毕业论文模板","uri":"/posts/2020-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/"},{"categories":["写作"],"content":"公式当我们用MathType编辑公式，粘贴至word时，往往会影响word的格式，主要体现在行与行之间的距离变大。 对应的解决方案便：在对应的段落内，右键选择“段落”，取消勾选下图中所示内容 ","date":"2020-04-21","objectID":"/posts/2020-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/:3:3","tags":["论文模板"],"title":"毕业论文模板","uri":"/posts/2020-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/"},{"categories":["写作"],"content":"代码高亮涉及到代码的话，为了美观，往往希望word中代码也实现高亮 推荐 planetB 暂时统计了这几个tips，欢迎交流 ","date":"2020-04-21","objectID":"/posts/2020-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/:3:4","tags":["论文模板"],"title":"毕业论文模板","uri":"/posts/2020-%E8%AE%BA%E6%96%87%E6%8E%92%E7%89%88/"}]